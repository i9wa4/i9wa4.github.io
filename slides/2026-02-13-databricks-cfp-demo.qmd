---
title: "From `jupyter execute` to Production"
author:
  - name: Mawatari Daiki
categories:
  - "slides"
  - "genda"
date: 2026-02-13
date-modified: last-modified
description: |
  [Demo Slides] Data + AI Summit 2026 Call for Presentation - Speaking Sample

  Conference: Data + AI Summit 2026

  CFP Statement: "The world's largest event for the data, analytics and AI community wants to hear from you. Data + AI Summit is the perfect showcase for your brilliant insights and know-how and a platform for emerging trends and challenges."
# draft: true
image: "/assets/common/icon_hhkb3_large.jpg"
format:
  revealjs:
    auto-stretch: false
    code-copy: true
    footer: "From `jupyter execute` to Production"
    include-in-header:
      - ../_includes/hatena-nocomment.html
    incremental: false
    scrollable: true
    slide-level: 2
    slide-number: true
    smaller: false
    theme:
      - simple
      - ../themes/font.scss
    title-prefix: ""
    toc-depth: 2
    toc: false
    height: 1080
    width: 1920
  gfm: default
---

## 1. Introduction

Hello, I'm Daiki Mawatari from GENDA.

Today I'll demonstrate how AI agents can autonomously execute Databricks notebooks via CLI, enabling agentic development on Databricks.

---

## 2. The Vision

To unlock full AI automation with Databricks notebooks, we need a CLI-first approach that enables agents to execute code, receive results, and iterate independently.

**What you'll take away:**

- How to enable AI agents to execute Databricks notebooks from command line
- Practical patterns from GENDA's production data platform
- An open source tool you can use today

---

## 3. The Solution

**jupyter-databricks-kernel enables:**

- One-command notebook execution via CLI
- Complete remote execution on Databricks compute
- Seamless integration with AI coding assistants
- Natural workflow for autonomous iteration

---

## 4. Demo Environment

For this demo, I'm using the [databricks-ai-starter](https://github.com/i9wa4/databricks-ai-starter) repository running on GitHub Codespaces.

**Sample prompt to AI agent:**

> Compare trip patterns between weekdays and weekends in the NYC taxi dataset. Create and execute a notebook with compelling visualizations.

Claude Code will write and execute notebooks autonomously, demonstrating the agentic workflow in action.

---

## 5. Demo: CLI Execution

Let me show you with NYC taxi data analysis. I'll execute a notebook that queries trip trends and generates a visualization - all remotely on Databricks.

**CLI Execution:**

```bash
jupyter execute demo_nyctaxi.ipynb --kernel_name=databricks --inplace
```

It syncs local files to Databricks, executes on Databricks compute, and returns results immediately. No UI operations. No manual copying. Just one command.

---

## 6. Complete Remote Execution

The output shows a daily trip trend chart for January 2016. Execution occurs on Databricks compute using Databricks Runtime libraries.

**The key differentiator:** All code runs on Databricks, not locally. You can use any library pre-installed in Databricks Runtime without local environment setup.

Agents can iterate independently with kernel support. Minimal human intervention required.

---

## 7. Why This Matters

**Why credible:**

We've been using this in production at GENDA. Real-world proof, not just a demo.

**Why useful:**

It's open source. You can try it today. Reproducible workflow for your own projects.

**Why now:**

This enables agents to execute notebooks autonomously, aligning with the AI Agents track theme.

---

## 8. Production Ready

Development with jupyter-databricks-kernel runs on Databricks compute, matching production runtime. Verified notebooks deploy via Databricks Asset Bundles. AI agents can automate the deployment process.

---

## 9. Get Started

GitHub: [github.com/i9wa4/jupyter-databricks-kernel](https://github.com/i9wa4/jupyter-databricks-kernel)

Thank you.
