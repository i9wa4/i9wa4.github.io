[
  {
    "objectID": "blog/2025-03-28-display-notion-relation-property.html",
    "href": "blog/2025-03-28-display-notion-relation-property.html",
    "title": "Notion データベースでリレーション元のプロパティを表示する (2025年3月28日時点)",
    "section": "",
    "text": "下図のように Notion データベースでリレーションプロパティ (列) にはリレーション元のプロパティも併せて表示させると便利ですよね。\n\n\n\nリレーションプロパティの表示設定成功例\n\n\nタイトル記載日時点で公式ドキュメントに記載された通りに設定ができなかったので手順を共有します。\n一応以下が公式ドキュメントです。\nhttps://www.notion.com/ja/help/relations-and-rollups#リレーションの表示オプション"
  },
  {
    "objectID": "blog/2025-03-28-display-notion-relation-property.html#はじめに",
    "href": "blog/2025-03-28-display-notion-relation-property.html#はじめに",
    "title": "Notion データベースでリレーション元のプロパティを表示する (2025年3月28日時点)",
    "section": "",
    "text": "下図のように Notion データベースでリレーションプロパティ (列) にはリレーション元のプロパティも併せて表示させると便利ですよね。\n\n\n\nリレーションプロパティの表示設定成功例\n\n\nタイトル記載日時点で公式ドキュメントに記載された通りに設定ができなかったので手順を共有します。\n一応以下が公式ドキュメントです。\nhttps://www.notion.com/ja/help/relations-and-rollups#リレーションの表示オプション"
  },
  {
    "objectID": "blog/2025-03-28-display-notion-relation-property.html#リレーションプロパティの表示設定",
    "href": "blog/2025-03-28-display-notion-relation-property.html#リレーションプロパティの表示設定",
    "title": "Notion データベースでリレーション元のプロパティを表示する (2025年3月28日時点)",
    "section": "2. リレーションプロパティの表示設定",
    "text": "2. リレーションプロパティの表示設定\n最も混乱しづらいであろう手順を以下に示します。\n\n2.1. 利用するデータベースの説明\n\n2.1.1. item_master\nリレーション元として利用します。\n\n\n\n2.1.2. transaction_a\nitem_master をプロパティに追加させたいデータベースです。\n\n\n\n\n2.2. リレーションプロパティの追加\nデータベース全体の設定を行うのではなく、1アイテムを編集→全体適用でいきます。\n\ntransaction_a の1アイテムをサイドピークで開く\n右上の「…」→「レイアウトをカスタマイズ」とクリックする \n「＋」をクリックする \nリレーションプロパティを選択する \nリレーション元として item_master を選択する \nリレーションを追加する \nすべてのページに適用する \nリレーションプロパティの「…」から表示させたいプロパティを選択する \n完了"
  },
  {
    "objectID": "blog/2024-09-08-quarto-dataframe-preview-test.html",
    "href": "blog/2024-09-08-quarto-dataframe-preview-test.html",
    "title": "Quarto による DataFrame の表示テスト",
    "section": "",
    "text": "Pandas の DataFrame をウェブサイト一覧表作成に転用するための実験記事です。\n以下のように使用すれば CSV ファイルでタグを付与した形でウェブサイト一覧を管理できます。"
  },
  {
    "objectID": "blog/2024-09-08-quarto-dataframe-preview-test.html#ライブラリのインストール",
    "href": "blog/2024-09-08-quarto-dataframe-preview-test.html#ライブラリのインストール",
    "title": "Quarto による DataFrame の表示テスト",
    "section": "1. ライブラリのインストール",
    "text": "1. ライブラリのインストール\n#| include: true\n!python3 -m pip install pandas\n!python3 -m pip install --upgrade jinja2"
  },
  {
    "objectID": "blog/2024-09-08-quarto-dataframe-preview-test.html#関数定義",
    "href": "blog/2024-09-08-quarto-dataframe-preview-test.html#関数定義",
    "title": "Quarto による DataFrame の表示テスト",
    "section": "2. 関数定義",
    "text": "2. 関数定義\n#| include: true\nimport numpy as np\nimport pandas as pd\n\ndf_all = pd.read_csv('../assets/2024-09-08-quarto-df/quarto-df.csv')\n\n\ndef make_clickable(url, title):\n    return f'&lt;a href=\"{url}\"&gt;{title}&lt;/a&gt;'\n\n\ndef extract_tag(tag, df=df_all):\n    _df = df[df['Tags'].str.contains(tag)].copy()\n\n    # 欠損埋め\n    _df = _df.fillna({'Date': '9999-12-31'})\n    _df = _df.fillna('-')\n\n    # HACK: __init__.py を強調させないためのワークアラウンド\n    _df['Title'] = _df['Title'].replace(\n            '__init__.py', '__ init __.py', regex=True\n        )\n\n    # 日付とクリック可能なページ名の表示\n    _df = _df[['Date', 'Title', 'URL']].sort_values(\n            ['Date', 'Title'], ascending=[False, True]\n        )\n    _df.index = np.arange(1, len(_df) + 1)\n    _df['Website'] = _df.apply(\n            lambda row: make_clickable(row['URL'], row['Title']), axis=1\n        )\n    _df = _df[['Date', 'Website']].to_html(escape=False, index=False)\n    return _df"
  },
  {
    "objectID": "blog/2024-09-08-quarto-dataframe-preview-test.html#csv-内容確認",
    "href": "blog/2024-09-08-quarto-dataframe-preview-test.html#csv-内容確認",
    "title": "Quarto による DataFrame の表示テスト",
    "section": "3. CSV 内容確認",
    "text": "3. CSV 内容確認\n!cat ../assets/2024-09-08-quarto-df/quarto-df.csv"
  },
  {
    "objectID": "blog/2024-09-08-quarto-dataframe-preview-test.html#taga",
    "href": "blog/2024-09-08-quarto-dataframe-preview-test.html#taga",
    "title": "Quarto による DataFrame の表示テスト",
    "section": "4. TagA",
    "text": "4. TagA\n#| code-fold: false\nextract_tag('TagA')"
  },
  {
    "objectID": "blog/2024-09-08-quarto-dataframe-preview-test.html#tagb",
    "href": "blog/2024-09-08-quarto-dataframe-preview-test.html#tagb",
    "title": "Quarto による DataFrame の表示テスト",
    "section": "5. TagB",
    "text": "5. TagB\n#| code-fold: true\nextract_tag('TagB')"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-by-devin.html",
    "href": "blog/2025-04-05-weekly-report-by-devin.html",
    "title": "Devin に週報を書いてもらった",
    "section": "",
    "text": "最近 Devin で遊びながら勘所を掴んでいる最中です。 題材として丁度よかったので週報作成を Devin にやらせてみることにしました。"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-by-devin.html#はじめに",
    "href": "blog/2025-04-05-weekly-report-by-devin.html#はじめに",
    "title": "Devin に週報を書いてもらった",
    "section": "",
    "text": "最近 Devin で遊びながら勘所を掴んでいる最中です。 題材として丁度よかったので週報作成を Devin にやらせてみることにしました。"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-by-devin.html#週報作成の概要",
    "href": "blog/2025-04-05-weekly-report-by-devin.html#週報作成の概要",
    "title": "Devin に週報を書いてもらった",
    "section": "2. 週報作成の概要",
    "text": "2. 週報作成の概要\n集計期間の GitHub の issue と pull request の情報を基に各メンバーの活動の概要と詳細を issue にまとめてもらいます。"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-by-devin.html#devin-へのプロンプト",
    "href": "blog/2025-04-05-weekly-report-by-devin.html#devin-へのプロンプト",
    "title": "Devin に週報を書いてもらった",
    "section": "3. Devin へのプロンプト",
    "text": "3. Devin へのプロンプト\n長文プロンプトを用意する必要があります。 Devin では Playbook を利用すればよいですね。 今回はリポジトリ内の Markdown ファイルを参照させてます。\nプロンプトは別記事に分けてます。\nDevin 週報作成用プロンプト\n上に書いたような長文プロンプトを用意した上で以下のように Devin に指示を出します。\n\n以下の Markdown の指示に従って情報収集を行った上で GitHub issue を作成してください。 &lt;プロンプトとなるMarkdownのURL&gt;\n集計開始日：2025/03/12 集計終了日：2025/03/18"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-by-devin.html#devin-へのプロンプトを書く上でのコツ",
    "href": "blog/2025-04-05-weekly-report-by-devin.html#devin-へのプロンプトを書く上でのコツ",
    "title": "Devin に週報を書いてもらった",
    "section": "4. Devin へのプロンプトを書く上でのコツ",
    "text": "4. Devin へのプロンプトを書く上でのコツ\n\n4.1. Devin というか LLM の忘れっぽさへの対処\n長文だとどうしても近眼的に周囲数行の記述に引っぱられてしまうので、大枠の構造を提示しつつ、詳細は具体例とピンポイントなコメントという書き味にすることで出力が安定しました。\n今回各メンバーを列挙する箇所がありますが、横着せず愚直に列挙しました。 冗長だなあと思いつつもこうすることで Devin が忘れずに全メンバーの情報収集をしてくれました。\n\n\n4.2. GitHub CLI の仕様への対処\nDevin がうまく情報収集してくれないことがあるので GitHub CLI の仕様を理解し適切なコマンドを実行できているか見ておく必要があります。 今回は --state all オプションを指定して閉じられた issue なども取得させるように指示を出しています。\nまた、issue の description が長文になると文章を分割して編集追加させなければならなくなるので issue の description とコメントの行数を想定した上で適度に分割しておくと良いでしょう。 もし長文投稿させたい場合は作成した issue を読み込ませて見切れてないか Devin に確認させるのも良いかもしれません。"
  },
  {
    "objectID": "blog/2025-01-31-get-instagram-api-access-token.html",
    "href": "blog/2025-01-31-get-instagram-api-access-token.html",
    "title": "Instagram API のアクセストークンを取得する",
    "section": "",
    "text": "こういった作業ってテックブログ見るしかないですよね。 やっていきます。"
  },
  {
    "objectID": "blog/2025-01-31-get-instagram-api-access-token.html#参考ページ",
    "href": "blog/2025-01-31-get-instagram-api-access-token.html#参考ページ",
    "title": "Instagram API のアクセストークンを取得する",
    "section": "1. 参考ページ",
    "text": "1. 参考ページ\n\nInstagram API のアクセストークン取得手順\n超簡単！Instagram graph APIのアクセストークンを取得する - to inc マーケティングを企業のスタンダードに"
  },
  {
    "objectID": "blog/2025-01-31-get-instagram-api-access-token.html#手順",
    "href": "blog/2025-01-31-get-instagram-api-access-token.html#手順",
    "title": "Instagram API のアクセストークンを取得する",
    "section": "2. 手順",
    "text": "2. 手順\n\nFacebook アカウント作成\n\n会社メールアドレスで個人アカウントに該当するアカウントを作成してます\n\nmeta for Developers アカウント作成\n新規アプリ作成\n\nユースケース：その他\nアプリタイプ：ビジネス\n\n作成したアプリの設定\n\nアプリID・app secret を控える\n\nmeta for Developers の「ツール」→「グラフ API エクスプローラ」を起動する\nページ作成\n\n「ページアクセストークンの取得」を選択\n「現在のページにのみオプトイン」を選択\nページを作成する\n(ここでページ名がユニークである必要があるようで、エラーを起こしてページ作成制限を受けてしまいました😢また挑戦します)"
  },
  {
    "objectID": "blog/2024-07-20-aigis-note.html",
    "href": "blog/2024-07-20-aigis-note.html",
    "title": "自分用千年戦争アイギスメモ",
    "section": "",
    "text": "偶にハマって偶に飽きて辞めるという距離感で遊んでいる千年戦争アイギスのメモです。"
  },
  {
    "objectID": "blog/2024-07-20-aigis-note.html#週次周回",
    "href": "blog/2024-07-20-aigis-note.html#週次周回",
    "title": "自分用千年戦争アイギスメモ",
    "section": "1. 週次周回",
    "text": "1. 週次周回\n\n\n\n曜日\n対象\n\n\n\n\n月\n刻水晶\n\n\n火\n\n\n\n水\n魔水晶\n\n\n木\n好感度\n\n\n金\n\n\n\n土\n刻水晶, 魔水晶\n\n\n日\n好感度"
  },
  {
    "objectID": "blog/2024-07-20-aigis-note.html#月次の交換先",
    "href": "blog/2024-07-20-aigis-note.html#月次の交換先",
    "title": "自分用千年戦争アイギスメモ",
    "section": "2. 月次の交換先",
    "text": "2. 月次の交換先\n\n刻水晶 400\n\n白の皇帝 * 4 に交換する\n白の皇帝 信頼度150% Lv20 まで育成して他ユニットの餌にする\nイベントヒストリー 11年目 星降る黎明の大神ディアスの効率が良いらしい\n\n魔水晶 900\n\nリングと勲章に交換する\n\n覚醒聖霊ヴィクトワール\n\n統帥結晶ではなく魔水晶で交換する"
  },
  {
    "objectID": "blog/2024-01-02-jelyll-adjust.html",
    "href": "blog/2024-01-02-jelyll-adjust.html",
    "title": "GitHub Pages (Jekyll) blog のタグ追加対応",
    "section": "",
    "text": "[2024-07-15 追記] ブログは Jekyll から Quarto に切り替えたため下記内容はブログに反映されなくなっています。\nブログを作ったので少しだけ機能と見た目を手入れしてみました。"
  },
  {
    "objectID": "blog/2024-01-02-jelyll-adjust.html#調整前",
    "href": "blog/2024-01-02-jelyll-adjust.html#調整前",
    "title": "GitHub Pages (Jekyll) blog のタグ追加対応",
    "section": "1. 調整前",
    "text": "1. 調整前\n\n現在 Jekyll (GitHub Pages) の Minima (jekyll/minima: Minima is a one-size-fits-all Jekyll theme for writers.) が適用されている状態\n\nHTML ファイルが必要になったらここから持ってくる！"
  },
  {
    "objectID": "blog/2024-01-02-jelyll-adjust.html#やりたいこと",
    "href": "blog/2024-01-02-jelyll-adjust.html#やりたいこと",
    "title": "GitHub Pages (Jekyll) blog のタグ追加対応",
    "section": "2. やりたいこと",
    "text": "2. やりたいこと\n\nタグ対応\n\nタグ毎の一覧ページの追加\nトップページに各タグの一覧ページへのリンク追加\n各記事にて付与したタグの一覧ページリンクの追加\n\nリポジトリルートの Markdown ファイルへのリンクがヘッダに追加されてしまうためヘッダの記述の簡素化"
  },
  {
    "objectID": "blog/2024-01-02-jelyll-adjust.html#タグ対応",
    "href": "blog/2024-01-02-jelyll-adjust.html#タグ対応",
    "title": "GitHub Pages (Jekyll) blog のタグ追加対応",
    "section": "3. タグ対応",
    "text": "3. タグ対応\n\nsyudead さんの記事とリポジトリを参考に実装しました。私は HTML ではなく Markdown 中心の構成としたかったのであくまで参考という感じです。\n\nJekyllのブログでタグ機能を実装する\n\n各記事へのタグ付け方法\n一覧ページの html 記述\n\nsyudead/syudead.github.io\n\nページ一覧の作成方法\n\n./_inclides/tag.html を ./blog.html などの一覧ページ内にて include する\n\n各記述でのタグ一覧ページリンク表示\n\n./_layouts/post.html 参照\n\n\n\nトップページに各タグの一覧ページへのリンクを追加する対応については ./index.md に地道にリンクを追加する方法を取ることとしました。"
  },
  {
    "objectID": "blog/2024-01-02-jelyll-adjust.html#ヘッダ簡素化",
    "href": "blog/2024-01-02-jelyll-adjust.html#ヘッダ簡素化",
    "title": "GitHub Pages (Jekyll) blog のタグ追加対応",
    "section": "4. ヘッダ簡素化",
    "text": "4. ヘッダ簡素化\n\nMinima の HTML ファイル (minima/_includes/header.html at master · jekyll/minima) をリポジトリに追加して対象箇所を削除すれば OK。\n\n(2024/01/28 追記) スマホ版のハンバーガーメニューが寂しかったのでヘッダ簡素化は取りやめました。"
  },
  {
    "objectID": "blog/2024-01-02-jelyll-adjust.html#感想",
    "href": "blog/2024-01-02-jelyll-adjust.html#感想",
    "title": "GitHub Pages (Jekyll) blog のタグ追加対応",
    "section": "5. 感想",
    "text": "5. 感想\n\n必要最低限の機能は実装できたので割と満足です。\n見た目をちゃんと調整しようとすると HTML や CSS の調整が必要になってきますが、あんまりやりたくないので当面このままでいきます。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html",
    "href": "blog/2025-02-20-vim-plugin-idea.html",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "",
    "text": "少し前の Vim プラグイン開発のアイデア記事 で7個のアイデアを書いてました。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#ローカル設定の読み込み",
    "href": "blog/2025-02-20-vim-plugin-idea.html#ローカル設定の読み込み",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "1. ローカル設定の読み込み",
    "text": "1. ローカル設定の読み込み\nおそらく以下が近い気がしていて、自分の dotfiles の設定を切り出しつつ自分が使いやすい形で作りたいです。\nthinca/vim-localrc: Enable configuration file of each directory.\n相変わらず自作のローカル設定読み込みは活用してます。設定ファイル作成コマンドと最下層のローカル設定ファイルにジャンプするキーバインドが結構お気に入り。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#terminal-管理",
    "href": "blog/2025-02-20-vim-plugin-idea.html#terminal-管理",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "2. Terminal 管理",
    "text": "2. Terminal 管理\nVim/Neovim のターミナルを気軽に開いたり選択範囲のコマンドを流し込むためのプラグイン。\ndotfiles の中で温めてはいるものの、tmux に対する優位性を見い出せずあまり使ってません。\n他には REPL (IPython) 向けの設定もあります。ただ、細々とした Python コードを Vim で動作確認したいユースケースがあるのかなあ？\nやっぱり tmux をゴリゴリ使ってるので用途が結構限定的ですね。CWDに対してちょっとしたコマンドを実行したいときなんかは重宝してます。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#jupytext-と-ipynb-の同期",
    "href": "blog/2025-02-20-vim-plugin-idea.html#jupytext-と-ipynb-の同期",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "3. Jupytext と ipynb の同期",
    "text": "3. Jupytext と ipynb の同期\nJupytext で ipynb と py を同期させるプラグイン。\n最近 Databricks を使うようになったのですが、 Databricks では .ipynb を .py として保存する機能がもともと備わっていたので尚のこと必要でなくなってしまいました。次回はこの項目を削除しようかな。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#tabline-設定",
    "href": "blog/2025-02-20-vim-plugin-idea.html#tabline-設定",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "4. Tabline 設定",
    "text": "4. Tabline 設定\n頑張って書き上げたため切り離してもよいかも。\nTabline 用と Statusline 用の2関数だけだし既存プラグインとの差別化には至らないのでこの項目も削除かな。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#virtualtext-を活用したメモプラグイン",
    "href": "blog/2025-02-20-vim-plugin-idea.html#virtualtext-を活用したメモプラグイン",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "5. virtualtext を活用したメモプラグイン",
    "text": "5. virtualtext を活用したメモプラグイン\nコードリーディング中にメモを残すためのプラグイン。\nメモ一覧をリポジトリ内に保持しておきたい。\nLinter を参考にすればいけそうだけど、コードの行追加削除に追従させるのは自分の技術力では難しそう。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#dbt-プラグイン-deno",
    "href": "blog/2025-02-20-vim-plugin-idea.html#dbt-プラグイン-deno",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "6. dbt プラグイン (Deno)",
    "text": "6. dbt プラグイン (Deno)\nこれは作りました！一応以下が紹介記事です。\nVim/Neovimのdbt開発環境の現状とVimを救う話\nバグ取りをする必要あり。"
  },
  {
    "objectID": "blog/2025-02-20-vim-plugin-idea.html#zenn-quarto-の本文変換",
    "href": "blog/2025-02-20-vim-plugin-idea.html#zenn-quarto-の本文変換",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "7. Zenn <–> Quarto の本文変換",
    "text": "7. Zenn &lt;–&gt; Quarto の本文変換\nコードブロックの書き方を変換するだけで足りる？\n個人執筆記事については Quarto で書いて Zenn に連携という流れにしたいので、利用機会があまりなさそう。。"
  },
  {
    "objectID": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html",
    "href": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html",
    "title": "tmux で Vim から Claude Code にテキストを送信するプラグインを作った",
    "section": "",
    "text": "昨日 Claude Code デビューしました！🙌\nClaude Code 入力欄に Vim からテキストを送信したかったので Claude Code で Vim プラグインを作りました。"
  },
  {
    "objectID": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html#はじめに",
    "href": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html#はじめに",
    "title": "tmux で Vim から Claude Code にテキストを送信するプラグインを作った",
    "section": "",
    "text": "昨日 Claude Code デビューしました！🙌\nClaude Code 入力欄に Vim からテキストを送信したかったので Claude Code で Vim プラグインを作りました。"
  },
  {
    "objectID": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html#プラグインの概要",
    "href": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html#プラグインの概要",
    "title": "tmux で Vim から Claude Code にテキストを送信するプラグインを作った",
    "section": "2. プラグインの概要",
    "text": "2. プラグインの概要\nこちらが作成した Vim プラグインです。\n\nhttps://github.com/i9wa4/vim-tmux-send-to-claude-code\ntmux で同一ウインドウ内の特定の Claude Code ペイン (変数で指定可) に対して Vim ペインから以下のテキストを送信できます。\n\nバッファ全体\nヤンクしたテキスト\nVisual モードで選択したテキスト\n指定した行範囲のテキスト"
  },
  {
    "objectID": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html#claude-code-を使ってみた感想",
    "href": "blog/2025-06-20-vim-plugin-for-tmux-claude-code.html#claude-code-を使ってみた感想",
    "title": "tmux で Vim から Claude Code にテキストを送信するプラグインを作った",
    "section": "3. Claude Code を使ってみた感想",
    "text": "3. Claude Code を使ってみた感想\nもともとヤンクしたテキストを tmux のペイン間で送信するためのプラグインを作ろうと思っていました。\nClaude Code に任せつつ私のアイデアを共有したところ、気の効いた機能追加やドキュメント整備をサクッとやってくれました。\nREADME.md で紹介されているプラグインマネージャーが古かったり、キーバインドをデフォルトで押し付けてこようとしたりと既存のプラグインのリポジトリの特徴を掴んでいて面白いかったです。\nキーバインド押し付けは主義に反するので直してもらいましたが、プラグインマネージャーは古いままにしておきましょうかね。笑"
  },
  {
    "objectID": "blog/2025-05-06-python-venv.html",
    "href": "blog/2025-05-06-python-venv.html",
    "title": "Python venv インストール・更新スクリプトの供養",
    "section": "",
    "text": "uv で venv 仮想環境をメンテナンスすることにしたためこれまで利用していた venv のインストール・更新スクリプトを供養します。"
  },
  {
    "objectID": "blog/2025-05-06-python-venv.html#はじめに",
    "href": "blog/2025-05-06-python-venv.html#はじめに",
    "title": "Python venv インストール・更新スクリプトの供養",
    "section": "",
    "text": "uv で venv 仮想環境をメンテナンスすることにしたためこれまで利用していた venv のインストール・更新スクリプトを供養します。"
  },
  {
    "objectID": "blog/2025-05-06-python-venv.html#スクリプト-makefile",
    "href": "blog/2025-05-06-python-venv.html#スクリプト-makefile",
    "title": "Python venv インストール・更新スクリプトの供養",
    "section": "2. スクリプト (Makefile)",
    "text": "2. スクリプト (Makefile)\n実際はこのように Makefile に書いていましたが、流石に見辛いのでシェルスクリプト版も載せます。\npython-venv:  ## install/update Python venv (e.g. make python-venv VENV_PATH=\"${PY_VENV_MYENV}\" REQUIREMENTS_PATH=\"${HOME}\"/ghq/github.com/i9wa4/dotfiles/etc/requirements-venv-myenv.txt)\n    # https://dev.classmethod.jp/articles/change-venv-python-version/\n    . $(MF_DOTFILES_DIR)/dot.zshenv \\\n    && if [ -d \"$(VENV_PATH)\" ]; then \\\n      python -m venv \"$(VENV_PATH)\" --clear; \\\n    else \\\n      python -m venv \"$(VENV_PATH)\"; \\\n    fi \\\n    && . \"$(VENV_PATH)\"/bin/activate \\\n    && python -m pip config --site set global.trusted-host \"pypi.org pypi.python.org files.pythonhosted.org\" \\\n    && python -m pip install --upgrade pip setuptools wheel \\\n    && [ -r \"$(REQUIREMENTS_PATH)\" ] && python -m pip install --requirement \"$(REQUIREMENTS_PATH)\" \\\n    && python -m pip check \\\n    && python --version \\\n    && deactivate"
  },
  {
    "objectID": "blog/2025-05-06-python-venv.html#スクリプト-シェルスクリプト",
    "href": "blog/2025-05-06-python-venv.html#スクリプト-シェルスクリプト",
    "title": "Python venv インストール・更新スクリプトの供養",
    "section": "3. スクリプト (シェルスクリプト)",
    "text": "3. スクリプト (シェルスクリプト)\n#!/usr/bin/env bash\n\nVENV_PATH=\"${HOME}\"/.venv\nREQUIREMENTS_PATH=\"${HOME}\"/requirements.txt\n\nif [ -d \"${VENV_PATH}\" ]; then\n  python -m venv \"${VENV_PATH}\" --clear;\nelse\n  python -m venv \"${VENV_PATH}\";\nfi\n\n. \"${VENV_PATH}\"/bin/activate\npython -m pip config --site set global.trusted-host \"pypi.org pypi.python.org files.pythonhosted.org\"\npython -m pip install --upgrade pip setuptools wheel\n[ -r \"${REQUIREMENTS_PATH}\" ] && python -m pip install --requirement \"${REQUIREMENTS_PATH}\"\npython -m pip check\npython --version\ndeactivate"
  },
  {
    "objectID": "blog/2024-07-15-technical-tips.html",
    "href": "blog/2024-07-15-technical-tips.html",
    "title": "技術系 Tips まとめ",
    "section": "",
    "text": "たまに使うけど忘れてしまうような技術系の小ネタ (コマンド・設定) まとめ記事です。\n分量が増えてきた分野は別記事に切り出すかもしれません。"
  },
  {
    "objectID": "blog/2024-07-15-technical-tips.html#git",
    "href": "blog/2024-07-15-technical-tips.html#git",
    "title": "技術系 Tips まとめ",
    "section": "1. Git",
    "text": "1. Git\n# よく使うコマンド\ngit add -n .\ngit log --graph\ngit diff --name-only HEAD HEAD~2\ngit diff ID1 ID2 filename\ngit difftool ID1 ID2\ngit show ID\n\ngit reflog\ngit rebase\n\n# リモートリポジトリ作成\ngit init --bare --shared\ngit remote add origin url\ngit clone url"
  },
  {
    "objectID": "blog/2024-07-15-technical-tips.html#postgresql",
    "href": "blog/2024-07-15-technical-tips.html#postgresql",
    "title": "技術系 Tips まとめ",
    "section": "2. PostgreSQL",
    "text": "2. PostgreSQL\n# 起動～データベースへのアクセス\npg_ctl restart\npsql -U postgres -d db_name\n\npg_ctl restart\npsql -U postgres\nCREATE DATABASE db_name;\n\\c db_name\nCREATE SCHEMA sc_name;"
  },
  {
    "objectID": "blog/2024-07-15-technical-tips.html#google-cloud-cli-gcloud-cli",
    "href": "blog/2024-07-15-technical-tips.html#google-cloud-cli-gcloud-cli",
    "title": "技術系 Tips まとめ",
    "section": "3. Google Cloud CLI (gcloud CLI)",
    "text": "3. Google Cloud CLI (gcloud CLI)\n# keyfile 登録からテーブル確認まで\ngcloud auth activate-service-account --key-file ***.json\ngcloud auth list\ngcloud set account ***\nbq --project_id=aaaaa ls\nbq --project_id=aaaaa ls dataset_name\nbq --project_id=aaaaa show dataset_name.table_name\nbq --project_id=aaaaa head --max_rows 5 dataset_name.table_name\n# ログイン\ngcloud auth login"
  },
  {
    "objectID": "blog/2024-07-15-technical-tips.html#excel",
    "href": "blog/2024-07-15-technical-tips.html#excel",
    "title": "技術系 Tips まとめ",
    "section": "4. Excel",
    "text": "4. Excel\n\n4.1. Excel VBA\n\nアドイン追加先\n\n%USERPROFILE%\\AppData\\Roaming\\Microsoft\\AddIns\n\n\n\n\n4.2. Excel 関数\n\nシート名を記載したセルB2を利用したハイパーリンク作成\n\n=HYPERLINK(\"#'\"&B2&\"'!$A$1\",B2)"
  },
  {
    "objectID": "blog/2024-07-15-technical-tips.html#word",
    "href": "blog/2024-07-15-technical-tips.html#word",
    "title": "技術系 Tips まとめ",
    "section": "5. Word",
    "text": "5. Word\n\n5.1. Normal.dotm 作成\n\n%APPDATA%\\Microsoft\\Templates\\Normal.dotm 削除\nデザインを作成し既定に設定する\n\nテーマ設定\n\n見出し: 游ゴシック Arial\n本文: 游ゴシック Medium Arial\n\nアウトライン –&gt; 新しいアウトラインの定義 –&gt; オプション –&gt; レベルと対応付ける見出しスタイル"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "",
    "text": "tmux / Zsh / Vim を愛用してターミナルに引き籠っている者です。\nリポジトリのステータスの表示先として元々 Zsh プロンプトを活用していましたが Vim 起動中やコマンド実行中でプロンプトが見えないときにどうなっているか分からない点が以前から気になっていました。\nそこで今回はその点を解消できる tmux のステータスラインを活用してみることにしました。\ntmux 上の表示内容が結構気に入ったので同様の表示を Zsh プロンプトで実現する方法もついでに記載します。"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html#はじめに",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html#はじめに",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "",
    "text": "tmux / Zsh / Vim を愛用してターミナルに引き籠っている者です。\nリポジトリのステータスの表示先として元々 Zsh プロンプトを活用していましたが Vim 起動中やコマンド実行中でプロンプトが見えないときにどうなっているか分からない点が以前から気になっていました。\nそこで今回はその点を解消できる tmux のステータスラインを活用してみることにしました。\ntmux 上の表示内容が結構気に入ったので同様の表示を Zsh プロンプトで実現する方法もついでに記載します。"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html#対象読者",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html#対象読者",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "2. 対象読者",
    "text": "2. 対象読者\n\ntmux ユーザー\nZsh ユーザー"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html#tmux-と-zsh-に表示させるリポジトリのステータスの説明",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html#tmux-と-zsh-に表示させるリポジトリのステータスの説明",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "3. tmux と Zsh に表示させるリポジトリのステータスの説明",
    "text": "3. tmux と Zsh に表示させるリポジトリのステータスの説明\n分かる方はスキップしてください。\nどのステータスを表示させたいかは人によって異なると思いますが、今回は後述する tmux のプラグインの表示内容に沿って以下の情報を表示させることとしました。\n\n3.1. ブランチ名\n説明不要の重要要素。\n\n\n3.2. [Untracked files] ステージングされていない新規作成ファイル数\ngit status で\n\nUntracked files:\n\nに表示されるファイル数です。\n以下の実行例の場合は “1” です。\n$ git status\nOn branch tmux-zsh-git-status\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   ../package-lock.json\n        modified:   ../package.json\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        2025-05-04-tmux-zsh-git-status.md\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n\n3.3. [Unstaged files] ステージングされていない変更のあるファイル数\ngit status で\n\nChanges not staged for commit:\n\nに表示されるファイル数です。\n他の確認方法としては以下の行数や\n$ git diff --name-only\npackage-lock.json\npackage.json\n以下の files changed の表示を確認する方法もあります。\n$ git diff --shortstat\n 2 files changed, 5 insertions(+), 5 deletions(-)\n\n\n3.4. [Inserted lines] 追加行数\nステージングされていない変更のうち追加部分の行数です。\n行数カウントは以下のように --shortstat オプションを使うと簡単にできます。\n$ git diff --shortstat\n 2 files changed, 5 insertions(+), 5 deletions(-)\n\n\n3.5. [Deleted lines] 削除行数\nステージングされていない変更のうち削除部分の行数です。\n↑でも表示されていますね。"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html#tmux-のステータスラインにリポジトリのステータスを表示する",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html#tmux-のステータスラインにリポジトリのステータスを表示する",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "4. tmux のステータスラインにリポジトリのステータスを表示する",
    "text": "4. tmux のステータスラインにリポジトリのステータスを表示する\ntmux プラグインを利用して tmux のステータスラインにリポジトリのステータスを表示させます。\n\n4.1. tpm のインストール\nまずは tmux プラグインマネージャー tpm をインストールします。\nhttps://github.com/tmux-plugins/tpm\ntmux の設定ファイルがない、もしくは設定ファイルを ~/.tmux.conf に配置している方は以下のコマンドを実行してください。\ngit clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm\n私自身は tmux の設定ファイルを $XDG_CONFIG_HOME/tmux/tmux.conf に配置しています。その場合は $XDG_CONFIG_HOME/tmux/plugins/tpm にクローンし、以降の手順も適宜読み替えてください。\n続いて ~/.tmux.conf に以下のように記載します。 tpm を有効化させ、かつ tpm に tpm 自身を管理させる記述ですね。 run コマンドが ~/.tmux.conf の最終行になるようにしてください。\n\n\n~/.tmux.conf\n\n# List of plugins\nset -g @plugin 'tmux-plugins/tpm'\n\n# Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)\nrun '~/.tmux/plugins/tpm/tpm'\n\nここまで記載できたら tmux を再起動します。\n\n\n4.2. tmux-simple-git-status のインストール\nリポジトリのステータスを表示させるための以下の tmux プラグインをインストールしていきます。\nhttps://github.com/kristijanhusak/tmux-simple-git-status\nまずは ~/.tmux.conf のプラグインリストに以下のように記載します。\n\n\n~/.tmux.conf\n\n# List of plugins\nset -g @plugin 'tmux-plugins/tpm'\nset -g @plugin 'kristijanhusak/tmux-simple-git-status'\n\n# Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)\nrun '~/.tmux/plugins/tpm/tpm'\n\n記載できたら prefix-I (私はデフォルト設定のままなので Ctrl + b –&gt; I) を押してプラグインをインストールします。I は大文字です。\n\n\n4.3. ~/.tmux.conf の編集\n中央に記載した設定を書き入れます。 私は status-right 派ですので以下の設定をオススメします。 見切れることが気になる場合は status-right-length を調整してください。\n\n\n~/.tmux.conf\n\n# List of plugins\nset -g @plugin 'tmux-plugins/tpm'\nset -g @plugin 'kristijanhusak/tmux-simple-git-status'\n\n# Reflect tmux-simple-git-status settings\nset-option -g status-interval 1\nset-option -g status-right \"#{simple_git_status}\"\nset-option -g status-right-length 30\n\n# Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)\nrun '~/.tmux/plugins/tpm/tpm'\n\n設定の反映は tmux の再起動か prefix-I です。\n\n\n4.4. tmux への反映完了\nこのようにステータスライン右側にブランチ名とリポジトリのステータスが表示されるようになります。 最近ステータスラインは上側派になりました。"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html#zsh-プロンプトにリポジトリのステータスを表示する",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html#zsh-プロンプトにリポジトリのステータスを表示する",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "5. Zsh プロンプトにリポジトリのステータスを表示する",
    "text": "5. Zsh プロンプトにリポジトリのステータスを表示する\nこちらは素直に ~/.zshrc に記載していきます。\n\n5.1. ~/.zshrc の編集\nおまけなので細かい説明は省略しますが、私は以下のように設定しています。\n\n\n~/.zshrc\n\n# Git\nautoload -Uz add-zsh-hook\nautoload -Uz vcs_info\nsetopt prompt_subst\nzstyle ':vcs_info:*' formats \"%F{#DAFFF9}%b%f %m%F{#696969}%8.8i%f\"\nzstyle ':vcs_info:*' actionformats '%F{red}%b|%a%f %m%F{#696969}%8.8i%f'\nzstyle ':vcs_info:git:*' get-revision true\nzstyle ':vcs_info:git+set-message:*' hooks \\\n  simple-git-status\n\nfunction +vi-simple-git-status() {\n  local untracked=$(git status --porcelain 2&gt;/dev/null | grep -c \"^??\")\n  local unstaged=$(git diff --name-only 2&gt;/dev/null | wc -l | tr -d ' ')\n\n  local shortstat=$(git diff --shortstat 2&gt;/dev/null)\n  local insertions=0\n  local deletions=0\n  if [[ \"${shortstat}\" =~ '([0-9]+) insertion' ]]; then\n    insertions=\"${match[1]}\"\n  fi\n  if [[ \"${shortstat}\" =~ '([0-9]+) deletion' ]]; then\n    deletions=\"${match[1]}\"\n  fi\n\n  if { [[ -n \"${untracked}\" ]] } \\\n    && { [[ \"${untracked}\" -gt 0 ]] }; then\n    hook_com[misc]+=\"%F{cyan}?${untracked}%f \"\n  fi\n  if { [[ -n \"${unstaged}\" ]] } \\\n    && { [[ \"${unstaged}\" -gt 0 ]] }; then\n    hook_com[misc]+=\"%F{red}~${unstaged}%f \"\n  fi\n  if [[ \"${insertions}\" -gt 0 ]]; then\n    hook_com[misc]+=\"%F{green}+${insertions}%f \"\n  fi\n  if [[ \"${deletions}\" -gt 0 ]]; then\n    hook_com[misc]+=\"%F{red}-${deletions}%f \"\n  fi\n}\n\n_vcs_precmd(){ vcs_info }\nadd-zsh-hook precmd _vcs_precmd\n\n\n# Prompt\nif { [ -n \"${SSH_CONNECTION}\" ] } \\\n  || { [ -n \"${SSH_TTY}\" ] } \\\n  || { [ -n \"${SSH_CLIENT}\" ] }; then\n  # remote host\n  PROMPT=\"%K{#FFB6C1}%F{#000000}[%M]%f%k \"\nelse\n  # local host\n  PROMPT=\"\"\nfi\n_shell_type=\"$(ps -o comm -p $$ | tail -n 1 | sed -e 's/.*\\///g')\"\nPROMPT=\"${PROMPT}%F{#696969}%D{[%Y-%m-%d %H:%M:%S]} ${_shell_type} %f%K{#198CAA}%F{black}[%~]%f%k \"'${vcs_info_msg_0_}'\"\n%F{#696969}$%f \"\n\n\n\n5.2. Zsh への反映完了\n以下のように tmux のステータスラインと同じ内容を表示できます。 色はカラーコードで指定できるので好きなように設定しましょう！"
  },
  {
    "objectID": "blog/2025-05-04-tmux-zsh-git-status.html#おまけ",
    "href": "blog/2025-05-04-tmux-zsh-git-status.html#おまけ",
    "title": "tmux と Zsh に Git リポジトリのステータスを表示する",
    "section": "6. おまけ",
    "text": "6. おまけ\n私の tmux.conf と .zshrc の全体は以下です。 最近まで tmux.conf はほとんど設定してなかったんですが、今回プラグインを導入してみて tmux の使用感を良くすることにもある程度注目してみてもよいなと感じました。\nhttps://github.com/i9wa4/dotfiles/blob/8cadb966fea3499926a0d9bacebd4179c57d2326/dot.config/tmux/tmux.conf\nhttps://github.com/i9wa4/dotfiles/blob/5888691c07aea3a41cb44c0ec20500c8cb0c9ac2/dot.zshrc"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "",
    "text": "AWS Lambda で ECR にあるコンテナイメージを実行するために必要な全てのリソースを Terraform で構築し、GitHub Actions でデプロイできるようにします。"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html#はじめに",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html#はじめに",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "",
    "text": "AWS Lambda で ECR にあるコンテナイメージを実行するために必要な全てのリソースを Terraform で構築し、GitHub Actions でデプロイできるようにします。"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html#背景",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html#背景",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "2. 背景",
    "text": "2. 背景\n以下のような記事を参考にしながら MCP クライアントと MCP サーバーを全て Lambda (& ECR) で管理させようと考えています。\n\nSlackからLambda上にあるMCPクライアントとMCPサーバー動かす\nコンテナイメージを使用してAWS Lambda関数を作成する #Python - Qiita\nAWS Cost Analysis MCP ServerのツールをLambda関数に移植してAWS Lambda MCP Server経由で実行する | DevelopersIO\n爆速？！コンテナイメージからデプロイしたLambdaのコールドスタートについて検証してみた #reinvent | DevelopersIO\n\nまずは表題の通り動く Lambda を作成し CI/CD を整備することで以降に備えます。"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html#構成",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html#構成",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "3. 構成",
    "text": "3. 構成\nとりあえず動くようになったので、ほぼ無説明で構成だけ載せます。\nhttps://github.com/i9wa4/terraform-mono-repo/tree/fe67b11fe6e7696325103fd997980f5cf8e94f1d\n関係する部分は以下になっています。\n$ tree -a -I \".git/|hands-on-import|hands-on-sfn|.terraform\" -A\n.\n├── .github\n│   └── workflows\n│       └── hands-on-lambda-ecr-deploy.yml\n└── services\n    └── hands-on-lambda-ecr\n        ├── app\n        │   ├── app.py\n        │   ├── Dockerfile\n        │   └── requirements.txt\n        ├── README.md\n        └── terraform\n            ├── .terraform.lock.hcl\n            ├── main.tf\n            ├── outputs.tf\n            ├── variables.tf\n            └── versions.tf\nモノレポの練習で作ってみたリポジトリなのですが、整備はこれからという感じです。"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html#大変だった点",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html#大変だった点",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "4. 大変だった点",
    "text": "4. 大変だった点\n\nECR Image URI の取得周り\n\nECR タグを Immutable にしたせい\n\nGitHub Actions 内の OIDC 認証\n\n初めてやると慣れてなくて手間取った"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html#課題",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html#課題",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "5. 課題",
    "text": "5. 課題\n\nデプロイだけ手動でできるが CI は追加できていない\nmain.tf でかすぎ\ndev/prod 環境分離考慮してない\nローカルから Makefile でデプロイできるようにしてない"
  },
  {
    "objectID": "blog/2025-05-12-hands-on-lambda-ecr.html#おわりに",
    "href": "blog/2025-05-12-hands-on-lambda-ecr.html#おわりに",
    "title": "AWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions",
    "section": "6. おわりに",
    "text": "6. おわりに\n今までで一番大変な Hello World でした。\n整備は一旦後回しにして MCP 周りの実装をやっていきたいです。"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html",
    "href": "blog/2025-07-14-my-first-vim-contribution.html",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "",
    "text": "Note\n\n\n\nこの記事は Vim 駅伝 の 2025-07-14 の記事です。\n前回は 2025-07-11 NI57721 さんの Vim が Wayland のクリップボードをサポート でした。"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#はじめに",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#はじめに",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "1. はじめに",
    "text": "1. はじめに\nVim 本体に出したバグ修正の Pull Request がマージされました。\nhttps://github.com/vim/vim/commit/b3eaae21b9f681d23466e7caa0b9d7e32cb4b206\n以降でバグ発見の経緯と学びを共有します。\n\n\n\n私に Vim Contributor 表記が付与されている様子"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#バグ発見の経緯",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#バグ発見の経緯",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "2. バグ発見の経緯",
    "text": "2. バグ発見の経緯\n私は Vim の HEAD (main ブランチの最新コミット) ビルドを日課にしています。\n自分でビルドするとビルドオプションを指定できたり最新機能が使えたりして楽しいです。\nそうしているうちにある日ビルトインのファイラープラグインである Netrw.vim のファイル一覧に空行の入るバグが入ったことに気付きました。\n気になって Vim 本体の Issue や Pull Request を見ても同様のバグが報告されていなかったので自分で Pull Request を出すことにしました。\n……反省点として後述しますがこの判断はちょっと考慮が足りなかったです。"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#pull-request-作成まで",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#pull-request-作成まで",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "3. Pull Request 作成まで",
    "text": "3. Pull Request 作成まで\nOSS プロジェクトに Pull Request を出したことがなかったのですが、 CONTRIBUTING.md を読めばいいであろうということは知っていたので Vim のリポジトリの CONTRIBUTING.md を読みました。\nhttps://github.com/vim/vim/blob/master/CONTRIBUTING.md\n今回については Signing-off commits 推奨ということくらいで特に細かく何かを守る必要はないのかなという理解をしました。\nとは言えそれでは不安があったので直近の Netrw.vim 関連のコミットや Pull Request をざっくり確認してみました。\n実際の修正内容については Netrw.vim プラグインの直近1-2週間の間に入ったコミットの影響であろうことは分かっていたので Claude Code にバグ混入コミットを特定してもらって、修正案も出してもらいました。\n自分のマシン (macOS) では1行追加するだけで修正できることが分かり、勢いで Pull Request を作成しました。"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#pull-request-のレビュー",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#pull-request-のレビュー",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "4. Pull Request のレビュー",
    "text": "4. Pull Request のレビュー\nNetrw.vim のメンテナの @saccarosium さんにレビューしていただき Upstream と書き味を揃える Suggestion をいただきマージされました。"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#学び",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#学び",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "5. 学び",
    "text": "5. 学び\n\n5.1. 反省点\nPull Request を出すまでは近眼的になって気付かなかったのですが今回の修正対象のファイルのトップに\nvim/runtime/pack/dist/opt/netrw/autoload/netrw.vim\n\n\" Upstream: &lt;https://github.com/saccarosium/netrw.vim&gt;\n\nと書かれている通り Netrw.vim には Upstream のリポジトリ\nhttps://github.com/saccarosium/netrw.vim\nが存在します。\n実際 Upstream では私が Pull Request を作成する2日前に既に本件は修正済みとなっていました。\nというわけで本来はこの Upstream のリポジトリを最初に確認するのが正しい手順でした。\nこの状況を理解していた場合でも早めに Vim 本体側へ適用してほしい旨を相談することに変わりはなかったのですが、全てを知った上で行動するのが最善だったなあと思います。\nだれがどのように関わって Vim という巨大なリポジトリが成り立っているのかもっと知ろうと思うようになりました。\nもう1つの反省点は、改行回りが関係するので macOS だけでなく Windows についても考慮する必要があったという点です。\nVim のクロスプラットフォーム対応って大変なことなんだなあと改めて実感しました。\n\n\n5.2. Netrw.vim の理解度アップ\nNetrw.vim はメンテナ不在でバグも放置されていると言われていてここ数年その理解のままでした。\n今回の Pull Request をきっかけに新しいメンテナの方が精力的にリファクタリングを行っている現状を知ることができました。\n(今回のバグはリファクタリングの影響で発生したものでした)"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#おわりに",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#おわりに",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "6. おわりに",
    "text": "6. おわりに\n理解が不十分なまま勢いで Pull Request を作成したもののメンテナの @saccarosium さんの温情によりマージに至りました。\nなんやかんやで自分は Netrw.vim を毎日使っていて愛着があるなと自覚したのでこれ以降 Upstream の最新版を利用してます。\nまた次のコントリビュートチャンスを狙っていきたいと思います。"
  },
  {
    "objectID": "blog/2025-07-14-my-first-vim-contribution.html#おまけ",
    "href": "blog/2025-07-14-my-first-vim-contribution.html#おまけ",
    "title": "Vimへの初コントリビューションの経緯と学び",
    "section": "7. おまけ",
    "text": "7. おまけ\nvim-jp Slack の #dev チャンネルにて成果報告した様子\nvim-jp における #dev チャンネルとはもちろん Vim 本体開発の話題を扱うチャンネルですよ！"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html",
    "href": "blog/2025-07-28-article1-devcontainer.html",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "",
    "text": "本記事は3部構成の1本目です。"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html#はじめに",
    "href": "blog/2025-07-28-article1-devcontainer.html#はじめに",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "1. はじめに",
    "text": "1. はじめに\nClaude Codeを使いたいけれど環境構築が面倒、チーム全員に同じ開発環境を提供したい、そんな悩みをサクッと解決します。\nこの記事では Anthropic のリファレンス実装をベースに、実用的にカスタマイズしたDev Container設定を紹介します。"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html#対象読者",
    "href": "blog/2025-07-28-article1-devcontainer.html#対象読者",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "2. 対象読者",
    "text": "2. 対象読者\n\nClaude Code を使いたいが環境構築を簡単にしたい方\nチーム開発で統一された開発環境を提供したい方"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html#前提知識",
    "href": "blog/2025-07-28-article1-devcontainer.html#前提知識",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "3. 前提知識",
    "text": "3. 前提知識\n\n3.1. Dev Container とは\nDev Container は VS Code でコンテナを開発環境として利用できる便利機能です。\n今回の設定をチームで共有すれば全員に同じ開発環境を提供できます。\nVS Code以外のエディタでも Dev Container CLI を利用することで恩恵を受けることができます。\n\n\n3.2. Claude Code in Dev Container\nClaude Code を Dev Container で利用する方法について2通り紹介します。\n\n3.2.1. devcontainer.json の features を利用する\nこちらが簡単な方法です。\n以下に Anthropic が提供している Dev Container feature を利用する方法が記載されています。\nhttps://github.com/anthropics/devcontainer-features/blob/main/src/claude-code/README.md\n抜粋すると以下の通りです。\n\n\n.devcontainer/devcontainer.json\n\n\"features\": {\n    \"ghcr.io/devcontainers/features/node:1\": {},\n    \"ghcr.io/anthropics/devcontainer-features/claude-code:1\": {}\n}\n\n\n\n3.2.2. Dockerfile を利用する\n本家のリファレンス実装を利用する方法です。\n以下が Claude Code 向け Dev Container について記載されている公式ドキュメントです。\nhttps://docs.anthropic.com/en/docs/claude-code/devcontainer\nこの中でリファレンス実装として Claude Code 自身の Dev Container 設定が紹介されています。\nhttps://github.com/anthropics/claude-code/tree/main/.devcontainer\n.devcontainer\n├── devcontainer.json\n├── Dockerfile\n└── init-firewall.sh\nこのリファレンス実装を参考にしつつ私が使いやすいようにカスタマイズしたものを以下で紹介していきます。"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html#dev-container-設定",
    "href": "blog/2025-07-28-article1-devcontainer.html#dev-container-設定",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "4. Dev Container 設定",
    "text": "4. Dev Container 設定\n\n4.1. VS Code 側の準備\nDev Container 拡張をインストールしておく必要があります。\nhttps://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers\n\n\n4.2. Dockerfile\nAnthropic のリファレンス実装をベースにして以下のような Dockerfile を作成しました。\n見て分かる通り hadolint で結構指摘が出る書き味ですが特に意思もないのでそのままにしています。\n\n\n\n\n\n\n4.2.1. .devcontainer/Dockerfile\n\n\n\n\n\n\n\n.devcontainer/Dockerfile\n\nFROM node:20\n\nARG TZ\nENV TZ=\"$TZ\"\n\n# Install basic development tools and iptables/ipset\nRUN apt update && apt install -y less \\\n  git \\\n  procps \\\n  sudo \\\n  fzf \\\n  zsh \\\n  man-db \\\n  unzip \\\n  gnupg2 \\\n  gh \\\n  iptables \\\n  ipset \\\n  iproute2 \\\n  dnsutils \\\n  aggregate \\\n  jq\n\n# Ensure default node user has access to /usr/local/share\nRUN mkdir -p /usr/local/share/npm-global && \\\n  chown -R node:node /usr/local/share\n\nARG USERNAME=node\n\n# Persist bash history.\nRUN SNIPPET=\"export PROMPT_COMMAND='history -a' && export HISTFILE=/commandhistory/.bash_history\" \\\n  && mkdir /commandhistory \\\n  && touch /commandhistory/.bash_history \\\n  && chown -R $USERNAME /commandhistory\n\n# Set `DEVCONTAINER` environment variable to help with orientation\nENV DEVCONTAINER=true\n\n# Create workspace and config directories and set permissions\nRUN mkdir -p /workspace /home/node/.claude && \\\n  chown -R node:node /workspace /home/node/.claude\n\nWORKDIR /workspace\n\nRUN ARCH=$(dpkg --print-architecture) && \\\n  wget \"https://github.com/dandavison/delta/releases/download/0.18.2/git-delta_0.18.2_${ARCH}.deb\" && \\\n  sudo dpkg -i \"git-delta_0.18.2_${ARCH}.deb\" && \\\n  rm \"git-delta_0.18.2_${ARCH}.deb\"\n\n# Set up non-root user\nUSER node\n\n# Install global packages\nENV NPM_CONFIG_PREFIX=/usr/local/share/npm-global\nENV PATH=$PATH:/usr/local/share/npm-global/bin\n\n# Set the default shell to zsh rather than sh\nENV SHELL=/bin/zsh\n\n# Default powerline10k theme\nRUN sh -c \"$(wget -O- https://github.com/deluan/zsh-in-docker/releases/download/v1.2.0/zsh-in-docker.sh)\" -- \\\n  -p git \\\n  -p fzf \\\n  -a \"source /usr/share/doc/fzf/examples/key-bindings.zsh\" \\\n  -a \"source /usr/share/doc/fzf/examples/completion.zsh\" \\\n  -a \"export PROMPT_COMMAND='history -a' && export HISTFILE=/commandhistory/.bash_history\" \\\n  -x\n\n# Install Claude\nRUN npm install -g @anthropic-ai/claude-code\n\n# Python environment setup (if needed)\n# Copy uv binary from official image\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n\nUSER node\n\nAnthropic のリファレンス実装 (e394b39) と比較すると以下のような変更を行っています。\n\nfirewall スクリプト対応部分を削除\nuv インストール部分を追加\n\n$ diff -u ../../anthropics/claude-code/.devcontainer/Dockerfile .devcontainer/Dockerfile\n--- ../../anthropics/claude-code/.devcontainer/Dockerfile       2025-07-26 16:16:50\n+++ .devcontainer/Dockerfile    2025-07-26 23:24:59\n@@ -69,10 +69,8 @@\n # Install Claude\n RUN npm install -g @anthropic-ai/claude-code\n\n-# Copy and set up firewall script\n-COPY init-firewall.sh /usr/local/bin/\n-USER root\n-RUN chmod +x /usr/local/bin/init-firewall.sh && \\\n-  echo \"node ALL=(root) NOPASSWD: /usr/local/bin/init-firewall.sh\" &gt; /etc/sudoers.d/node-firewall && \\\n-  chmod 0440 /etc/sudoers.d/node-firewall\n+# Python environment setup (if needed)\n+# Copy uv binary from official image\n+COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv\n+\n USER node\n\n\n\n\n\n4.3. devcontainer.json\n以下のような devcontainer.json を作成しました。\nこちらは Anthropic のリファレンス実装に比べると割と変更点が多いです。\n\n\n\n\n\n\n4.3.1. .devcontainer/devcontainer.json\n\n\n\n\n\n\n\n.devcontainer/devcontainer.json\n\n{\n    \"name\": \"Claude Code Development Environment\",\n    \"build\": {\n        \"dockerfile\": \"Dockerfile\",\n        \"args\": {\n            \"TZ\": \"${localEnv:TZ:Asia/Tokyo}\"\n        }\n    },\n    \"runArgs\": [\n        \"--cap-add=NET_ADMIN\",\n        \"--cap-add=NET_RAW\"\n    ],\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\n                \"editorconfig.editorconfig\",\n                \"elagil.pre-commit-helper\"\n            ],\n            \"settings\": {\n                \"terminal.integrated.defaultProfile.linux\": \"zsh\",\n                \"terminal.integrated.profiles.linux\": {\n                    \"bash\": {\n                        \"path\": \"bash\",\n                        \"icon\": \"terminal-bash\"\n                    },\n                    \"zsh\": {\n                        \"path\": \"zsh\"\n                    }\n                }\n            }\n        }\n    },\n    \"remoteUser\": \"node\",\n    \"mounts\": [\n        \"source=${localEnv:CLAUDE_CONFIG_DIR},target=/home/node/.claude,type=bind,consistency=cached\",\n        \"source=${localEnv:HOME}/.config/gh,target=/home/node/.config/gh,type=bind,consistency=cached\",\n        \"source=${localEnv:HOME}/.config/git,target=/home/node/.config/git,type=bind,consistency=cached\",\n        \"source=${localEnv:HOME}/.gitconfig,target=/home/node/.gitconfig,type=bind,consistency=cached\",\n        \"source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,consistency=cached\",\n        \"source=claude-code-bashhistory-${devcontainerId},target=/commandhistory,type=volume\"\n    ],\n    \"remoteEnv\": {\n        \"CLAUDE_CONFIG_DIR\": \"/home/node/.claude\",\n        \"NODE_OPTIONS\": \"--max-old-space-size=4096\",\n        \"POWERLEVEL9K_DISABLE_GITSTATUS\": \"true\"\n    },\n    \"workspaceMount\": \"source=${localWorkspaceFolder},target=/workspace,type=bind,consistency=delegated\",\n    \"workspaceFolder\": \"/workspace\"\n}\n\nAnthropic のリファレンス実装 (33e37bd) と比較すると以下のような変更を行っています。\n\nVS Code 向け拡張機能を追加\n\neditorconfig.editorconfig\n\nテキストエディタ間での設定を統一する\n\nelagil.pre-commit-helper\n\npre-commit を使いやすくする\n\n\nVS Code 向け Formatter 設定を削除\nmounts に設定ファイル群を追加\n\n以下のツールの設定ファイルをマウントして利用します\n\nClaude Code\nGitHub CLI\nGit\nssh\n\n\nmounts の Claude Code 設定分離部分を削除\n\nユーザー設定をマウントして利用したかったので削除しました\n\nremoteEnv に以下の環境変数を追加\n\nCLAUDE_CONFIG_DIR\n\nClaude Code の設定参照箇所の安定化を図る"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html#利用手順",
    "href": "blog/2025-07-28-article1-devcontainer.html#利用手順",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "5. 利用手順",
    "text": "5. 利用手順\n\n5.1. Claude Code 設定\nClaude Code の設定ディレクトリを環境変数で指定しておきます。\nexport CLAUDE_CONFIG_DIR=\"$HOME/.claude\"\n\n\n5.2. Dev Container VS Code\n\nF1 -&gt; “Dev Containers: Open Folder in Container…” を選択します\nClaude Code はインストール済みなのでターミナルから起動できます\n\n\n\n5.3. Dev Container CLI\nVS Code を使わない場合は Dev Container CLI を利用できます。\n# Dev Container CLI のインストール\nnpm install -g @devcontainers/cli\n\n# コンテナ起動\ndevcontainer up --workspace-folder .\n\n# コンテナに接続\ndevcontainer exec --workspace-folder . zsh"
  },
  {
    "objectID": "blog/2025-07-28-article1-devcontainer.html#おわりに",
    "href": "blog/2025-07-28-article1-devcontainer.html#おわりに",
    "title": "Claude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも",
    "section": "6. おわりに",
    "text": "6. おわりに\nこれで Claude Code が使える開発環境の完成です。\n次回はこの環境に Python 開発環境を追加する方法を紹介します。\nPython 開発環境最適化編 - uv + pre-commit + GitHub Actions"
  },
  {
    "objectID": "blog/2025-06-15-dbt-bigquery-auth.html",
    "href": "blog/2025-06-15-dbt-bigquery-auth.html",
    "title": "ローカル dbt で BigQuery への認証を行う",
    "section": "",
    "text": "dbt も BigQuery も経験それなりにあるものの dbt x BigQuery をやったことがなかったので認証方法を知ったのが今となります。"
  },
  {
    "objectID": "blog/2025-06-15-dbt-bigquery-auth.html#はじめに",
    "href": "blog/2025-06-15-dbt-bigquery-auth.html#はじめに",
    "title": "ローカル dbt で BigQuery への認証を行う",
    "section": "",
    "text": "dbt も BigQuery も経験それなりにあるものの dbt x BigQuery をやったことがなかったので認証方法を知ったのが今となります。"
  },
  {
    "objectID": "blog/2025-06-15-dbt-bigquery-auth.html#dbt-のドキュメントを参照してみる",
    "href": "blog/2025-06-15-dbt-bigquery-auth.html#dbt-のドキュメントを参照してみる",
    "title": "ローカル dbt で BigQuery への認証を行う",
    "section": "2. dbt のドキュメントを参照してみる",
    "text": "2. dbt のドキュメントを参照してみる\nOAuth を使った認証方法は以下のドキュメントに記載されています。\nhttps://docs.getdbt.com/docs/core/connect-data-platform/bigquery-setup#local-oauth-gcloud-setup\nではあるのですが、実際のログイン方法として紹介されているコマンドは少し違うようで、代表的なものは以下のような感じです。\ndbt CoreでローカルからBigQueryを操作するためのセットアップ方法 | DevelopersIO\n記事でよく見かけるものを実行していきます。"
  },
  {
    "objectID": "blog/2025-06-15-dbt-bigquery-auth.html#認証手順",
    "href": "blog/2025-06-15-dbt-bigquery-auth.html#認証手順",
    "title": "ローカル dbt で BigQuery への認証を行う",
    "section": "3. 認証手順",
    "text": "3. 認証手順\n\n3.1. profiles.yml の設定\n以下のような記載が含まれていれば OK\nmethod: oauth を指定していることがポイントです。\n\n\n~/.dbt/profiles.yml\n\nmy_dbt_project:\n  target: dev\n  outputs:\n    dev:\n      type: bigquery\n      method: oauth\n      project: my-google-cloud-project\n      threads: 4\n      schema: my_schema\n\n\n\n3.2. アプリケーション向けのログイン\n以下のコマンドにより dbt が Google Cloud の API を呼び出せることになります。\n$ gcloud auth application-default login"
  },
  {
    "objectID": "blog/2025-06-15-dbt-bigquery-auth.html#おわりに",
    "href": "blog/2025-06-15-dbt-bigquery-auth.html#おわりに",
    "title": "ローカル dbt で BigQuery への認証を行う",
    "section": "4. おわりに",
    "text": "4. おわりに\nいま手元では1環境にしかログインしないのであまり深く理解していなくても大丈夫ですが、複数環境にログインする際にもうちょっと深く理解しておきます。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html",
    "href": "blog/2025-04-02-looking-back-on-2024.html",
    "title": "2024年度を振り返る",
    "section": "",
    "text": "本当は年末に振り返ろうかと思っていましたが転職したてだったのでこのタイミングになりました。\n2024年度に初めて経験したことを振り返ってみます。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html#初めて東京の会社に勤めた",
    "href": "blog/2025-04-02-looking-back-on-2024.html#初めて東京の会社に勤めた",
    "title": "2024年度を振り返る",
    "section": "1. 初めて東京の会社に勤めた",
    "text": "1. 初めて東京の会社に勤めた\n2018年からずっと東京の顧客相手に仕事をしてきたものの拠点自体は東京ではありませんでした。\n東京に住んでいないというハンデがある中でどのようにキャリア構築していくかというゲームだと思って頑張ってます。折角なのでいつかこの手の話で登壇したいです。\nリモートワークとはいえやはり東京の会社に正社員として勤めていると刺激を多く得られますね。\n東京のエンジニアのキャリア構築の考え方や仕事ぶりを目の前で見るという経験を今得られて本当によかったと思ってます。\n自分の職業人生もプライベートもよりよいものにできる指針が見つかった1年でした。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html#初めてインフラ領域に触れた",
    "href": "blog/2025-04-02-looking-back-on-2024.html#初めてインフラ領域に触れた",
    "title": "2024年度を振り返る",
    "section": "2. 初めてインフラ領域に触れた",
    "text": "2. 初めてインフラ領域に触れた\n2024年3月以前の自分は AWS に触っていたとはいえ SageMaker や MWAA (Amazon Managed Workflows for Apache Airflow) など構築済みのリソースを利用するばかりで全般に解像度が低めでした。\nCloudWatch を使う必要のない仕事をしていたというと分かりやすいかしれません。\nそれが今では AWS の主要サービス全般をデータエンジニア業務遂行上全く困らなくなるレベルで使えるようになりました。\nTerraform を介して AWS/Google Cloud (BigQuery)/Snowflake の使われている基盤の構築や修正、GitHub Actions を使った CI/CD 整備、機械学習におけるインフラリソース調整までできるようになり飛躍的に基盤周りの仕事がこなせるようになりました。\n特に Terraform に関しては2024年3月まで勤めていた会社ではベテランのつよつよインフラエンジニアが社内で唯一ちょっと齧ったことがあるという程度で正直雲の上の存在でした。\nまさか自分がここまでできるようになるとはという思いです。\nとは言えこれからデータ組織の長を目指していく上で Terraform や基盤のことくらい分からないとダメだよねと思って転職していて自分で引き寄せた結果ではあります。\nエンジニアとしての仕事の密度が非常に高く、これまでの社会人生活で最も成長した1年間でした。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html#初めてデータ基盤開発からダッシュボード運用までの一気通貫な仕事をした",
    "href": "blog/2025-04-02-looking-back-on-2024.html#初めてデータ基盤開発からダッシュボード運用までの一気通貫な仕事をした",
    "title": "2024年度を振り返る",
    "section": "3. 初めてデータ基盤開発からダッシュボード運用までの一気通貫な仕事をした",
    "text": "3. 初めてデータ基盤開発からダッシュボード運用までの一気通貫な仕事をした\n現職での話です。\n直接目の前の誰かの役に立つ仕事、良いですね。\n売上を追求するというより社員のためになることに喜びを感じます。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html#初めて-macbook-を会社支給された-私用端末として購入した",
    "href": "blog/2025-04-02-looking-back-on-2024.html#初めて-macbook-を会社支給された-私用端末として購入した",
    "title": "2024年度を振り返る",
    "section": "4. 初めて MacBook を会社支給された & 私用端末として購入した",
    "text": "4. 初めて MacBook を会社支給された & 私用端末として購入した\n上に書いたものに比べるとスケールが小さい話ですが自分にとっては大きなターニングポイントであると感じます。\nWindows か macOS かなんてただ OS が違うだけではないかと思ってしまいそうですが、これが会社のカテゴリを象徴してるんですよね。\n自分はこれからも個人に自由や裁量のある環境で仕事を続けていこうと思っていて、MacBook はその象徴であると感じています。\nこれから先の自分のキャリアは MacBook と共にあるということです。\nこれは Apple というブランドが好きになったということなのだろうと思います。\n実は iPhone と Apple Watch を初めて買ったのも2024年でした。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html#初めて会社ブログを執筆した",
    "href": "blog/2025-04-02-looking-back-on-2024.html#初めて会社ブログを執筆した",
    "title": "2024年度を振り返る",
    "section": "5. 初めて会社ブログを執筆した",
    "text": "5. 初めて会社ブログを執筆した\nSIer 歴が長く会社ブログを書く機会がありませんでした。\n現状は Zenn に好きなだけ記事を投稿させてもらえるのでもっと色々と書いていきたいです。\nとりとめのないことを書くという立ち位置のこのブログは2024年1月から始めてますが意外と飽きずに続いてますね。えらい。"
  },
  {
    "objectID": "blog/2025-04-02-looking-back-on-2024.html#まとめ",
    "href": "blog/2025-04-02-looking-back-on-2024.html#まとめ",
    "title": "2024年度を振り返る",
    "section": "6. まとめ",
    "text": "6. まとめ\n間違いなく人生のターニングポイントになった1年でした。\n泥臭くキャリアを構築してきた地方民とキャリアの話をしてみたいですねぇ。こういう話をしながら飲む酒が一番良いんだ。。"
  },
  {
    "objectID": "blog/2025-09-28-bigquery-dbt-incremental-intro.html",
    "href": "blog/2025-09-28-bigquery-dbt-incremental-intro.html",
    "title": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた",
    "section": "",
    "text": "ログ同士を突き合わせる dbt モデルの dbt run 実行時間が1時間を超えていたため、BigQuery の特性を活かしつつ実行時間を40分短縮した流れを紹介します。対象はイミューターなログを扱うモデルで、過去データの更新を考慮しない前提を置ける構造でした。"
  },
  {
    "objectID": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#はじめに",
    "href": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#はじめに",
    "title": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた",
    "section": "",
    "text": "ログ同士を突き合わせる dbt モデルの dbt run 実行時間が1時間を超えていたため、BigQuery の特性を活かしつつ実行時間を40分短縮した流れを紹介します。対象はイミューターなログを扱うモデルで、過去データの更新を考慮しない前提を置ける構造でした。"
  },
  {
    "objectID": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#当初の課題",
    "href": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#当初の課題",
    "title": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた",
    "section": "2. 当初の課題",
    "text": "2. 当初の課題\n\nincremental_strategy が merge で、ターゲットテーブル全体を走査していた\nunique_key が15列と多く、結合条件が複雑であった\n参照元テーブルが期間条件なしで FULL OUTER JOIN され、中間結果が肥大化していた"
  },
  {
    "objectID": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#実施した改善策",
    "href": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#実施した改善策",
    "title": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた",
    "section": "3. 実施した改善策",
    "text": "3. 実施した改善策\n\n3.1. incremental_strategy の切り替え\n\nmerge から insert_overwrite へ変更し、対象パーティションのみを差し替えた\n\n\n\n3.2. パーティションプルーニングの徹底\n\nvars で渡した日付範囲を JOIN 前のフィルタで適用し、読み取り対象を日次で限定した\nパーティション指定を日単位で明示化し、BigQuery のスキャン範囲を事前に制限した\n\n\n\n3.3. 重複除去ロジックの簡素化\n\n15列のunique_key指定を ROW_NUMBER() による決定的な重複除去に変更した\n複雑なMERGE処理からシンプルな重複除去ロジックへ簡素化した"
  },
  {
    "objectID": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#効果と検証",
    "href": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#効果と検証",
    "title": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた",
    "section": "4. 効果と検証",
    "text": "4. 効果と検証\n\ndbt run 実行時間は1時間超えから40分短縮できた\n同期間の surrogate key 単位で件数と代表値を比較し整合性を確認できた\n修正前後で更新内容に差異がないことを確認できた (ログデータの特性上そうなる)"
  },
  {
    "objectID": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#おわりに",
    "href": "blog/2025-09-28-bigquery-dbt-incremental-intro.html#おわりに",
    "title": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた",
    "section": "5. おわりに",
    "text": "5. おわりに\nBigQuery の挙動と dbt の incremental モデルへの習熟度がまだまだなので引き続き学びを深めます。"
  },
  {
    "objectID": "blog/2024-06-17-purchased-gadgets.html",
    "href": "blog/2024-06-17-purchased-gadgets.html",
    "title": "購入したガジェットの紹介",
    "section": "",
    "text": "詳細まで書くかは決めていませんが、これまで購入したガジェット一覧を作っておきます。\n\n\n\nTable 1: 購入ガジェット一覧\n\n\n\n\n\n購入日\nメーカー\n製品名\n\n\n\n\n2019-07-01\nLogicool\nPebble M350\n\n\n2020-09-12\n象印\nスチーム式加湿器 EE-RN35-WA\n\n\n2020-07-19\nPFU\nHHKB Professional HYBRID Type-S 英語配列／墨\n\n\n2022-03-12\nLogicool\nERGO M575\n\n\n2022-12-05\nKensington\nスリムブレードトラックボール\n\n\n2023-03-05\nGoogle\nPixel 6a\n\n\n2023-03-12\nSONY\nWF-1000XM4\n\n\n2023-08-05\nBeelink\nBeelink SEi10 Mini PC\n\n\n2024-02-28\nAnker\nAnker PowerExpand 6-in-1 USB-C PD イーサネット ハブ\n\n\n2024-03-02\nLenovo\nThinkPad T14s Gen 4 (AMD)\n\n\n2024-04-05\nShokz\nOpenRun Pro Mini\n\n\n2024-05-06\nFitbit\nFitbit Charge 6\n\n\n2024-06-03\nDell\nDell 27 USB-C モニター - S2722DC\n\n\n2024-06-07\nLogicool\nC270n HDウェブカメラ\n\n\n2024-07-07\nPanasonic\nラムダッシュ パームイン ES-PV3A\n\n\n2024-08-18\nOMRON\n体重体組成計 HBF-702T カラダスキャン\n\n\n2024-10-05\nApple\niPhone 16 256GB\n\n\n2024-10-05\nApple\nApple Watch Series 10\n\n\n2024-12-13\nfinal\nZE500 for ASMR -Patra Black-\n\n\n2024-12-15\n象印\nスチーム式加湿器 EE-RT50-WA\n\n\n2025-02-12\nProtoArc\nProtoArc EM01\n\n\n2025-03-23\nApple\nMacBook Air M4 13インチ 10コアCPU 10コアGPU メモリ32GB"
  },
  {
    "objectID": "blog/2024-06-28-systemd-user.html",
    "href": "blog/2024-06-28-systemd-user.html",
    "title": "systemd がユーザー権限でも使える",
    "section": "",
    "text": "systemd がユーザー権限でも設定できると知ったので記事にします。"
  },
  {
    "objectID": "blog/2024-06-28-systemd-user.html#基本的な情報まとめ",
    "href": "blog/2024-06-28-systemd-user.html#基本的な情報まとめ",
    "title": "systemd がユーザー権限でも使える",
    "section": "1. 基本的な情報まとめ",
    "text": "1. 基本的な情報まとめ\n\n設定ファイル格納先\n\n~/.config/systemd/user/\n\nコマンド\n\nsystemd --user\nuser オプションを付けて通常の systemd と同様に使用する"
  },
  {
    "objectID": "blog/2024-06-28-systemd-user.html#timer-設定手順",
    "href": "blog/2024-06-28-systemd-user.html#timer-設定手順",
    "title": "systemd がユーザー権限でも使える",
    "section": "2. timer 設定手順",
    "text": "2. timer 設定手順\n私の用途では timer 設定ができれば OK です。\n下記リポジトリの設定を使って説明していきます。\ni9wa4/minecraft-bedrock-server-setup/bin/init.sh\n# ~/.config/systemd/user/ に設定ファイルを配置する\nln -fs \"${DIR_REPO}\"/etc/mbs-backup.service \\\n  \"${HOME}\"/.config/systemd/user/mbs-backup.service\nln -fs \"${DIR_REPO}\"/etc/mbs-backup.timer \\\n  \"${HOME}\"/.config/systemd/user/mbs-backup.timer\n\n# 設定ファイルを読み込む\nsystemctl --user daemon-reload\n\n# timer をログイン時に実行する\nsystemctl --user enable mbs-backup.timer\n\n# timer を実行する\nsystemctl --user start mbs-backup.timer\n\n# サーバーの起動時にサービスを立ち上げる\nsudo loginctl enable-linger i9wa4"
  },
  {
    "objectID": "blog/2024-06-28-systemd-user.html#参考リンク",
    "href": "blog/2024-06-28-systemd-user.html#参考リンク",
    "title": "systemd がユーザー権限でも使える",
    "section": "3. 参考リンク",
    "text": "3. 参考リンク\n\nsystemd/ユーザー - ArchWiki\nサーバー起動時に非rootユーザーでsystemdを使ってサービスを立ち上げる #systemd - Qiita"
  },
  {
    "objectID": "blog/2025-05-21-databricks-dashboard-github-operation.html",
    "href": "blog/2025-05-21-databricks-dashboard-github-operation.html",
    "title": "Databricks AI/BI ダッシュボードの Git 連携の運用方法",
    "section": "",
    "text": "Databricks のダッシュボードは Git 連携できます！\nGitにおけるDatabricks AI/BIダッシュボードのソース管理 #Databricks_AI_BI - Qiita\nバックアップを取り安心したいので必ず導入しましょう。\nGit 連携を用いた運用方法について検討したので記事として残します。"
  },
  {
    "objectID": "blog/2025-05-21-databricks-dashboard-github-operation.html#はじめに",
    "href": "blog/2025-05-21-databricks-dashboard-github-operation.html#はじめに",
    "title": "Databricks AI/BI ダッシュボードの Git 連携の運用方法",
    "section": "",
    "text": "Databricks のダッシュボードは Git 連携できます！\nGitにおけるDatabricks AI/BIダッシュボードのソース管理 #Databricks_AI_BI - Qiita\nバックアップを取り安心したいので必ず導入しましょう。\nGit 連携を用いた運用方法について検討したので記事として残します。"
  },
  {
    "objectID": "blog/2025-05-21-databricks-dashboard-github-operation.html#databricks-の-git-連携機能とダッシュボードの相性",
    "href": "blog/2025-05-21-databricks-dashboard-github-operation.html#databricks-の-git-連携機能とダッシュボードの相性",
    "title": "Databricks AI/BI ダッシュボードの Git 連携の運用方法",
    "section": "2. Databricks の Git 連携機能とダッシュボードの相性",
    "text": "2. Databricks の Git 連携機能とダッシュボードの相性\nCommit & Push とブランチ切り替え以外の操作は結構厳しいです。\nJSON形式でウィジェット配置やSQLを管理しているのでコンフリクトが起きた場合の解消が難しいです。\nなのでそもそもコンフリクトの起きない運用をしておきたいです。"
  },
  {
    "objectID": "blog/2025-05-21-databricks-dashboard-github-operation.html#databricks-の考えるベストプラクティス",
    "href": "blog/2025-05-21-databricks-dashboard-github-operation.html#databricks-の考えるベストプラクティス",
    "title": "Databricks AI/BI ダッシュボードの Git 連携の運用方法",
    "section": "3. Databricks の考えるベストプラクティス",
    "text": "3. Databricks の考えるベストプラクティス\n\n自分の開発ブランチで作業するユーザーごとに、リモート Git リポジトリにマップされた個別の Databricks Git フォルダーを使用します 。\n\nhttps://docs.databricks.com/aws/ja/repos/git-operations-with-repos#ベスト-プラクティス-git-フォルダーでの共同作業\nそうは言うけれども実際は開発スキルを持たない方がダッシュボードを作成しますよね。\nこれを守るのは現実的ではないです。"
  },
  {
    "objectID": "blog/2025-05-21-databricks-dashboard-github-operation.html#実際の運用",
    "href": "blog/2025-05-21-databricks-dashboard-github-operation.html#実際の運用",
    "title": "Databricks AI/BI ダッシュボードの Git 連携の運用方法",
    "section": "4. 実際の運用",
    "text": "4. 実際の運用\n共有ワークスペース内に Git フォルダを作成して Git Flow で運用しています。\nワークスペースでは常時 develop ブランチ固定で時々 Commit & Push したり main にマージしたりします。\nmain への直接の Push 禁止という企業も多いと思いますので、その観点でも Git Flow は運用しやすそうです。\nこれくらいのゆるさで気楽に今後も運用していきます。\n\n\n\n\n\n%%{\n    init: {\n        'logLevel': 'debug',\n        'theme': 'base',\n        'themeVariables': {\n            'commitLabelFontSize': '14px',\n            'tagLabelFontSize': '12px'\n        }\n    }\n}%%\ngitGraph LR:\n    checkout main\n    commit\n    branch develop order: 4\n    checkout develop\n    commit\n    commit\n\n    branch release-1 order: 2\n    checkout release-1\n    commit\n\n    checkout main\n    merge release-1 tag: \"25.02\"\n\n    checkout develop\n    commit\n    commit\n\n    branch feature/new-master-data order: 5\n    checkout feature/new-master-data\n    commit\n    commit\n    checkout develop\n    merge feature/new-master-data\n    commit\n\n    branch release-2 order: 3\n    checkout release-2\n    commit\n\n    checkout main\n    merge release-2 tag: \"25.05\"\n\n    checkout develop\n    commit\n    commit\n    commit"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html",
    "href": "blog/2025-04-11-mcp-hands-on.html",
    "title": "MCP に入門した",
    "section": "",
    "text": "非エンジニアに Databricks でデータ分析をしてもらう"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html#直近-mcp-でやりたいこと",
    "href": "blog/2025-04-11-mcp-hands-on.html#直近-mcp-でやりたいこと",
    "title": "MCP に入門した",
    "section": "",
    "text": "非エンジニアに Databricks でデータ分析をしてもらう"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html#参考リンク",
    "href": "blog/2025-04-11-mcp-hands-on.html#参考リンク",
    "title": "MCP に入門した",
    "section": "2. 参考リンク",
    "text": "2. 参考リンク\n以下の順に触っていけばよいはず\n\nMCP入門\nMCP (Model Context Protocol) の仕組みを知りたい！ #Python - Qiita\nSiteMCP: 任意のサイトを丸ごとMCPサーバー化\n\nDatabricks 公式ドキュメントを投げつける用途で使いたい\n\nCursorにおけるDatabricks MCPサーバーの活用 #cursor - Qiita\nCursorでDatabricks Connect(とMCPサーバー)を使ってみる #cursor - Qiita"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html#mcp-入門",
    "href": "blog/2025-04-11-mcp-hands-on.html#mcp-入門",
    "title": "MCP に入門した",
    "section": "3. MCP 入門",
    "text": "3. MCP 入門\n全体を読みサンプルコードを実行してみる\n\n3.1. MCPクライアントを実行する\n(myenv3.12) [2025-04-10 22:50:25] -zsh [~/ghq/github.com/i9wa4/mcp-hands-on] (main) 9e297f01\n$ python mini_client.py\nProcessing request of type CallToolRequest\nTool result: [TextContent(type='text', text='Hello, MCP!', annotations=None)]"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html#mcp-model-context-protocol-の仕組みを知りたい",
    "href": "blog/2025-04-11-mcp-hands-on.html#mcp-model-context-protocol-の仕組みを知りたい",
    "title": "MCP に入門した",
    "section": "4. MCP (Model Context Protocol) の仕組みを知りたい！",
    "text": "4. MCP (Model Context Protocol) の仕組みを知りたい！\nちょこっと理解が深まった"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html#sitemcp",
    "href": "blog/2025-04-11-mcp-hands-on.html#sitemcp",
    "title": "MCP に入門した",
    "section": "5. SiteMCP",
    "text": "5. SiteMCP\n\n5.1. インストール\nnpx sitemcp"
  },
  {
    "objectID": "blog/2025-04-11-mcp-hands-on.html#cursor-を-mcp-クライアントとして使う",
    "href": "blog/2025-04-11-mcp-hands-on.html#cursor-を-mcp-クライアントとして使う",
    "title": "MCP に入門した",
    "section": "6. Cursor を MCP クライアントとして使う",
    "text": "6. Cursor を MCP クライアントとして使う\n{\n  \"mcpServers\": {\n    \"sitemcp\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"sitemcp@latest\",\n        \"https://i9wa4.github.io/\"\n      ]\n    }\n  }\n}\nMCPサーバ設定をこのように記載して Cursor の Agent でサイトのインデックス取得を命令していくことで内容に関する質問ができるようになりました。"
  },
  {
    "objectID": "blog/2024-03-26-setup-ds100knock.html",
    "href": "blog/2024-03-26-setup-ds100knock.html",
    "title": "データサイエンス100本ノックの実行環境構築 (WSL2)",
    "section": "",
    "text": "下記リポジトリを見てください。以上。\nhttps://github.com/i9wa4/wsl2-100knocks-preprocess"
  },
  {
    "objectID": "blog/2025-09-14-codex-cli-config-management.html",
    "href": "blog/2025-09-14-codex-cli-config-management.html",
    "title": "Codex CLI の設定ファイルを dotfiles で管理する",
    "section": "",
    "text": "Codex CLI を使い始めたのですが dotfiles 使いにとっては辛い部分があり距離を置いてしまっていました。\n今回力技で設定ファイルを dotfiles で管理する方法を思いついたので紹介します。"
  },
  {
    "objectID": "blog/2025-09-14-codex-cli-config-management.html#codex-cli-の設定ファイルについて",
    "href": "blog/2025-09-14-codex-cli-config-management.html#codex-cli-の設定ファイルについて",
    "title": "Codex CLI の設定ファイルを dotfiles で管理する",
    "section": "1. Codex CLI の設定ファイルについて",
    "text": "1. Codex CLI の設定ファイルについて\nCodex CLI の設定ファイルは ~/.config/codex/config.toml です。\n内容は例えば以下のような感じです。\n[projects.\"/Users/uma/ghq/github.com/i9wa4/dotfiles\"]\ntrust_level = \"trusted\""
  },
  {
    "objectID": "blog/2025-09-14-codex-cli-config-management.html#問題点",
    "href": "blog/2025-09-14-codex-cli-config-management.html#問題点",
    "title": "Codex CLI の設定ファイルを dotfiles で管理する",
    "section": "2. 問題点",
    "text": "2. 問題点\nconfig.toml にはフルパスが書かれるため複数のマシンで設定を管理するのが面倒です。\nかつどのプロジェクトを信頼するかの設定もマシンごとに異なることが多いので config.toml をそのまま dotfiles で管理するのはイマイチと言えます。"
  },
  {
    "objectID": "blog/2025-09-14-codex-cli-config-management.html#解決策",
    "href": "blog/2025-09-14-codex-cli-config-management.html#解決策",
    "title": "Codex CLI の設定ファイルを dotfiles で管理する",
    "section": "3. 解決策",
    "text": "3. 解決策\n共通設定だけ dotfiles の管理対象とし、プロジェクト別の設定はスクリプトで生成してしまうというものです。\nこれで困ることはほとんどないでしょう！\n\n3.1. config.toml の生成スクリプト\n共通設定を ~/.config/codex/config.common.toml に書いておき、プロジェクトごとの設定を自動生成して config.toml を生成させます。\n※リポジトリを ghq で管理していることを前提としています。\n\n\n~/.config/codex/generate_config.sh\n\n#!/usr/bin/env bash\nset -euo pipefail\n\nGHQ_BASE=\"${HOME}\"/ghq/github.com\nCOMMON=\"./config.common.toml\"\nOUTPUT=\"./config.toml\"\n\ncd \"$(dirname \"$0\")\"\n\n# Copy common settings\ncp -f \"${COMMON}\" \"${OUTPUT}\"\n\n# Add project-specific settings\nfind \"${GHQ_BASE}\" -maxdepth 3 -type d -name \".git\" 2&gt;/dev/null \\\n  | sed 's|\\.git$||' \\\n  | sort \\\n  | while read -r repo; do\n    [[ -z ${repo} ]] && continue\n    echo \"\n[projects.\\\"${repo}\\\"]\ntrust_level = \\\"trusted\\\"\"\n  done &gt;&gt;\"${OUTPUT}\"\n\necho \"Generated: ${OUTPUT}\""
  },
  {
    "objectID": "blog/2025-09-14-codex-cli-config-management.html#おわりに",
    "href": "blog/2025-09-14-codex-cli-config-management.html#おわりに",
    "title": "Codex CLI の設定ファイルを dotfiles で管理する",
    "section": "4. おわりに",
    "text": "4. おわりに\ndotfiles で管理しづらいから Codex CLI と距離を置いていたみなさん、これで今日から使えるようになりましたよ！"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html",
    "href": "blog/2024-10-25-thinking-of-my-career.html",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "",
    "text": "言ってしまえばポジティブな就職・転職理由を並べるといったところでしょうか。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#大学入学時",
    "href": "blog/2024-10-25-thinking-of-my-career.html#大学入学時",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "1. 大学入学時",
    "text": "1. 大学入学時\n特に何も考えていなかったのですが、自分が生意気すぎる生徒だったことからそんな生徒を受け持ちたくなくて教師だけは絶対にならないぞとは思っていました。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#就職活動時",
    "href": "blog/2024-10-25-thinking-of-my-career.html#就職活動時",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "2. 就職活動時",
    "text": "2. 就職活動時\n本当にぼんやりとIT系業務をやってみたいと思っていました (ただしスキルは大学の授業で少しだけC言語を書けるようになった程度)。\n当時業務系システムの求人が多かったのですがどうしても興味がもてず、実際にモノを動かせたり難しいことに挑戦したりとやりがいのありそうな仕事を選んでみました。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時",
    "href": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "3. 1回目の転職活動時",
    "text": "3. 1回目の転職活動時\n大学時代に住んでいた土地に戻りたくて転職することに。\nどうせならと経験を積めなかったプログラミングができてモノを動かすこともできる組み込みエンジニアを選びました。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時-1",
    "href": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時-1",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "4. 2回目の転職活動時",
    "text": "4. 2回目の転職活動時\nコロナ禍でテレワークを経験し、今後のライフステージを踏まえた上でテレワークに向いている職種に切り替えようと思っていました。\n面白そうだったのでデータサイエンティスト求人に応募してみたところ、景気の良い時期だったためか未経験ながら内定を頂きました。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時-2",
    "href": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時-2",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "5. 3回目の転職活動時",
    "text": "5. 3回目の転職活動時\n案件都合でデータエンジニア・アナリティクスエンジニア業務に取り組んでいました。\nこの頃はデータ基盤について割とブラックボックス状態でしたが、純粋に興味もありましたし、かつこのまま自分が偉くなったときにデータ基盤のことも知らないようでは責任をもってデータ業務の指揮ができないだろうなという危機感からデータ基盤業務を志すようになりました。\nまた、この辺りで本格的に vim-jp Slack で東京のエンジニアの空気感・レベル感を知り、エンジニアとしてのレベルや年収を上げていこうという発想が人生で初めて出てきたことも転職を後押ししてくれました。\n体感としてはこの辺りでようやく自分はITエンジニアであると思えるようになりました。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時-3",
    "href": "blog/2024-10-25-thinking-of-my-career.html#回目の転職活動時-3",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "6. 4回目の転職活動時",
    "text": "6. 4回目の転職活動時\nこれまでの経験から自分の仕事のモチベーションを上げる要因はどうやら以下の4点のようであると理解できました。\n\nチームで仕事ができること\n自分の仕事が目の前の社員の役に立っていると胸を張って言えること\n自分の仕事が会社の売上につながっていると胸を張って言えること\nできればエンドユーザーの満足度を高める方向の仕事であること\n\nこのような自分の特性を踏まえると、今後の先の長い職業人生で自分が充実感をもつには、技術的なエキスパートに向かっていくというより、マネジメントに取り組んだりビジネスサイドに寄せたりしてより抽象度の高い課題解決に向き合う立場を目指した方が良さそうだなと思うようになりました。\nそんなことを考えているところにお声がけいただいた会社で2024年11月から働くことにしました。\n決め手としては上に挙げた要素を全て満足できそう、将来的なキャリア構築の観点でもプラスになりそう、という点以外にも、事業領域が個人的な趣味と合致し会社の売上貢献に本気になれそうと思った点も意外と大きかったです。"
  },
  {
    "objectID": "blog/2024-10-25-thinking-of-my-career.html#おわりに",
    "href": "blog/2024-10-25-thinking-of-my-career.html#おわりに",
    "title": "キャリアについてぼんやり考えていたことを時系列順にまとめる",
    "section": "7. おわりに",
    "text": "7. おわりに\nこれ以上の詳しい話は飲みの場で！笑"
  },
  {
    "objectID": "blog/2025-04-20-lefthook.html",
    "href": "blog/2025-04-20-lefthook.html",
    "title": "lefthook 設定の供養",
    "section": "",
    "text": "GitHub Profile 用のリポジトリで lefthook を活用していましたが、不要になり削除しようと思うのでここに知見を残します。"
  },
  {
    "objectID": "blog/2025-04-20-lefthook.html#はじめに",
    "href": "blog/2025-04-20-lefthook.html#はじめに",
    "title": "lefthook 設定の供養",
    "section": "",
    "text": "GitHub Profile 用のリポジトリで lefthook を活用していましたが、不要になり削除しようと思うのでここに知見を残します。"
  },
  {
    "objectID": "blog/2025-04-20-lefthook.html#lefthook-とは",
    "href": "blog/2025-04-20-lefthook.html#lefthook-とは",
    "title": "lefthook 設定の供養",
    "section": "2. lefthook とは",
    "text": "2. lefthook とは\nevilmartians/lefthook: Fast and powerful Git hooks manager for any type of projects.\nlefthook は Git hooks の設定管理のツールです。\n使用方法は上記リポジトリの README を参照するとよいです。"
  },
  {
    "objectID": "blog/2025-04-20-lefthook.html#lefthook.yml",
    "href": "blog/2025-04-20-lefthook.html#lefthook.yml",
    "title": "lefthook 設定の供養",
    "section": "3. lefthook.yml",
    "text": "3. lefthook.yml\n設定ファイルは以下のように記述していました。\n\n\nlefthook.yml\n\n# EXAMPLE USAGE:\n#\n#   Refer for explanation to following link:\n#   https://github.com/evilmartians/lefthook/blob/master/docs/configuration.md\n#\n# pre-push:\n#   commands:\n#     packages-audit:\n#       tags: frontend security\n#       run: yarn audit\n#     gems-audit:\n#       tags: backend security\n#       run: bundle audit\n#\n# pre-commit:\n#   parallel: true\n#   commands:\n#     eslint:\n#       glob: \"*.{js,ts,jsx,tsx}\"\n#       run: yarn eslint {staged_files}\n#     rubocop:\n#       tags: backend style\n#       glob: \"*.rb\"\n#       exclude: '(^|/)(application|routes)\\.rb$'\n#       run: bundle exec rubocop --force-exclusion {all_files}\n#     govet:\n#       tags: backend style\n#       files: git ls-files -m\n#       glob: \"*.go\"\n#       run: go vet {files}\n#   scripts:\n#     \"hello.js\":\n#       runner: node\n#     \"any.go\":\n#       runner: go run\npost-commit:\n  piped: true\n  commands:\n    01-quarto-render:\n      priority: 1\n      glob:\n        - \"index.qmd\"\n      stage_fixed: false\n      run: |\n        set -e\n        . \"${PY_VENV_MYENV}\"/bin/activate\n        quarto render\n        cp ./_site/README.md .\n        git add ./README.md\n        git commit -m \"[lefthook] rendered index.qmd in README.md\" || exit 0\n\n\n3.1. 処理概要説明\nQuarto のレンダリングを実施させて、レンダリング結果から README.md を抜き出してコミットさせてます。\n\n\n3.2. 公式ドキュメントに書かれていないコツ\n処理実行順序の設定については以下のように決まっているようです。結構大事なことがソースコードのコメントに書かれてますね。\npriority を設定したくないケースもあると思いますので、その際の挙動ということで知っておいても損はないかと思います。\n\n\ninternal/lefthook/runner/runner.go\n\n// sortByPriority sorts the tags by preceding numbers if they occur and special priority if it is set.\n// If the names starts with letter the command name will be sorted alphabetically.\n// If there's a `priority` field defined for a command or script it will be used instead of alphanumeric sorting.\n//\n//  []string{\"1_command\", \"10command\", \"3 command\", \"command5\"} // -&gt; 1_command, 3 command, 10command, command5\n\nhttps://github.com/evilmartians/lefthook/blob/38390de0efee2627ccaaa562a823945218be3604/internal/lefthook/runner/runner.go#L637-L641"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html",
    "href": "blog/2025-04-07-bookmarks.html",
    "title": "個人的ブックマーク",
    "section": "",
    "text": "個人的な重要記事などをまとめておきます。"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#キャリア",
    "href": "blog/2025-04-07-bookmarks.html#キャリア",
    "title": "個人的ブックマーク",
    "section": "1. キャリア",
    "text": "1. キャリア\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-07-21\n\n\n\n【炬燵編】Kaigi on Railsのプロポーザルを評価するときに考えていること、求めていること - 感情的ドリル\n\n\n\n\n\n\n\n2025-03-31\n\n\n\nジュニアエンジニアからシニアエンジニアになるまでに自分がやっていたことまとめ - yasuhisa's blog\n\n\n\n\n\n\n\n2025-01-03\n\n\n\n休養も仕事と同じ本気度で取り組むと決めた - 自戒、点検、内省\n\n\n\n\n\n\n\n2024-12-27\n\n\n\nソフトウェアエンジニアの転職活動で準備したこと、そして使ったもの。｜中川 伸一 / shinyorke\n\n\n\n\n\n\n\n2024-12-20\n\n\n\n濃い職務経歴書(Curriculum Vitae/Resume)とは何か｜mtsuka\n\n\n\n\n\n\n\n2024-10-30\n\n\n\n「転職した方が年収上げやすい」は過去の話！それでも“年収アップ転職”をしたいエンジニアがやるべき三つの対策 - エンジニアtype | 転職type\n\n\n\n\n\n\n\n2024-10-23\n\n\n\n中堅の停滞期、ゆるやかな死。｜FromAtom\n\n\n\n\n\n\n\n2024-10-18\n\n\n\n40代後半で開発エンジニアからクラウドインフラエンジニアにキャリアチェンジし、生き残れる自信がようやく持てた話 - Speaker Deck\n\n\n\n\n\n\n\n2024-06-24\n\n\n\n課題を管理して実行して達成するための手順 - そーだいなるらくがき帳 | 最終更新日\n\n\n\n\n\n\n\n2024-03-07\n\n\n\n「クランボルツのキャリア論」が教えてくれる人生で大切なこと | 定番読書 | ダイヤモンド・オンライン\n\n\n\n\n\n\n\n2024-03-05\n\n\n\n行動をするときに「自分には向いてないかも」と悩む時間は必要ない - そーだいなるらくがき帳\n\n\n\n\n\n\n\n2023-12-09\n\n\n\n自らを強いエンジニアにするための3つの習慣 / I need to be myself, I can't be no one else - Speaker Deck\n\n\n\n\n\n\n\n2023-06-10\n\n\n\nキャリアに偶発性を呼び込み、複数の専門性を獲得するには？冒険的なキャリアデザインのためには、あえて軸をズラしてキャリア・トラベリングせよ｜安斎勇樹\n\n\n\n\n\n\n\n2021-11-25\n\n\n\nデータサイエンティストのインターン面談をして採用側が感じているズレの正体とは？ #Python - Qiita\n\n\n\n\n\n\n\n2015-05-07\n\n\n\nきっと何者にもなれない焦りを抱えながら、がむしゃらに前に進む - Konifar's WIP"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#テキストエディタ",
    "href": "blog/2025-04-07-bookmarks.html#テキストエディタ",
    "title": "個人的ブックマーク",
    "section": "2. テキストエディタ",
    "text": "2. テキストエディタ\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-04-14\n\n\n\nNeovimをはじめよう feat. mini.nvim\n\n\n\n\n\n\n\n2023-06-04\n\n\n\nddu.vimにちゃんと入門した話 | Zenn\n\n\n\n\n\n\n\n2022-05-05\n\n\n\nVim で折り返し行を簡単に移動できるサブモード・テクニック | Zenn"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#github-git",
    "href": "blog/2025-04-07-bookmarks.html#github-git",
    "title": "個人的ブックマーク",
    "section": "3. GitHub / Git",
    "text": "3. GitHub / Git\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2024-11-07\n\n\n\ngit rebaseの苦労を減らすための覚え書き | Atusy's blog\n\n\n\n\n\n\n\n2024-10-24\n\n\n\nなんとなくから脱却する GitHub Actionsグッドプラクティス11選 | gihyo.jp | gihyo.jp | 技術評論社\n\n\n\n\n\n\n\n2022-12-07\n\n\n\nGitHub Actions上でgit commitするときにgit userをどうするか #GitHubActions - Qiita\n\n\n\n\n\n\n\n2022-02-26\n\n\n\n2022-02-26開催 - merge / rebase 勉強会 - Speaker Deck\n\n\n\n\n\n\n\n2021-10-30\n\n\n\nGitHub Actions でデフォルトブランチにないワークフローの動作確認をする #GitHubActions - Qiita"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#データ分析",
    "href": "blog/2025-04-07-bookmarks.html#データ分析",
    "title": "個人的ブックマーク",
    "section": "4. データ分析",
    "text": "4. データ分析\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-08-31\n\n\n\nClaude CodeでBigQueryのクエリを実行する際のガードレールを設計する - yasuhisa's blog\n\n\n\n\n\n\n\n2025-04-14\n\n\n\n半年で社内BigQueryの月間利用者数を+300%にした話｜Yuto Shinahara\n\n\n\n\n\n\n\n2024-12-08\n\n\n\nデータ分析で用いるSQLクエリの設計方法 - 風音屋TechBlog"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#データエンジニアリング",
    "href": "blog/2025-04-07-bookmarks.html#データエンジニアリング",
    "title": "個人的ブックマーク",
    "section": "5. データエンジニアリング",
    "text": "5. データエンジニアリング\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-05-12\n\n\n\nmise + uv + dbt-coreで、ゼロから爆速でdbtの環境構築\n\n\n\n\n\n\n\n2025-05-08\n\n\n\nuvを使ったdbt Coreの導入手順\n\n\n\n\n\n\n\n2025-03-30\n\n\n\nディメンショナル・モデリング 勉強法 | Zenn\n\n\n\n\n\n\n\n2024-12-11\n\n\n\ndbt モデルを安全に更新！データ差分検出ツールの「table diff」の実装 | Zenn\n\n\n\n\n\n\n\n2024-12-11\n\n\n\ndbt-checkpointを活用したコード検証 #GitHubActions - Qiita\n\n\n\n\n\n\n\n2024-01-23\n\n\n\nディメンショナルモデリングに入門しよう！Snowflakeとdbt Cloudで「Building a Kimball dimensional model with dbt」をやってみた | DevelopersIO"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#機械学習",
    "href": "blog/2025-04-07-bookmarks.html#機械学習",
    "title": "個人的ブックマーク",
    "section": "6. 機械学習",
    "text": "6. 機械学習\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2024-12-02\n\n\n\nMLOpsパイプラインをSnowflakeのみで実現してみた - ENGINEERING BLOG ドコモ開発者ブログ\n\n\n\n\n\n\n\n2024-12-02\n\n\n\n機械学習基盤のアーキテクチャ特集 〜8社の設計意図と今後の展望〜 - Findy Tools\n\n\n\n\n\n\n\n2024-09-11\n\n\n\nRAGもファインチューニングも使わない 素朴なAIチャットボットを職場に導入した結果 - Speaker Deck\n\n\n\n\n\n\n\n2023-06-12\n\n\n\n協調フィルタリングとベクトル検索エンジンを利用した商品推薦精度改善の試み | メルカリエンジニアリング\n\n\n\n\n\n\n\n2015-12-21\n\n\n\nプロトタイプで終わらせない死の谷を超える機械学習プロジェクトの進め方 #MLCT4 | PPT"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#mcp-model-context-protocol",
    "href": "blog/2025-04-07-bookmarks.html#mcp-model-context-protocol",
    "title": "個人的ブックマーク",
    "section": "7. MCP (Model Context Protocol)",
    "text": "7. MCP (Model Context Protocol)\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-08-04\n\n\n\n開いているブラウザの内容を読める MCP サーバー - ぽ靴な缶\n\n\n\n\n\n\n\n2025-05-21\n\n\n\nGemini API ＆ SDK が MCP 対応したので試す（Node.js を利用）【Google I/O 2025】 #googleio - Qiita\n\n\n\n\n\n\n\n2025-05-11\n\n\n\nリモートサーバーで動かす Python MCP Server — Streamable HTTP 時代の始まり ~ uv / Docker / pytest を備えたミニマルテンプレート付き ~ #AI - Qiita\n\n\n\n\n\n\n\n2025-05-08\n\n\n\n比較的安全にMCPサーバを動かす - LIFULL Creators Blog\n\n\n\n\n\n\n\n2025-05-07\n\n\n\nMCP サーバにユーザ認証機能を実装する - フレクトのクラウドblog\n\n\n\n\n\n\n\n2025-05-02\n\n\n\nA Critical Look at MCP- Raz Blog\n\n\n\n\n\n\n\n2025-04-19\n\n\n\nリモートMCPがやってくる、そしてA2Aについて"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#ai",
    "href": "blog/2025-04-07-bookmarks.html#ai",
    "title": "個人的ブックマーク",
    "section": "8. AI",
    "text": "8. AI\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-06-02\n\n\n\n「AIエージェント疲れ」の原因と対策\n\n\n\n\n\n\n\n2024-01-01\n\n\n\nGemini Proと会話できるSlackBotをAWSサーバレス上に作る"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#docker",
    "href": "blog/2025-04-07-bookmarks.html#docker",
    "title": "個人的ブックマーク",
    "section": "9. Docker",
    "text": "9. Docker\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2099-12-31\n\n\n\nDockerfile reference | Docker Docs"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#ツール",
    "href": "blog/2025-04-07-bookmarks.html#ツール",
    "title": "個人的ブックマーク",
    "section": "10. ツール",
    "text": "10. ツール\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2099-12-31\n\n\n\nCard Validator | X Developers\n\n\n\n\n\n\n\n2099-12-31\n\n\n\nComfy | バツグンに探しやすい物件検索 | 全国の賃貸を検索\n\n\n\n\n\n\n\n2099-12-31\n\n\n\nLGTMoon - Simplest LGTM Image Generator\n\n\n\n\n\n\n\n2099-12-31\n\n\n\nMEGAMOJI - カスタム絵文字メーカー\n\n\n\n\n\n\n\n2025-08-12\n\n\n\n終活は、まず預貯金口座の付番申請をしよう。\n\n\n\n\n\n\n\n2025-01-05\n\n\n\nXやSlackで大きめのOGP画像を表示する設定と注意点"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#チームマネジメント",
    "href": "blog/2025-04-07-bookmarks.html#チームマネジメント",
    "title": "個人的ブックマーク",
    "section": "11. チームマネジメント",
    "text": "11. チームマネジメント\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2024-10-30\n\n\n\n役割をお願いする時に伝えていること - Konifar's ZATSU\n\n\n\n\n\n\n\n2021-02-08\n\n\n\n今日のリモート雑談テーマを決める魔法のスプレッドシートを運用している話 - エムスリーテックブログ\n\n\n\n\n\n\n\n2016-02-22\n\n\n\n失敗から学ぶ データ分析グループの チームマネジメント変遷 （デブサミ2016） #devsumi | PPT"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#インフラストラクチャ",
    "href": "blog/2025-04-07-bookmarks.html#インフラストラクチャ",
    "title": "個人的ブックマーク",
    "section": "12. インフラストラクチャ",
    "text": "12. インフラストラクチャ\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-08-26\n\n\n\nなぜ複数のVPCをつなぐ必要があるのか？ - Speaker Deck\n\n\n\n\n\n\n\n2025-04-24\n\n\n\n丁度ええ! ロギング - kawasima\n\n\n\n\n\n\n\n2024-10-21\n\n\n\nGithub Actions で実現する Terraform plan, apply 自動化\n\n\n\n\n\n\n\n2024-10-09\n\n\n\nAWSのOpenSearch Serviceで ベクトル検索を実現するまでの流れ | by Akihiro Wakamatsu | スタディスト Tech Blog\n\n\n\n\n\n\n\n2023-11-14\n\n\n\nロギング設計大全 - kawasima"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#テスト",
    "href": "blog/2025-04-07-bookmarks.html#テスト",
    "title": "個人的ブックマーク",
    "section": "13. テスト",
    "text": "13. テスト\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2025-08-29\n\n\n\nAIエージェント時代のテスト駆動開発（TDD） - Agile Journey\n\n\n\n\n\n\n\n2024-12-09\n\n\n\nデータ精度100%を目指す！dbt test徹底活用ガイド - ENGINEERING BLOG ドコモ開発者ブログ"
  },
  {
    "objectID": "blog/2025-04-07-bookmarks.html#書籍学習リソース",
    "href": "blog/2025-04-07-bookmarks.html#書籍学習リソース",
    "title": "個人的ブックマーク",
    "section": "14. 書籍・学習リソース",
    "text": "14. 書籍・学習リソース\n\n\n\n\n\n\n\n\n\nDate\n\n\n\nWebsite\n\n\n\n\n\n\n\n\n\n\n\n2024-12-06\n\n\n\n私たちのR\n\n\n\n\n\n\n\n2024-10-26\n\n\n\n技術書の電子書籍を PDF/EPUB で配信しているサイトまとめ #PDF - Qiita\n\n\n\n\n\n\n\n2018-11-01\n\n\n\n『機械学習のエッセンス』はゼロからガチで機械学習を生業にしたい人が「いの一番に」読むべき一冊 - 渋谷駅前で働くデータサイエンティストのブログ"
  },
  {
    "objectID": "blog/2024-05-04-get-git-branch-name.vim.html",
    "href": "blog/2024-05-04-get-git-branch-name.vim.html",
    "title": "Vim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみた",
    "section": "",
    "text": "私の Vim 設定では操作中のリポジトリのブランチ名を tabline に表示させていて、これは bash-completion に依存した実装となっています。この依存をなくし、ついでに依存をゼロにしようと思ったので Vim script でプラグインを書いてみようと思いました。\n.git ディレクトリを覗けば現在のブランチ名が分かるらしいことは知っていて、以下のリポジトリが自分のやりたいことであるということも知っている状態です。\nhttps://github.com/itchyny/vim-gitbranch\nGemini がどれくらい使えるか試してみたくて、上記リポジトリは見ずに進めてみます。"
  },
  {
    "objectID": "blog/2024-05-04-get-git-branch-name.vim.html#経緯",
    "href": "blog/2024-05-04-get-git-branch-name.vim.html#経緯",
    "title": "Vim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみた",
    "section": "",
    "text": "私の Vim 設定では操作中のリポジトリのブランチ名を tabline に表示させていて、これは bash-completion に依存した実装となっています。この依存をなくし、ついでに依存をゼロにしようと思ったので Vim script でプラグインを書いてみようと思いました。\n.git ディレクトリを覗けば現在のブランチ名が分かるらしいことは知っていて、以下のリポジトリが自分のやりたいことであるということも知っている状態です。\nhttps://github.com/itchyny/vim-gitbranch\nGemini がどれくらい使えるか試してみたくて、上記リポジトリは見ずに進めてみます。"
  },
  {
    "objectID": "blog/2024-05-04-get-git-branch-name.vim.html#gemini-との開発過程",
    "href": "blog/2024-05-04-get-git-branch-name.vim.html#gemini-との開発過程",
    "title": "Vim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみた",
    "section": "2. Gemini との開発過程",
    "text": "2. Gemini との開発過程\nGemini とのやりとりを書き残しておきます。\n\n2.1. .git 探索関数作成\n\n2.1.1. 質問\nVim script で以下の関数を作成してほしいです。\n- あるディレクトリのパスを引数にとり、そこから順に上の階層をたどって、.git ディレクトリがあればそこで探索をやめて.gitディレクトリのパスを戻り値とする。見つからなければ空文字列を返す。\n\n\n2.1.2. 回答\nVim script で .git ディレクトリを探す関数\n\n以下の Vim script は、引数として渡されたディレクトリパスから順に上の階層をたどり、.git ディレクトリを見つけたらそのパスを返します。見つからなければ空文字列を返します。\n\nfunction! FindGitDir(dir)\n  \" 引数がない場合はカレントディレクトリを代入 \"\n  if (empty(a:dir))\n    let dir = expand('%:p')\n  endif\n\n  \" ループフラグを初期化 \"\n  let found = 0\n\n  \" 順に上の階層をたどる \"\n  while (!found && !empty(dir) && dir != '/')\n    \" .git ディレクトリが存在するか確認 \"\n    if (isdirectory(dir . '/.git'))\n      let found = 1\n      let gitdir = dir . '/.git'\n    endif\n\n    \" 上の階層へ移動 \"\n    let dir = expand(dirname(dir))\n  endwhile\n\n  \" 結果を返す \"\n  if (found)\n    return gitdir\n  else\n    return ''\n  endif\nendfunction\n\n\n\n2.2. ブランチ名取得関数作成\n\n2.2.1. 質問\nVim script で以下の関数を作成してほしいです。\n- .gitディレクトリのパスを引数にとり、.gitディレクトリを除いて現在のブランチ名を取得し、それを戻り値とする。\n\n\n2.2.2. 回答\n以下の Vim script は、.git ディレクトリのパスを引数にとり、.git ディレクトリを除いた現在のブランチ名を取得し、それを戻り値とします。\n\nfunction! GetCurrentBranch(gitdir)\n  \" 引数が空の場合、エラーを返す \"\n  if (empty(a:gitdir))\n    error('引数が空です')\n  endif\n\n  \" カレントブランチ名の取得 \"\n  let branch = system('git --git-dir=\"' . a:gitdir . '\" rev-parse --abbrev-ref HEAD')\n\n  \" .git ディレクトリを除いたブランチ名を返す \"\n  return substitute(branch, a:gitdir . '/', '', 'g')\nendfunction\n\n\n2.2.3. 質問\nsystem() を使わず、gitコマンドを使わずに実現させてほしいです。\n\n\n2.2.4. 回答\nVim script で system() や git コマンドを使わずに現在のブランチ名を取得するには、以下の方法があります。\n\n\n1. :echo %b コマンドを使用する\n\nこの方法は、最も簡単でシンプルな方法です。%b 変数は、現在選択されているバッファのブランチ名を表します。\n\n\" 現在のブランチ名をエコーする \"\n:echo %b\n\n\n2. expand('%:p:h') を使って .git/HEAD ファイルを読み込む\n\nこの方法は、より汎用的で、カレントバッファ以外のブランチ名を取得する場合にも使用できます。.git/HEAD ファイルには、現在のブランチ名が格納されています。\n\n\" .git/HEAD ファイルのパスを取得 \"\nlet headfile = expand('%:p:h') . '/.git/HEAD'\n\n\" HEAD ファイルの内容を読み込む \"\nlet headcontent = readfile(headfile)\n\n\" ブランチ名を抽出する \"\nlet branch = match(headcontent, 'ref: refs/heads/(.+)')\n\n\" 結果を確認 \"\necho \"現在のブランチ: \" . branch\n\n\n3. git log の出力を解析する\n\nこの方法は、より詳細なブランチ情報 (コミットハッシュなど) を取得する場合に役立ちます。\nVim Script\n\n\" git log の出力をバッファに読み込む \"\n:redir &gt; /dev/null git log -1\n\n\" ブランチ名を抽出する \"\nlet branch = match(v:buffer['[0]'], 'ref: refs/heads/(.+)')\n\n\" 結果を確認 \"\necho \"現在のブランチ: \" . branch\n回答1が嘘すぎてびっくり。今回は回答2がよさそう。\nこの時点で下記リポジトリを確認してみたところ回答2と同様の手法でブランチ名を取得しているようでした。\nhttps://github.com/itchyny/vim-gitbranch\nここまで分かればあとは動作を確認しながら書けそうです。"
  },
  {
    "objectID": "blog/2024-05-04-get-git-branch-name.vim.html#完成品",
    "href": "blog/2024-05-04-get-git-branch-name.vim.html#完成品",
    "title": "Vim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみた",
    "section": "3. 完成品",
    "text": "3. 完成品\nGemini と考えたコードが跡形もなくなっている。。なぜ。。\nTODO: 繰り返し呼ばれることを念頭に処理を軽くしたい\nhttps://github.com/i9wa4/get-git-branch-name.vim"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-prompt-for-devin.html",
    "href": "blog/2025-04-05-weekly-report-prompt-for-devin.html",
    "title": "Devin 週報作成用プロンプト",
    "section": "",
    "text": "親記事は以下です。\nDevin に週報を書いてもらった"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-prompt-for-devin.html#人間への補足",
    "href": "blog/2025-04-05-weekly-report-prompt-for-devin.html#人間への補足",
    "title": "Devin 週報作成用プロンプト",
    "section": "1. 人間への補足",
    "text": "1. 人間への補足\nDevin にこのプロンプトを見せて、集計開始日と集計終了日を教えてあげてください。\n指示例は以下のようになります。\n以下の Markdown の指示に従って情報収集を行った上で GitHub issue を作成してください。\n&lt;プロンプトとなるMarkdownのURL&gt;\n\n集計開始日：2025/03/12\n集計終了日：2025/03/18"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-prompt-for-devin.html#github-の情報収集方法",
    "href": "blog/2025-04-05-weekly-report-prompt-for-devin.html#github-の情報収集方法",
    "title": "Devin 週報作成用プロンプト",
    "section": "2. GitHub の情報収集方法",
    "text": "2. GitHub の情報収集方法\n\nテンプレートに記載した対象リポジトリの issue, pull request, そしてそれらの comment を取得してください。\nissue や pull request を GitHub CLI で取得する場合は --state all オプションを使用して Closed や Merged になっているものも忘れずに取得してください。\n対象リポジトリにアクセスできない場合は、そのリポジトリは集計対象外としてください。\n対象メンバー毎に活動をまとめる際は対象者が assignee でない issue や pull request は含めないでください。"
  },
  {
    "objectID": "blog/2025-04-05-weekly-report-prompt-for-devin.html#issue-テンプレート",
    "href": "blog/2025-04-05-weekly-report-prompt-for-devin.html#issue-テンプレート",
    "title": "Devin 週報作成用プロンプト",
    "section": "3. issue テンプレート",
    "text": "3. issue テンプレート\n\n補足コメントは &lt;!-- --&gt; で与えているので参照してください。\nただし issue 作成時には補足コメントは記載しないでください。\n\n\n3.1. Title\n集計開始日と集計終了日を YYYY/MM/DD 形式で記載してください。\n[Devin] チーム週報 (YYYY/MM/DD-YYYY/MM/DD)\n\n\n3.2. Assignee\n\n@i9wa4\n\n\n\n3.3. Description\n## 1. 期間\n\n&lt;!-- 集計開始日と集計終了日を記載してください。 --&gt;\n&lt;!-- (aaa) は曜日です。(月) や (火) のように記載してください。 --&gt;\n\nYYYY/MM/DD(aaa)～YYYY/MM/DD(aaa)\n\n## 2. 対象リポジトリ\n\n- GitHub リポジトリの URL\n\n## 3. 対象メンバー (GitHub ユーザー名)\n\n- `@i9wa4`\n\n## 4. 概要\n\n### 4.1. `@i9wa4`\n\n&lt;!-- 当該メンバーの大きめの活動をしたプロジェクトから順にやったことの概要を4文程度に要約して紹介してください。 --&gt;\n\n### 4.2. 他メンバーはこのような記述にする\n\n&lt;!-- 集計期間に活動があれば上記と同様の形式で記入してください。 --&gt;\n\n\n3.4. Comment (1)\n## 5. 詳細\n\n### 5.1. `@i9wa4`\n\n&lt;!-- 当該メンバーの活動詳細を以下の形式で列挙してください。 --&gt;\n&lt;!-- - [status (Open/Closed/Merged)] [category (issue/pull request)] [issue/pull request title #number](URL) --&gt;\n&lt;!-- 列挙したあとアルファベット順にソートしてください。 --&gt;\n\n- [Closed] [issue] [issue title #189](issue url)\n- [Merged] [pull request] [pull request title #124](pull request url)\n- [Open] [issue] [issue #106](issue url)\n\n### 5.2. 他メンバーはこのような記述にする\n\n&lt;!-- 集計期間に活動があれば上記と同様の形式で記入してください。 --&gt;\n\n\n3.5. Comment (2)\n## 6. Devin への指示内容\n\n&lt;!-- Devin へ指示した内容をそのまま引用符付きで記載してください。 --&gt;\n&lt;!-- 例 --&gt;\n\n&gt; 以下の Markdown の指示に従って GitHub issue を作成してください。\n&gt; &lt;プロンプトとなるMarkdownのURL&gt;\n&gt;\n&gt; 集計開始日：2025/03/12\n&gt; 集計終了日：2025/03/18"
  },
  {
    "objectID": "blog/2024-06-17-setup-mac.html",
    "href": "blog/2024-06-17-setup-mac.html",
    "title": "Mac 環境構築手順",
    "section": "",
    "text": "私の Mac 環境構築手順をまとめておきます。"
  },
  {
    "objectID": "blog/2024-06-17-setup-mac.html#dotfiles-導入",
    "href": "blog/2024-06-17-setup-mac.html#dotfiles-導入",
    "title": "Mac 環境構築手順",
    "section": "1. dotfiles 導入",
    "text": "1. dotfiles 導入\ncf. https://github.com/i9wa4/dotfiles"
  },
  {
    "objectID": "blog/2024-06-17-setup-mac.html#システム設定",
    "href": "blog/2024-06-17-setup-mac.html#システム設定",
    "title": "Mac 環境構築手順",
    "section": "2. システム設定",
    "text": "2. システム設定\n\nバッテリー\n\nバッテリーの状態\n\nバッテリー充電の最適化\n\n\nコントロールセンター\n\nBluetooth\n\nメニューバーに表示\n\nバッテリー\n\nメニューバーに表示 ON\n割合 (%) を表示 ON\n\nメニューバーのみ\n\n時計\n\n日付を表示 常に\n曜日を表示 ON\n秒を表示 ON\n\nメニューバーを自動的に表示/非表示 しない\n\n\nディスプレイ\n\nTrue Tone OFF (内蔵ディスプレイ使用時に出現する設定項目)\nNight Shift\n\nカスタム 5:00-4:59\n色温度 中央と右端の間\n\n\nデスクトップと Dock\n\nDock\n\n画面上の位置 任意\nDock を自動的に表示/非表示 任意\nアプリの提案と最近使用したアプリを Dock に表示 OFF\n\nデスクトップとステージマネージャー\n\n壁紙をクリックしてデスクトップを表示\n\nステージマネージャー使用時のみ\n\n\nウィジェット\n\nデフォルトの Web ブラウザ\n\nGoogle Chrome\n\n\n\n通知\n\n通知センター OFF\nアプリケーションの通知 システム系以外は OFF\n\nロック画面\n\n時間設定 30分\n\nプライバシーとセキュリティ\n\nフルディスクアクセス\n\nターミナル\n\n画面収録とシステムオーディオ録音\n\nSlack\nWeb ブラウザ\nZoom\n\n\nユーザとグループ\n\n管理者\n\nキーボード\n\nキーボードの輝度 最小\nキーボードショートカット\n\n修飾キー\n\n内蔵キーボード\n\nCaps Lock -&gt; Control\n\n\n\n入力ソース\n\nすべての入力ソース\n\n英字入力中にスペルを自動変換 OFF\n文頭を自動的に大文字にする OFF\nインライン予測テキストを表示 OFF\nスペースバーを2回押してピリオドを入力 OFF\nスマート引用符とスマートダッシュを使用 OFF\n二重引用符 “abc”\n一重引用符 ‘abc’\n\n日本語 - ローマ字入力\n\nライフ変換 OFF\nタイプミスを修正\n\n\n音声入力 OFF\n\nマウス\n\nナチュラルなスクロール OFF\n\nトラックパッド\n\nスクロールとズーム\n\nナチュラルなスクロール OFF"
  },
  {
    "objectID": "blog/2024-06-17-setup-mac.html#その他",
    "href": "blog/2024-06-17-setup-mac.html#その他",
    "title": "Mac 環境構築手順",
    "section": "3. その他",
    "text": "3. その他\n\nFinder\n\n表示\n\nパスバーを表示\n\nよく使う項目にユーザーホームをドラッグ&ドロップで追加する\n\nDocker Desktop\n\nSettings\n\nGeneral\n\nStart Docker Desktop when you sign in to your computer\n\n\n\nRectangle\n\nログイン時に起動 ON\nアップデートを自動的に確認 ON"
  },
  {
    "objectID": "blog/2024-06-17-setup-mac.html#おまけ-ショートカット集",
    "href": "blog/2024-06-17-setup-mac.html#おまけ-ショートカット集",
    "title": "Mac 環境構築手順",
    "section": "4. (おまけ) ショートカット集",
    "text": "4. (おまけ) ショートカット集\n\n\n\nカテゴリ\nショートカット\n説明\n\n\n\n\nウインドウ操作\nCommand + Tab\nアプリケーション切り替え\n\n\nウインドウ操作\nCommand + @\n同一アプリケーションの切り替え\n\n\nその他\nCommad + Q\nFinder 終了\n\n\nその他\nCommand + Ctrl + Q\nロック"
  },
  {
    "objectID": "blog/2025-08-23-diary.html",
    "href": "blog/2025-08-23-diary.html",
    "title": "2025-08-23 日誌",
    "section": "",
    "text": "毎日書いているような顔してますが初めての日誌です"
  },
  {
    "objectID": "blog/2025-08-23-diary.html#最近考えていること",
    "href": "blog/2025-08-23-diary.html#最近考えていること",
    "title": "2025-08-23 日誌",
    "section": "1. 最近考えていること",
    "text": "1. 最近考えていること\n色々と忙しくなり上手く回ってない感があり自己肯定感が下がっています。\nが、下記のように最近新しく始めたことがちゃんと結構あって案外悪くないかも！"
  },
  {
    "objectID": "blog/2025-08-23-diary.html#最近新しく始めたこと",
    "href": "blog/2025-08-23-diary.html#最近新しく始めたこと",
    "title": "2025-08-23 日誌",
    "section": "2. 最近新しく始めたこと",
    "text": "2. 最近新しく始めたこと\n刺激を求めると色々好転する感覚があるので元々保守的でインドアですが頑張ってます。\nここ1-2ヶ月で新しく始めたこと\n\n馴染みのない技術要素 (CloudFormation, Datadog, AWS のネットワーク周り) に触れてみた\nチームメンバーへのタスク切り出し・進捗管理を本格的にやっている\n社内の飲みたい人集めて飲み会開いた\n他部署の定例に勝手に毎週参加して居座る\n半分仕事だけどデータ界隈の交流を増やしてみた\nエンジニア友達 @YKirin0418 と初対面 & サシ飲みした"
  },
  {
    "objectID": "blog/2025-08-23-diary.html#副業ちゃんとやれてそう",
    "href": "blog/2025-08-23-diary.html#副業ちゃんとやれてそう",
    "title": "2025-08-23 日誌",
    "section": "3. 副業ちゃんとやれてそう",
    "text": "3. 副業ちゃんとやれてそう\n6月から PIVOT の業務委託を始めていました。\nこれが副業デビューです。\n最初はドメイン知識や開発環境面で苦戦していましたが徐々にシュッっと貢献する動きができるようになってきました！\n自分のもつ経験やスキルを積極的に提供していければと思っています。\nやっぱり自分の好きなプロダクトに関わるのは楽しいです。"
  },
  {
    "objectID": "blog/2025-08-23-diary.html#直近やってみたいこと",
    "href": "blog/2025-08-23-diary.html#直近やってみたいこと",
    "title": "2025-08-23 日誌",
    "section": "4. 直近やってみたいこと",
    "text": "4. 直近やってみたいこと\nやる時間は無いだろうなと思いつつも書くだけ書いておきます。\nUbuntu に Docker Compose で Minecraft 統合版サーバーを立てているのですが、Java 版に切り替えて GeyserMC 対応をしたい！"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "",
    "text": "GitHub でブログやスライドを管理したい方にオススメな Quarto による GitHub Pages 公開手順を紹介していきます。\nスライド管理に興味がない方は適宜スライドに関する記述を無視しながら読み進めてください。\nここでは以下のドキュメントの手順をなぞりつつ、ブログ記事とスライドを管理するためのプロジェクト構成を導入します。\nQuarto – GitHub Pages"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#想定する読者",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#想定する読者",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "1. 想定する読者",
    "text": "1. 想定する読者\n\nPython の環境構築ができている方\nGit/GitHub 操作の説明がなくても問題ない方"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#事前準備",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#事前準備",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "2. 事前準備",
    "text": "2. 事前準備\n\n2.1. Quarto のインストール\nまずは Quarto をインストールしておきましょう。\n$ pip install quarto-cli\nなぜか公式ドキュメントではこのインストール方法は説明されていなかったのですが、これが一番簡単です。同じ疑問をもった方が以下で質問していました。\nInstalling quarto-cli via pip · quarto-dev/quarto-cli · Discussion #8597\n\n\n2.2. GitHub リポジトリ作成\n任意の名前でリポジトリを作成しましょう。\n私は GitHub リポジトリ https://github.com/i9wa4/i9wa4.github.io を作成していて公開 URL は https://i9wa4.github.io になります。\nここではデモ用に https://github.com/i9wa4/quarto-page というリポジトリを作成してみます。こちらの公開 URL は https://i9wa4.github.io/quarto-page になります。\n特にこだわりがなければリポジトリ名は username.github.io でよいでしょう。"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#基本構造を整える",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#基本構造を整える",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "3. 基本構造を整える",
    "text": "3. 基本構造を整える\n作成したリポジトリをクローンして以下のファイルを作成します。\n\n_quarto.yml\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: docs\n\n.nojelyll\n空ファイルなので下記コマンドで作成します。\n$ touch .nojekyll\n.gitignore\n\n\n.gitignore\n\n/.quarto/\n/docs/\n\nindex.qmd\n\n\nindex.qmd\n\n---\ntitle: トップページ index.qmd\n---\n\n本文\n\n\n作成できたら main ブランチに push しておきましょう。"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#初回デプロイを行う",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#初回デプロイを行う",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "4. 初回デプロイを行う",
    "text": "4. 初回デプロイを行う\n初回はローカル環境からデプロイを実行します。\n指示に従って yes と入力すると gh-pages ブランチが作成されて初回デプロイが完了します。\n$ quarto publish gh-pages\n? Publish site to ssh://git@github.com/i9wa4/quarto-page using gh-pages? (Y/n) › Yes"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#回目以降のデプロイを自動化する",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#回目以降のデプロイを自動化する",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "5. 2回目以降のデプロイを自動化する",
    "text": "5. 2回目以降のデプロイを自動化する\n2回目以降のデプロイは以下のファイルを作成しておくことで GitHub Actions に任せることができます。\n\n\n.github/workflows/publish.yml\n\non:\n  workflow_dispatch:\n  push:\n    branches: main\n\nname: Quarto Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#ブログ記事とスライドのための構造を整える",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#ブログ記事とスライドのための構造を整える",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "6. ブログ記事とスライドのための構造を整える",
    "text": "6. ブログ記事とスライドのための構造を整える\n以下の内容を push すると https://i9wa4.github.io/quarto-page が完成します。\n\nindex.qmd\n\n\nindex.qmd\n\n---\ntitle: トップページ index.qmd\nlisting:  # トップページにリスト表示させたくない場合は listing の設定は不要\n  contents:\n    - \"blog\"\n    - \"slides\"  # トップページにスライドを表示させる場合\n  exclude:\n    filename: \"index.qmd\"\n  sort:\n    - \"date desc\"\n---\n\n本文\n\n- [ブログ記事一覧](./blog)\n- [スライド一覧](./slides)\n\n## ブログとスライドの新着一覧\n\nブログやスライドなどディレクトリを分けている記事をまとめてリスト表示することができます。\n\n\n\n6.1. ブログ\n\nblog/index.qmd\n\n\nblog/index.qmd\n\n---\ntitle: ブログ記事一覧\nlisting:\n  contents:\n    - \".\"\n  sort:\n    - \"date desc\"\n---\n\nblog/2024-08-25-test1.qmd\n\n\nblog/2024-08-25-test1.qmd\n\n---\ntitle: test1\ndate: 2024-08-25\n---\n\n1行目\n\nファイル名の先頭に日付をつけておくと管理しやすいですが必須ではありません。\n\nblog/test2.qmd\n\n\nblog/test2.qmd\n\n---\ntitle: test2\ndate: 2024-08-26\n---\n\nここが1行目\n\nファイル名の先頭に日付をつけておくと管理しやすいですが必須ではありません。\n\n\n\n\n6.2. スライド\n\nslides/index.qmd\n\n\nslides/index.qmd\n\n---\ntitle: スライド一覧\nlisting:\n  contents:\n    - \".\"\n  sort:\n    - \"date desc\"\n---\n\nslides/test1-slide.qmd\n\n\nslides/test1-slide.qmd\n\n---\ntitle: \"test1-slide タイトル\"\nauthor: i9wa4\ndate: 2024-08-25\nformat:\n  revealjs:\n    slide-level: 2\n    slide-number: true\n---\n\n本文\n\n## サブタイトル1\n\n本文\n\n## サブタイトル2\n\n本文\n\nslides/test2-slide.qmd\n\n\nslides/test2-slide.qmd\n\n---\ntitle: \"test2-slide タイトル\"\nauthor: i9wa4\ndate: 2024-08-25\nformat:\n  revealjs:\n    slide-level: 2\n    slide-number: true\n---\n\n本文\n\n## サブタイトル1\n\n本文\n\n## サブタイトル2\n\n本文"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#プレビューを確認しつつ編集する",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#プレビューを確認しつつ編集する",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "7. プレビューを確認しつつ編集する",
    "text": "7. プレビューを確認しつつ編集する\nプレビューを Web ブラウザで確認しながら編集が可能です。\n$ quarto preview\n編集内容がリアルタイムに反映されるので執筆体験がとても良いです！\n[2024-08-26 追記] プロジェクト構成によっては Firefox 以外の Web ブラウザでうまくプレビューできない事象が発生している模様。\nQuarto preview only loading homepage in Firefox · Issue #3045 · quarto-dev/quarto-cli\n遭遇した場合は以下のコマンドで docs/ 配下に都度 html ファイルを作成する、もしくは Firefox を使う、で対処しましょう。\n$ quarto render"
  },
  {
    "objectID": "blog/2024-08-25-publishing-github-pages-with-quarto.html#おわりに",
    "href": "blog/2024-08-25-publishing-github-pages-with-quarto.html#おわりに",
    "title": "Markdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する",
    "section": "8. おわりに",
    "text": "8. おわりに\nもっと色々といじっていきたい方は以下を参考にしてみるとよいでしょう。\n\nQuarto 公式\n\nページ https://quarto.org\nリポジトリ https://github.com/quarto-dev/quarto-web\n\ni9wa4 の GitHub Pages\n\nページ https://i9wa4.github.io\nリポジトリ https://github.com/i9wa4/i9wa4.github.io"
  },
  {
    "objectID": "slides/2024-02-04-sapporo.vim.html#自己紹介",
    "href": "slides/2024-02-04-sapporo.vim.html#自己紹介",
    "title": "Sapporo.vim 自己紹介",
    "section": "1. 自己紹介",
    "text": "1. 自己紹介\n\n【HN】 i9wa4 (いくわよ)\n【札幌在住歴】 9年\n【仕事】 直近1.5年は AWS 機械学習基盤の業務\n【最近の Vim 活】\n\nプラグインマネージャー dein.vim から dpp.vim へ移行\nvim-lsp 導入\nefm-langserver 導入"
  },
  {
    "objectID": "slides/2024-02-04-sapporo.vim.html#本日のタスク",
    "href": "slides/2024-02-04-sapporo.vim.html#本日のタスク",
    "title": "Sapporo.vim 自己紹介",
    "section": "2. 本日のタスク",
    "text": "2. 本日のタスク\n\nDocker / Kubernetes の入門書を読む"
  },
  {
    "objectID": "slides/2024-02-04-sapporo.vim.html#結果",
    "href": "slides/2024-02-04-sapporo.vim.html#結果",
    "title": "Sapporo.vim 自己紹介",
    "section": "3. 結果",
    "text": "3. 結果\n\n何となく compose.yml と Dockerfile を触ってた状態だったので頭の中を整理できたかも\nちょっと古い本だったので Compose Spec について追加で調べた\n\ndocker-compose (旧) と docker compose (新) があり検索すると前者の情報の方が多い……\n\nKubernetes (Minikube) の章は読めてないのでは帰宅後に"
  },
  {
    "objectID": "slides/2025-08-08-midas-ai.html#はじめに",
    "href": "slides/2025-08-08-midas-ai.html#はじめに",
    "title": "Claude Code データ業務活用",
    "section": "1. はじめに",
    "text": "1. はじめに"
  },
  {
    "objectID": "slides/2025-08-08-midas-ai.html#claude-code-を組み込んだ開発環境",
    "href": "slides/2025-08-08-midas-ai.html#claude-code-を組み込んだ開発環境",
    "title": "Claude Code データ業務活用",
    "section": "2. Claude Code を組み込んだ開発環境",
    "text": "2. Claude Code を組み込んだ開発環境"
  },
  {
    "objectID": "slides/2025-08-08-midas-ai.html#vibe-data-science",
    "href": "slides/2025-08-08-midas-ai.html#vibe-data-science",
    "title": "Claude Code データ業務活用",
    "section": "3. Vibe Data Science",
    "text": "3. Vibe Data Science"
  },
  {
    "objectID": "slides/2025-08-08-midas-ai.html#雑多なタスクをやらせてみる",
    "href": "slides/2025-08-08-midas-ai.html#雑多なタスクをやらせてみる",
    "title": "Claude Code データ業務活用",
    "section": "4. 雑多なタスクをやらせてみる",
    "text": "4. 雑多なタスクをやらせてみる"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Slides",
    "section": "",
    "text": "Claude Code データ業務活用\n\n\n\nslides\n\ngenda\n\n\n\n[登壇資料] 2025-08-08 ミダス企業群生成AI横断勉強会\n\n\n\n2025-08-08\n\n\n\n\n\n\n\n\n\n\n\n\n\n自己紹介\n\n\n\nslides\n\npivot\n\n\n\n2025-06-03 自己紹介 @PIVOT\n\n\n\n2025-06-03\n\n\n\n\n\n\n\n\n\n\n\n\n\nCursorのおすすめ設定 & Cursorにデータ分析を任せる方法\n\n\n\nslides\n\ngenda\n\n\n\n[登壇資料] 2025-05-22 AIネイティブ開発 Tips 1000本ノック (ミダスキャピタル投資先企業勉強会)\n\n\n\n2025-05-22\n\n\n\n\n\n\n\n\n\n\n\n\n\nSapporo.vim 自己紹介\n\n\n\nslides\n\nvim-jp\n\n\n\n2024-02-04 Sapporo.vim 自己紹介\n\n\n\n2024-02-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nSapporo.vim 自己紹介\n\n\n\nslides\n\nvim-jp\n\n\n\n2023-12-16 Sapporo.vim 自己紹介\n\n\n\n2023-12-16\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Content",
      "Slides"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "uma-chan’s page",
    "section": "",
    "text": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた\n\n\n\ntech\n\ntech-data\n\ntech-dbt\n\n\n\nBigQuery 上で dbt incremental モデルの dbt run 実行時間を40分短縮した手順を共有する\n\n\n\n2025-09-28\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodex CLI の設定ファイルを dotfiles で管理する\n\n\n\nblog\n\ntech-ai\n\n\n\nCodex CLI の設定ファイルを dotfiles で管理する方法について説明します。\n\n\n\n2025-09-14\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年のアウトプットまとめ with LAPRAS\n\n\n\nblog\n\ndiary\n\n\n\n2025年のアウトプットを LAPRAS に出力してもらいました。\n\n\n\n2025-09-02\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025-08-23 日誌\n\n\n\nblog\n\ndiary\n\n\n\n2025-08-23 日誌\n\n\n\n2025-08-23\n\n\n\n\n\n\n\n\n\n\n\n\n\nClaude Code データ業務活用\n\n\n\nslides\n\ngenda\n\n\n\n[登壇資料] 2025-08-08 ミダス企業群生成AI横断勉強会\n\n\n\n2025-08-08\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatabricks Connect 実践編 - ローカルから Databricks コンピュートを利用\n\n\n\nblog\n\ntech\n\ntech-python\n\ntech-databricks\n\n\n\nDatabricks Connect でローカル開発環境から Databricks の Spark セッションを制御します\n\n\n\n2025-07-28\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython 開発環境最適化編 - uv + pre-commit + GitHub Actions\n\n\n\nblog\n\ntech\n\ntech-python\n\ntech-vscode\n\n\n\nuv と pre-commit で Python 開発環境を最適化。 VS Code 以外のエディタや GitHub Actions でも統一された品質を保てます\n\n\n\n2025-07-28\n\n\n\n\n\n\n\n\n\n\n\n\n\nClaude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-vscode\n\n\n\nClaude Code 対応の Dev Container 環境をサクッと構築。VS Code 以外のエディタでも恩恵を受けられます\n\n\n\n2025-07-28\n\n\n\n\n\n\n\n\n\n\n\n\n\n個人的ターミナル最適化 for Claude Code\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-tmux\n\ntech-vim\n\n\n\nClaude Code を便利に使うためのターミナル環境について共有します\n\n\n\n2025-07-14\n\n\n\n\n\n\n\n\n\n\n\n\n\nVimへの初コントリビューションの経緯と学び\n\n\n\nblog\n\ntech\n\ntech-vim\n\nvim-jp\n\n\n\nVim 本体への初コントリビューションの経緯と学びを共有します\n\n\n\n2025-07-14\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmux で Vim から Claude Code にテキストを送信するプラグインを作った\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-tmux\n\ntech-vim\n\n\n\ntmux で Vim から Claude Code にテキストを送信する Vim プラグインの紹介\n\n\n\n2025-06-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nローカル dbt で BigQuery への認証を行う\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nローカル dbt で BigQuery への認証を行う\n\n\n\n2025-06-15\n\n\n\n\n\n\n\n\n\n\n\n\n\nuv で Python のグローバルインストールを行う\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nuv を使って Python のグローバルインストールを行う\n\n\n\n2025-06-10\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoetry の pyproject.toml を使って uv で .venv を作成する\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nPoetry の pyproject.toml を使って uv で .venv を作成する\n\n\n\n2025-06-08\n\n\n\n\n\n\n\n\n\n\n\n\n\nVim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\nVim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法\n\n\n\n2025-06-04\n\n\n\n\n\n\n\n\n\n\n\n\n\n自己紹介\n\n\n\nslides\n\npivot\n\n\n\n2025-06-03 自己紹介 @PIVOT\n\n\n\n2025-06-03\n\n\n\n\n\n\n\n\n\n\n\n\n\nCursorのおすすめ設定 & Cursorにデータ分析を任せる方法\n\n\n\nslides\n\ngenda\n\n\n\n[登壇資料] 2025-05-22 AIネイティブ開発 Tips 1000本ノック (ミダスキャピタル投資先企業勉強会)\n\n\n\n2025-05-22\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatabricks AI/BI ダッシュボードの Git 連携の運用方法\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nDatabricks AI/BI ダッシュボードを Git flow で運用することにした経緯と実際の運用について\n\n\n\n2025-05-21\n\n\n\n\n\n\n\n\n\n\n\n\n\nAWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions\n\n\n\nblog\n\ntech\n\n\n\nAWS Lambda で ECR にあるコンテナイメージを実行するために必要な全てのリソースを Terraform で構築し GitHub Actions でデプロイできるようにします\n\n\n\n2025-05-12\n\n\n\n\n\n\n\n\n\n\n\n\n\nBash/Zsh でコマンドをエディタで編集する\n\n\n\nblog\n\ntech\n\n\n\nBash/Zsh で入力中のコマンドをエディタで編集して実行する方法について書いています\n\n\n\n2025-05-10\n\n\n\n\n\n\n\n\n\n\n\n\n\n今更ながら Vim に EditorConfig を導入しました\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n今更ながら Vim に EditorConfig を導入しました。設定方法と感想を書いています。\n\n\n\n2025-05-06\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython venv インストール・更新スクリプトの供養\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nPython venv 仮想環境のインストール・更新スクリプトを供養します\n\n\n\n2025-05-06\n\n\n\n\n\n\n\n\n\n\n\nMarkdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nMarkdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する方法を紹介します\n\n\n\n2025-05-06\n\n\n\n\n\n\n\n\n\n\n\ntmux と Zsh に Git リポジトリのステータスを表示する\n\n\n\nblog\n\ntech\n\ntech-tmux\n\n\n\ntmux のステータスラインと Zsh プロンプトに Git リポジトリのステータスを表示させる方法を紹介します\n\n\n\n2025-05-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatabricks MCP Server を Service Principal 認証対応させた\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-data\n\n\n\nDatabricks MCP Server を Service Principal 認証対応させたものを公開しました\n\n\n\n2025-04-29\n\n\n\n\n\n\n\n\n\n\n\n\n\nlefthook 設定の供養\n\n\n\nblog\n\ntech\n\n\n\nGitHub Profile 用のリポジトリで lefthook を活用していましたが、不要になり削除しようと思うのでここに知見を残します\n\n\n\n2025-04-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython でありがちな本体バージョンとライブラリバージョンの不整合の例\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nPython のバージョンとライブラリのバージョンの不整合で発生したエラーの例を記録に残しておきます\n\n\n\n2025-04-16\n\n\n\n\n\n\n\n\n\n\n\nMCP に入門した\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nMCP (Model Context Protocol) に入門してみました\n\n\n\n2025-04-11\n\n\n\n\n\n\n\n\n\n\n\n\n\nGemini API に課金した\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nGemini API に課金したので手順をメモしておきます\n\n\n\n2025-04-10\n\n\n\n\n\n\n\n\n\n\n\n\n\n個人的ブックマーク\n\n\n\nblog\n\nmemo\n\n\n\n個人的な重要記事などをまとめておきます\n\n\n\n2025-04-07\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevin に週報を書いてもらった\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nDevin に週報を書いてもらうためのプロンプトを用意して実際に週報を書いてもらったのでその内容を共有します\n\n\n\n2025-04-05\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevin 週報作成用プロンプト\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nDevin に週報を書いてもらうためのプロンプト\n\n\n\n2025-04-05\n\n\n\n\n\n\n\n\n\n\n\n\n\n2024年度を振り返る\n\n\n\nblog\n\ndiary\n\n\n\n2024年度に初めて経験したことを振り返ってみます\n\n\n\n2025-04-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nAider を使ってみる\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nAI エージェント Aider を使ってみました\n\n\n\n2025-04-01\n\n\n\n\n\n\n\n\n\n\n\nNotion データベースでリレーション元のプロパティを表示する (2025年3月28日時点)\n\n\n\nblog\n\ntech\n\n\n\nNotion データベースでリレーションプロパティ (列) にリレーション元のプロパティも併せて表示させる方法を紹介します\n\n\n\n2025-03-23\n\n\n\n\n\n\n\n\n\n\n\n\n\n見やすい SQL を書くための Tips\n\n\n\nblog\n\ntech\n\n\n\ndbt モデルやダッシュボード向けの SQL を書くことが多いので戒めの意味も込めて見やすい SQL を書くための Tips をまとめてみました\n\n\n\n2025-02-21\n\n\n\n\n\n\n\n\n\n\n\n\n\n最近の Vim プラグイン開発のアイデア\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n最近の Vim プラグイン開発のアイデアを振り返ります\n\n\n\n2025-02-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstagram API のアクセストークンを取得する\n\n\n\nblog\n\ntech\n\n\n\n失敗していますが Instagram API のアクセストークンを取得する手順を途中まで書いておきます\n\n\n\n2025-01-31\n\n\n\n\n\n\n\n\n\n\n\n\n\nデータエンジニアが初めてダッシュボードを作成して気づいたこと\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nデータエンジニア3年目にして初めてダッシュボードを作成する機会を得たので時系列順に思ったことを書いていきます\n\n\n\n2024-12-23\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto の YAML ヘッダにコードを埋め込みたい\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nQuarto の YAML ヘッダにコードを埋め込む方法についてのメモです。GitHub Actions で生成した値を埋め込むことができます。\n\n\n\n2024-12-07\n\n\n\n\n\n\n\n\n\n\n\n\n\n事故らない OneDrive 設定変更手順\n\n\n\nblog\n\ntech\n\n\n\nOneDrive の設定変更手順をまとめました。デスクトップやドキュメントの同期を避けたい場合に役立つ内容です。\n\n\n\n2024-12-07\n\n\n\n\n\n\n\n\n\n\n\n\n\nSnowSQL セットアップ (Mac)\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nMac で SnowSQL をセットアップする手順をまとめました\n\n\n\n2024-12-05\n\n\n\n\n\n\n\n\n\n\n\n\n\nVim/Neovim の dbt 開発環境の現状と Vim を救う話\n\n\n\nblog\n\ntech\n\ntech-data\n\ntech-vim\n\n\n\n私が業務でよく利用する dbt のローカル開発環境の話をしていきます\n\n\n\n2024-12-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nZennの記事をGitHubリポジトリで管理する\n\n\n\nblog\n\ntech\n\n\n\nZenn の記事を GitHub リポジトリで管理する方法をまとめました\n\n\n\n2024-11-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nnektos/act を使ってみた\n\n\n\nblog\n\ntech\n\n\n\nGitHub Actions をローカルで実行できる便利な OSS nektos/act を使ってみました\n\n\n\n2024-11-12\n\n\n\n\n\n\n\n\n\n\n\n\n\nキャリアについてぼんやり考えていたことを時系列順にまとめる\n\n\n\nblog\n\ndiary\n\n\n\n自分のキャリアについてぼんやり考えていたことを時系列順にまとめてみました\n\n\n\n2024-10-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n:%s/i9wa4/uma-chan/g\n\n\n\nblog\n\ndiary\n\n\n\nRenaming i9wa4 to uma-chan\n\n\n\n2024-10-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n最近の Vim プラグイン開発のアイデア\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n最近の Vim プラグイン開発のアイデアをメモしておきます\n\n\n\n2024-09-22\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto による DataFrame の表示テスト\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nPandas の DataFrame をウェブサイト一覧表作成に転用するための実験記事\n\n\n\n2024-09-08\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nGitHub でブログやスライドを管理したい方にオススメな Quarto による GitHub Pages 公開手順を紹介します\n\n\n\n2024-08-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n自分用千年戦争アイギスメモ\n\n\n\nblog\n\ngame\n\nmemo\n\n\n\n千年戦争アイギスの自分用メモ\n\n\n\n2024-07-20\n\n\n\n\n\n\n\n\n\n\n\n\n\n自分用 Minecraft メモ\n\n\n\nblog\n\ngame\n\nmemo\n\n\n\nMinecraft の自分用メモ\n\n\n\n2024-07-20\n\n\n\n\n\n\n\n\n\n\n\n\n\n技術系 Tips まとめ\n\n\n\nblog\n\ntech\n\n\n\nたまに使うけど忘れてしまうような技術系の小ネタ (コマンド・設定) まとめ記事です\n\n\n\n2024-07-15\n\n\n\n\n\n\n\n\n\n\n\n\n\nsystemd がユーザー権限でも使える\n\n\n\nblog\n\ntech\n\n\n\nsystemd がユーザー権限でも設定できる\n\n\n\n2024-06-28\n\n\n\n\n\n\n\n\n\n\n\n\n\n購入したガジェットの紹介\n\n\n\nblog\n\ndiary\n\n\n\nこれまで購入したガジェットの一覧\n\n\n\n2024-06-17\n\n\n\n\n\n\n\n\n\n\n\n\n\nMac 環境構築手順\n\n\n\nblog\n\ntech\n\nmemo\n\n\n\n私の Mac 環境構築手順をまとめておきます\n\n\n\n2024-06-17\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto で作ったスライドを GitHub Pages にデプロイする\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nQuarto で作ったスライドを GitHub Pages にデプロイする方法について書いています\n\n\n\n2024-05-05\n\n\n\n\n\n\n\n\n\n\n\n\n\nVim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみた\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\nVim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみました\n\n\n\n2024-05-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nデータサイエンス100本ノックの実行環境構築 (WSL2)\n\n\n\nblog\n\ntech\n\n\n\nデータサイエンス100本ノックの実行環境構築 (WSL2)\n\n\n\n2024-03-26\n\n\n\n\n\n\n\n\n\n\n\n\n\nWSL2 のセットアップ\n\n\n\nblog\n\ntech\n\n\n\n\n\n\n\n2024-03-25\n\n\n\n\n\n\n\n\n\n\n\n\n\nSapporo.vim 自己紹介\n\n\n\nslides\n\nvim-jp\n\n\n\n2024-02-04 Sapporo.vim 自己紹介\n\n\n\n2024-02-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nefm-langserver を Vim/Neovim で利用する\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n\n\n\n\n2024-01-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n\n\n\n\n2024-01-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Pages (Jekyll) blog のタグ追加対応\n\n\n\nblog\n\ntech\n\n\n\n\n\n\n\n2024-01-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Post\n\n\n\nblog\n\ndiary\n\n\n\n\n\n\n\n2024-01-01\n\n\n\n\n\n\n\n\n\n\n\n\n\nSapporo.vim 自己紹介\n\n\n\nslides\n\nvim-jp\n\n\n\n2023-12-16 Sapporo.vim 自己紹介\n\n\n\n2023-12-16\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Top"
    ]
  },
  {
    "objectID": "resume/05-genda.html",
    "href": "resume/05-genda.html",
    "title": "株式会社GENDA",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2024年時点)\n\n\n\n\n\n\n\n\n\n事業内容\nグループ各社の事業成長の支援および経営管理\n\n\n資本金\n197億6,465万円（資本剰余金含む）\n\n\n売上高\n連結：556億円（2024年1月期）\n\n\n従業員数\n連結：12,056名（2024年8月31日時点）\n\n\n上場／非上場\n上場\n\n\n雇用形態\n正社員\n\n\n勤務地\n東京都港区 (フルリモート・月1出社)\n\n\n所属\n[2024/11 - 現在] IT戦略部 データチーム"
  },
  {
    "objectID": "resume/05-genda.html#データ-カラオケ事業会社のデータ利活用推進",
    "href": "resume/05-genda.html#データ-カラオケ事業会社のデータ利活用推進",
    "title": "株式会社GENDA",
    "section": "1. [データ] カラオケ事業会社のデータ利活用推進",
    "text": "1. [データ] カラオケ事業会社のデータ利活用推進\n\n1.1. 概要\n\n様々な意思決定をデータに基づいて行うために必要なデータ基盤の構築運用とデータ活用方法の提案\n\n\n\n1.2. 期間\n\n2024/11 - 現在\n\n\n\n1.3. 規模・役割\n\n役割：リーダー\n規模：4名\n\nデータエンジニアリング全般：2名 (自分含む)\n\n内訳\n\nデータパイプライン構築：メンバー1名\ndbt によるデータマート構築：私1名\nダッシュボード作成：私1名\n\n\n事業会社側役員との折衝等担当 (BizDev)：1名\n事業会社側経理担当：1名\n\n\n\n\n1.4. 担当業務\n\nPOS データやアプリDBのデータを Snowflake に集約するデータパイプライン構築・運用\n\n補足：Snowflake に転送後 Databricks からテーブルを参照しています\n\n用途に応じた dbt によるデータマート構築\nデータ基盤上のデータを利用したダッシュボード作成・運用\nデータ基盤 (Databricks) やデータ利活用方法の啓蒙\n\n\n\n1.5. 機能開発・実装詳細\n\nデータパイプライン構築\n\nMWAA を用いて事業会社側の SFTP サーバ上の CSV ファイルをダウンロードし Snowflake のテーブルへデータを追加する\nデータパイプライン全体を Terraform で管理している\nあるいは直接受領したファイルを Snowflake へ手動追加する\n\ndbt によるデータマート構築\n\nDatabricks で dbt Core ジョブを実行し Databricks 上にデータマートを構築する\n\nダッシュボード作成\n\nDatabricks のダッシュボード機能を利用する\n\n\n\n\n1.6. 目的・背景\n\n開発が生じる要因\n\nデータパイプライン構築\n\nM&A によりグループインした企業の POS データを新たに取り込む\n目標数値など連携対象が増加した際に適宜取り込む\nIPコラボの情報などのマスターデータを営業サイドから受領する\n\ndbt によるデータマート構築\n\nダッシュボード作成に必要なデータ集計処理時間の短縮のために dbt によるバッチ処理に切り出す\n\nダッシュボード作成\n\n料金体系の変更など施策の効果を監視するために可視化したいデータの要望を受ける\n\n\n\n\n\n1.7. 課題\n\n人員不足による開発遅延\n\n私がデータ転送部分の開発・改修を自分の手で直接実施はせず他メンバーに任せるという業務分担状況で、なおかつグループインする企業が増え続けている都合でデータ転送部分を担うデータエンジニアの手が回りづらい状況が続いていました。\n経営目線で求められるダッシュボードを作成する上で必要なデータへの知見や技術をもった人間が私しかいないため私がボトルネックになっています。\n\n\n\n\n1.8. 工夫した点\n\n\n私がデータ転送部分の開発・改修に深くコミットしていないという業務分担状況で、なおかつグループインする企業が増え続けている都合でデータ転送部分を担うデータエンジニアの手が回りづらい状況が続いている\n\n\n後段の開発作業の工数を削減する目的で、現状の実装から最小限の変更で対応できる要件となるよう事業会社側と交渉をまとめました。 実装作業こそ自分で実施しないものの、実装内容を100%理解できているため業務の切り出しを最適な形で行うことができました。\n\n\n経営目線で求められるダッシュボードを作成する上で必要なデータへの知見や技術をもった人間が私しかいないため私がボトルネックになっています。\n\n\n現状も続いている課題であって大きな成果はまだ出せていません。 現在事業会社側では全社的にトップダウンな意思決定を伴いつつDX推進中になるため、事業会社側のメンバーの工数の確保をトップダウンで実施してもらい、その時間を活用して私の手で人材育成を行う流れを検討しています。 生成AIを補助に利用する方法などを提示しつつできる形で関与できるメンバーを増やしていければと思います。\n\n\n1.9. 成果\n\nダッシュボード\n\n事業会社側の経理部門により Excel で毎日作成されていた売上速報をダッシュボードにより完全自動化できました。\n週次で実施している全国のエリア統括者と役員の参加する営業会議向けに作成していた週報の作成をほぼ自動化できました。\n事業会社側の担当者から追跡したいデータに関する要望が出てくるようになり、データドリブンな意思決定をできる体質に一歩近付きました。\n\nデータ基盤\n\nマーケティング施策の効果検証に利用するデータを揃えることで効果的なマーケティング施策立案に貢献しました。\n\n\n\n\n1.10. 担当フェーズ\n\nヒアリングや提案による以下の要件整理\n\nデータパイプライン改修\nダッシュボード新規作成・項目追加\n\n開発指揮\n\nデータパイプライン改修\n\n開発作業\n\ndbt によるデータマート構築\nダッシュボード新規作成・項目追加\n\n運用作業\n\nデータパイプライン不通時の原因調査\nデータマートやダッシュボードの障害解消\n\n\n\n\n1.11. 開発環境\n\nGitHub\nAWS\n\nMWAA\n\nSnowflake\nDatabricks\ndbt Core\nTerraform"
  },
  {
    "objectID": "resume/05-genda.html#データ-ゲームセンター事業会社のipマスターデータ作成支援",
    "href": "resume/05-genda.html#データ-ゲームセンター事業会社のipマスターデータ作成支援",
    "title": "株式会社GENDA",
    "section": "2. [データ] ゲームセンター事業会社のIPマスターデータ作成支援",
    "text": "2. [データ] ゲームセンター事業会社のIPマスターデータ作成支援\n※IP：知的財産 (Intellectual Property)。ゲームやアニメのタイトルなどを指しています。\n\n2.1. 概要\n\nIP名、IP・キャラクターの関係性、景品・IP・キャラクターの関係性を整理したマスターデータを作成する\n\n\n\n2.2. 期間\n\n2025/04 - 現在\n\n\n\n2.3. 規模・役割\n\n役割：リーダー\n規模：4名\n\nマスターデータ設計・システム設計：私1名\nkintone アプリ PoC 担当：1名\n事業会社側メンバーとの調整担当兼 kintone アプリ実装担当：1名\nデータパイプライン構築：1名\n\n\n\n\n2.4. 担当業務\n\nデータ入力用の kintone アプリ設計\nkintone アプリからデータ基盤への連携に必要なデータパイプライン設計\nkintone アプリの運用方法検討\n\n\n\n2.5. 機能開発・実装詳細\n\nkintone アプリ\n\nIP名、IP・キャラクターの関係性、景品・IP・キャラクターの関係性を表すマスターデータへのデータ追加・修正を行う\n\nデータパイプライン\n\nkintone アプリから Snowflake へのデータ転送を行う\nデータパイプライン全体を Terraform で管理する\n\n\n\n\n2.6. 目的・背景\n\nIPやキャラクターを包括的に管理する仕組みが社内外ともに存在せず、景品選定も担当者の経験則に依存しており改善が求められる状況でした。\n景品の売上実績やIPの流行に関する情報をデータとして蓄積していき更に景品選定に活用するサイクルを作っていきたい狙いがあります。\n\n\n\n2.7. 課題\n\n以下の要求があり、入力からデータ基盤への連携までどのようなシステムが最適か検討する必要がありました。\n\n景品を卸す業者に一次情報を入力してもらう kintone アプリの導入が進められている最中であった\n責任分掌の観点からデータの修正や管理を調達部門に自律的に実施してもらう必要がある\n毎日数十件のデータ入力が必要でありデータ入力担当者の負担を極力軽減させたい\n\n当初利便性を考慮して Notion によるデータ入力を検討していました。Notion では誤入力が起こりやすいという欠点があるため Notion 上の仮のマスターデータと、データ基盤上に別途真のマスターデータを用意しておき、レビューを行った後に両者を同期するという運用を検討しました。\n\nこの構成の場合レビュー工程が都度入ることで入力担当者の負担が大きくなることが予想されました。\n\n\n\n\n2.8. 工夫した点\n\nkintone アプリの仕様を調査していくうちに入力データへのバリデーションを設定でき誤入力を防げることが分かりました。これにより当初考慮していなかったマスターデータ管理用社内 kintone アプリの導入を決めました。\n\nこの方向転換によって課題をほぼ全て解消できました。\n\n\n\n\n2.9. 成果\n\n開発中\n\n\n\n2.10. 担当フェーズ\n\nマスターデータの設計\nシステム全体の要件定義・設計\n\n\n\n2.11. 開発環境\n\nデータ入力アプリ\n\nkintone\n\nデータ基盤\n\nGitHub\nAWS\n\nMWAA\n\nSnowflake\nTerraform"
  },
  {
    "objectID": "resume/05-genda.html#mlops-機械学習開発運用環境の改善",
    "href": "resume/05-genda.html#mlops-機械学習開発運用環境の改善",
    "title": "株式会社GENDA",
    "section": "3. [MLOps] 機械学習開発運用環境の改善",
    "text": "3. [MLOps] 機械学習開発運用環境の改善\n\n3.1. 概要\n\n社内で運用されている機械学習モデルの開発・運用ともに継続改善を行う\n\n\n\n3.2. 期間\n\n2024/11\n2025/03 - 現在\n\n\n\n3.3. 規模・役割\n\n役割：リーダー\n規模：私1名\n\n\n\n3.4. 担当業務\n\n機械学習関連の改善策立案・設計・実装\n\n\n\n3.5. 機能開発・実装詳細\n\nリポジトリへの CI/CD 導入\n\nLinter/Formatter を導入し Python/SQL/Terraform のコード品質を確保する\nStaging/Production へのデプロイを GitHub Actions の手動実行で行えるようにする\n\nデプロイ手順改善\n\nProduction 環境へのデプロイ実行はレビューを伴う形へと改善する\nリリースタグを用いた標準的なリリース管理を行う運用手順を整備する\n\nスコアリング結果のプロダクトへの連携システム構成の変更\n\nスコアリングをプロダクトアプリと同じ AWS アカウント内の ECS で実施していた構成から、より開発をしやすくスケーラビリティの確保が容易な Databricks でのスコアリング実施に変更する\n\n[検討中] 機械学習に利用するデータのデータマート化\n[検討中] プロダクトへのデータ反映確認の自動化\n[検討中] 学習データの増加に対応できるような処理改善\n[検討中] 機械学習モデルの精度を継続監視する仕組みの導入\n[検討中] テストの導入\n[検討中] モノレポ化\n\n\n\n3.6. 目的・背景\n\n取り扱う事業の増加・学習データの増加に対応していくために開発・運用を改善が求められている\n\n\n\n3.7. 課題\n\n数名のインターン生にロジック部分の開発に集中してもらうことで成果を出そうとしている中で、開発・運用に手作業が多く含まれることからコントリビューションの難易度が高くなってしまっている\n対象事業のアクティブユーザー数が増加することで学習データが増加しシステムのスケールが必要となる\n対象事業が増加する際の工数増加を懸念して新たな機械学習活用を提案しづらい状況にある\n\n\n\n3.8. 工夫した点\n\nまずできる所から改善を進めていき1年かけてゴールを目指すというマイルストーンを立て、恩恵を実感してもらいつつ協力を得ながら進める方針を取った点\n\n\n\n3.9. 成果\n\nデータサイエンスチームで最も注力しているオンラインクレーン事業の景品レコメンドシステムに関して CI/CD 導入・デプロイ手順改善を行いインターン生のコントリビューション難易度を下げることに成功しています。\n\n\n\n3.10. 担当フェーズ\n\n機械学習関連の改善策立案・設計・実装\n\n\n\n3.11. 開発環境\n\nGitHub\nGitHub Actions\nAWS\n\nECS\nRDS\nS3\n\nDatabricks\ndbt Core"
  },
  {
    "objectID": "resume/05-genda.html#その他-開発環境等へのai導入推進",
    "href": "resume/05-genda.html#その他-開発環境等へのai導入推進",
    "title": "株式会社GENDA",
    "section": "4. [その他] 開発環境等へのAI導入推進",
    "text": "4. [その他] 開発環境等へのAI導入推進\n\n4.1. 役割\n\nチーム内へのAI導入は私が主導して進めています。\n\n\n\n4.2. 所感\n\nデータエンジニアチームのコーディング作業では単調なカラム修正などが多いことから導入メリットが大きいです。\nデータサイエンスチームのコーディング作業ではコアとなる機械学習の実装に関して AI がまだあまり役に立たないことから一般的な Python コーディングの支援の観点で導入を進めています。\nデータ分析支援に MCP を活用できるか検討中です。感触は良いです。\n\n\n\n4.3. 各種ツールの検討状況 (2025年4月時点)\n\nGitHub Copilot\n\nコード補完は有用なので継続利用していきたい\n\nGitHub Copilot Chat\n\n後続の AI エージェントに比べて優位性がない\n\nDevin\n\n初回の環境構築・スタートアップスクリプトの作成を実施\nPR作成に限らない用途での利用例を見せてチーム内で更なる活用を促進\n\n執筆記事：Devin に週報を書いてもらった - Zenn\n\n\nAider\n\n任意の開発環境で利用できる CLI ベースの AI エージェントとして Aider の調査を実施\n\n執筆記事：Aider を使ってみる – uma-chan’s page\n\n任意の環境で AI エージェントを利用できるという観点で有用\n\nLLM の API 利用が必要で後述の Cursor を利用する場合2重課金になってしまうためあくまでも最終手段\n\n\nCursor\n\n社内で利用可能であったため検討を実施\nVS Code の fork であり VS Code の資源が活用できる点と既存コードを加味したコーディングが最もスムーズな点からローカル開発環境として最良の選択肢と考えています\nデータサイエンスチームでは Cursor + VS Code の Databricks 拡張の利用を検討しています\n\nGitHub Copilot Agent Mode (VS Code)\n\nCursor に比べて既存コードを考慮しない挙動になり Cursor の次点となる印象\n\nMCP\n\nDatabricks MCP サーバー\n\nLLM に実際に試行錯誤させながらデータ分析用の SQL を書かせることができる感触を得たのでビジネスサイドで SQL が書けない方にもデータ分析に参入してもらうための MCP 利用推進策を検討中です。\n\nCursor の活用\n\n公式ドキュメント・社内ドキュメント・他のリポジトリなどコンテキストの理解に各種サーバーを利用できるため Cursor を MCP クライアントに据えた開発環境改善方法を検討中です。"
  },
  {
    "objectID": "resume/05-genda.html#その他-開発業務以外の活動",
    "href": "resume/05-genda.html#その他-開発業務以外の活動",
    "title": "株式会社GENDA",
    "section": "5. [その他] 開発業務以外の活動",
    "text": "5. [その他] 開発業務以外の活動\n\n5.1. 記事執筆・登壇等\n下記ページをご確認ください。\n通常業務以外の活動 | 職務経歴書\n\n\n5.2. 採用活動\n\nカジュアル面談実施\n\nSNS にてカジュアル面談を実施している旨宣伝を行い面談に繋げました。\n\n転職媒体での候補者選定\n\n自主的に採用業務への関与を申し出て以降、現在まで継続的に候補者選定業務を担当しております。"
  },
  {
    "objectID": "resume/07-pivot.html",
    "href": "resume/07-pivot.html",
    "title": "PIVOT株式会社",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2025年時点)\n\n\n\n\n\n\n\n\n\n事業内容\n経済コンテンツサービス開発\n\n\n資本金\n1億円\n\n\n従業員数\n約50名 (インターン含む)\n\n\n上場／非上場\n非上場\n\n\n雇用形態\n業務委託\n\n\n勤務地\n東京都渋谷区 (フルリモート)\n\n\n所属\nプロダクトマネジメントチーム"
  },
  {
    "objectID": "resume/03-cnsh.html",
    "href": "resume/03-cnsh.html",
    "title": "株式会社シイエヌエス北海道",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2024年時点)\n\n\n\n\n\n\n\n\n\n事業内容\nアプリケーション開発・インフラ構築事業、クラウド構築事業、データ分析・AI事業、DX支援事業\n\n\n資本金\n2500万円\n\n\n売上高\n7億5,351万円\n\n\n従業員数\n39名\n\n\n上場／非上場\n非上場\n\n\n勤務地\n北海道札幌市(リモートワーク・週1出社)\n\n\n雇用形態\n正社員\n\n\n所属\n[2022/04 - 2024/03] デジタルビジネス推進部"
  },
  {
    "objectID": "resume/03-cnsh.html#mlops-情報通信企業向け-機械学習ワークフローと-ai-プラットフォーム移管",
    "href": "resume/03-cnsh.html#mlops-情報通信企業向け-機械学習ワークフローと-ai-プラットフォーム移管",
    "title": "株式会社シイエヌエス北海道",
    "section": "1. [MLOps] 情報通信企業向け 機械学習ワークフローと AI プラットフォーム移管",
    "text": "1. [MLOps] 情報通信企業向け 機械学習ワークフローと AI プラットフォーム移管\n\n1.1. 概要\n\nDataRobot 中心で構築していた機械学習ワークフローから Snowpark ML (Snowflake) 中心の構築への移管\n\n\n\n1.2. 期間\n\n[2023/12 - 2024/01] Snowpark ML 事前検証\n[2024/02 - 2024/03] 追加調査・ワークフロー設計\n\n\n\n1.3. 規模・役割\n\n[2023/12 - 2024/01]\n\n役割：メンバー\n規模：1名 (私)\n\n[2024/02 - 2024/03]\n\n役割：リーダー\n規模：2名\n\n自社の若手2名\n\n\n\n\n\n1.4. 担当業務\n\n[2023/12 - 2024/01] (私1名) Snowpark ML の事前検証\n[2024/02 - 2024/03] (2名) DataRobot から Snowpark ML への移管のための追加調査\n[2024/03] (私1名) ワークフロー設計\n\n\n\n1.5. 機能開発・実装詳細\n移管前後の構築詳細は以下の通りです。\n\n移管前構築 (AWS MWAA + ECS + DataRobot + Snowflake)\n\nMWAA にてワークフロー管理を行っており DAG ファイルにてジョブを定義し並列処理や直列処理を記述していました。\nMWAA KubernetesPodOperator にて利用する ECS イメージを JupyterHub (ノートブック実行環境) でも共有していたため本番と開発でライブラリ依存関係の齟齬がない環境でした。\nAI プラットフォームとして DataRobot を採用し、ハイパーパラメータチューニングやモデル評価を全てフルマネージドで実施させていました。ただしコストが嵩む問題がありました。\n\n移管後構築 (AWS SageMaker + Snowpark ML + Snowflake)\n\nAI プラットフォームとして Snowpark ML を採用することとしました。使用感は scikit-learn に近く、ラベルエンコーディング・ハイパーパラメータチューニング・モデル評価を自力で実装する必要があります。\nワークフローは “SageMaker + Papermill” でノートブック上での管理となります。\nモデルはモデルレジストリ機能にて管理させます。\n他部署 (他の環境) とも共有できるように素朴な実装を目指しました。\n\n\n\n\n1.6. 目的・背景\n\nコスト上の問題から DataRobot の利用を2024年8月に停止するという判断を受けて AI プラットフォームの移行先を探す必要がありました。\n\n\n\n1.7. 課題\n\n移行業務は付加価値を生みづらい都合で移行先調査の優先順位が低くなってしまい、分析基盤管理側の社員も移行先調査がほとんど実施できていない状況でした。\nSnowpark ML は新しいサービスのため公式ドキュメント以外で参照出来る情報が社内外ともにかなり限られている状況でした。\n\n\n\n1.8. 工夫した点\n\n調査作業での工夫点\n\n後から続く方が参照しやすいように調査記録を丁寧に取りました。\n\nSnowflake 公式のリポジトリに置かれているサンプルコードや公式ドキュメント・公式ライブラリソースコードのどの部分を参照したか記録に残しました。\n調査記録を客先社内公開済み。\n\n必要最低限の領域までの調査に留めることで、スケジュールや実装方針について予定より早く合意を取ることができました。\n\n関係者が多くなるため情報提供をいち早く行うことを優先しました。\n\n\n\n\n\n1.9. 成果\n\nSnowpark ML の利用は前例が少なかったため Snowflake 社からの個別開示情報などを利用して情報収集と事前検証を行ないました。結果、既存ワークフローに比べてコスト・性能面・セキュリティ面で優位性があることを示し、客先での先行事例を作ることができました。\n\n価値を生みづらいと見込まれていた移管作業の意義を示したため、注目度を上げ、周囲を巻き込むことに成功しました。客先での社内政治的にも Snowpark ML 導入推進の話を通しやすくなる状況作りに貢献しました。\n\n本プロジェクトではリーダーとして技術調査・スケジュール策定・チームへの作業指示・顧客他部署への情報共有など多様な役割を担うことができました。\n\n\n\n1.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n1.11. 開発環境\n\nAWS\n\nSageMaker\nCodeCommit\nSecrets Manager\n\nSQL\n\nSnowflake\n\nPython 実行環境\n\nSageMaker (conda_python3)\n\nAI プラットフォーム\n\nSnowpark ML"
  },
  {
    "objectID": "resume/03-cnsh.html#データ-情報通信企業向け-データマート整備",
    "href": "resume/03-cnsh.html#データ-情報通信企業向け-データマート整備",
    "title": "株式会社シイエヌエス北海道",
    "section": "2. [データ] 情報通信企業向け データマート整備",
    "text": "2. [データ] 情報通信企業向け データマート整備\n\n2.1. 概要\n顧客情報と紐付けて分析や機械学習に利用するための下記特徴量の作成\n\nポイントサービス加盟店と顧客推定住所との距離\nポイントサービス詳細情報\n決済情報\n様々な特徴量を次元圧縮して生成する特徴量\n行動履歴からルールベースで推定されたライブイベント実績\n\n\n\n2.2. 期間\n\n[2023/04 - 2023/05] ポイントサービス加盟店と顧客推定住所との距離\n[2023/06 - 2023/07] 決済情報\n[2023/08 - 2023/09] 行動履歴からルールベースで推定されたライフイベント実績\n[2023/10 - 2023/12] 様々な特徴量を次元圧縮して生成する特徴量\n[2024/01 - 2024/03] ポイントサービス詳細情報\n\n\n\n2.3. 規模・役割\n\n役割：サブリーダー\n規模：4名\n\n\n\n2.4. 担当業務\n\n(主に私1名) データ作成月次作業向けワークフロー構築\n(4名) データレイク調査\n(4名) データ抽出クエリ作成\n(リーダーと私の2名) レビュー\n(4名) 検証\n(4名) 保守\n(4名) 月次運用作業\n\n\n\n2.5. 機能開発・実装詳細\nデータマート構成のためのクエリは Juupyter Notebook 上から Python API 経由で実行していましたが、2023年秋頃から dbt Core を導入し SQL ファイルベースへ置き替えつつある状況でした。\n\n[旧環境] Snowflake の Python API 利用 (Jupyter Notebook にて管理)\n\nSnowflake Python API を Jupyter Notebook から実行します。\n\nファイル数が増えたりコード量が増えるとコードの見通しが悪くなりやすい欠点があります。\n\nワークフローは MWAA にて構築しています。\n\n[新環境] dbt Core 利用 (SQL ファイルベース)\n\ndbt Core により SQL ファイル主体で管理を行います。\n\n入出力の依存関係が明示され管理が容易になります。\nCI/CD、自動テスト、自動ドキュメント生成など現代的な開発・運用が可能となります。\n必要に応じて増分データのみを対象とするクエリに変更できます。\n\n\n\n\n\n2.6. 目的・背景\n\nデータレイクは充実しているものの、機械学習や顧客情報分析に利用できるデータマートは発展途上のため適宜追加していく必要がありました。\n\n\n\n2.7. 課題\n\n分析に利用できる特徴量が不足している状況でした。\n従来作成していた特徴量が上流データの仕様変更や不具合によって作ることができない場合がありました。\nJupyter Notebook で管理しているデータマート向けプログラムが長大なため不具合発生時の原因究明に時間が掛かることが多くありました。\n上流データが全て揃ったタイミングでデータマートの月次更新を行っておりましたが、一部情報をできるだけ早く更新してほしいと言われるようになりました。\n\n\n\n2.8. 工夫した点\n\n\n分析に利用できる特徴量が不足している状況でした。\n従来作成していた特徴量が上流データの仕様変更や不具合によって作ることができない場合がありました。\n\n\n\nユーザーアンケートにより整備すべきデータを決定し、より必要とされるデータマートを目指しました。\nできるだけ早くデータを提供できるような上流データを選定しつつ、上流データの障害発生率を調査し取捨選択を行いました。信頼性の高いデータマート運用のために設計時に十分考慮を行いました。\n\n\n\nJupyter Notebook で管理しているデータマート向けプログラムが長大なため不具合発生時の原因究明に時間が掛かることが多くありました。\n上流データが全て揃ったタイミングでデータマートの月次更新を行っておりましたが、一部情報をできるだけ早く更新してほしいと言われるようになりました。\n\n\n\nいずれも解消できるポテンシャルをもつ dbt に移行することとしました。\n\n\n\n2.9. 成果\n\nユーザー目線での改善を続けたことでデータマートのアクセス数増加につながり、部内の大きな成果として表彰を受けました。\n自チーム・他チームともに顧客行動予測を行っており、そのために必要な特徴量を自力で作成し社内の多様なモデルの精度向上に貢献できました。\ndbt 移行を推進することでソースコードを SELECT 文中心の理解しやすいものに置き換えることができました。\n上流データが追加されたタイミングで必要に応じてデータ作成処理を行える (セマンティックレイヤ対応ができる) ように dbt 環境に移行を順次進めることができています。\n\nセマンティックレイヤ対応は dbt Core では非対応のため dbt Cloud 導入時の対応となります。\n\n\n\n\n2.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n運用\n保守\n\n\n\n2.11. 開発環境\n\nAWS\n\nCodeCommit\nCloud9\nSecrets Manager\nSageMaker\nMWAA\nEKS\nECS\n\nSQL\n\nSnowflake\ndbt\n\nPython 実行環境\n\nSageMaker (conda_python3)\nJupyterHub (conda_python3)"
  },
  {
    "objectID": "resume/03-cnsh.html#mlops-情報通信企業向け-機械学習ワークフローのクラウドシフト",
    "href": "resume/03-cnsh.html#mlops-情報通信企業向け-機械学習ワークフローのクラウドシフト",
    "title": "株式会社シイエヌエス北海道",
    "section": "3. [MLOps] 情報通信企業向け 機械学習ワークフローのクラウドシフト",
    "text": "3. [MLOps] 情報通信企業向け 機械学習ワークフローのクラウドシフト\n\n3.1. 概要\n\nオンプレ基盤で実施していた顧客行動予測モデル作成 (50モデル分) ワークフローのクラウドシフト\n\n\n\n3.2. 期間\n\n[2022/07 - 2022/10] 28モデル分\n[2022/11 - 2023/03] 22モデル分\n\n\n\n3.3. 規模・役割\n\n規模：4名\n役割：メンバー\n\n\n\n3.4. 担当業務\n\n(私1名) ワークフロー設計・実装\n(私1名) 各ジョブ設計\n(4名) 各ジョブ実装\n(4名) 上流データ調査\n(4名) 機械学習用データ作成クエリの再構成\n(4名) 検証\n(4名) 保守\n\n\n\n3.5. 機能開発・実装詳細\nMWAA (Airflow) + EKS + Kubernetes + Papermill な Python 実行環境が構築済みのため以下の要領で実装を行いました。\n\nMWAA ワークフローを設計し DAG ファイルとして実装\n\n大まかにはモデル共通処理を実行した後、モデル固有の処理を並列で実行する流れです。\n\nSnowflake Python API と DataRobot API を実行する Python コード (Jupyter Notebook) を各ジョブの設計内容に応じて作成\n\n機械学習用データ作成・モデリング・スコアリング・モデル評価指標取得などの処理を実装します。\n\n\n\n\n3.6. 目的・背景\n\n従来の基盤の廃止に伴い AWS 基盤にて機械学習ワークフローを構築する必要がありました。\n\n\n\n3.7. 課題\n\n上流データは仕様が変わりつつ移行済みだったため、従来基盤で利用していたクエリと同等のものを作るには調査・検証の時間を大きく取る必要がありました。\nMWAA と DataRobot に関するノウハウがチーム内になく、自力で調査をしつつ基盤担当者から情報提供を受けながら取り組む必要がありました。\n\n\n\n3.8. 工夫した点\n\nMWAA (Airflow) + EKS + Kubernetes + Papermill の構成で並列処理に強いことを利用し、並列処理を最大限活用できるようにジョブの粒度を調整しました。\n移行対象のクエリの量が膨大かつ移行先上流データがどれか分からない状況だったため、初期調査段階では件数比較を活用しある程度当たりを付ける方法で効率的に設計を進めました。\n\n最終的にはレコードの一致率確認を行っていますが、初めから一致率確認をしていると時間が足りなかったと思われます。\n\nMWAA による機械学習ワークフロー構築時に従来手動で実施していた検証処理も含め、最終的に Slack 通知確認で完了するように作業を簡素化することで単純な移行ではなく価値を生むことを意識しました。\n\n\n\n3.9. 成果\n\n従来と同等のワークフローを維持しつつ、自動化と時短の工夫を入れることで大幅に運用工数を減らすことができました。\n\n\n\n3.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n保守\n運用\n\n\n\n3.11. 開発環境\n\nAWS\n\nSageMaker\nCodeCommit\nSecrets Manager\nMWAA\nEKS\nECS\n\nSQL\n\nSnowflake\n\nPython 実行環境\n\nSageMaker (conda_python3)\nJupyterHub (conda_python3)\n\nAI プラットフォーム\n\nDataRobot"
  },
  {
    "objectID": "resume/03-cnsh.html#mlops-小売企業向け-客数予測処理実行環境構築",
    "href": "resume/03-cnsh.html#mlops-小売企業向け-客数予測処理実行環境構築",
    "title": "株式会社シイエヌエス北海道",
    "section": "4. [MLOps] 小売企業向け 客数予測処理実行環境構築",
    "text": "4. [MLOps] 小売企業向け 客数予測処理実行環境構築\n\n4.1. 概要\n\nオンプレ基盤で実施していた客数予測処理の AWS 環境移行\n\n\n\n4.2. 期間\n\n2022/05 - 2022/06\n\n\n\n4.3. 規模・役割\n\n1名\nメンバー\n\n\n\n4.4. 担当業務\n\n予測処理実行環境構築 (EC2, Python)\n環境変更に伴う Python コード修正・スクリプト作成\n予測処理実行手順構築\n\n\n\n4.5. 機能開発・実装詳細\n\nEC2 に Anaconda をインストールしベイズ統計モデル作成環境を構築します。\n顧客の要求により客数予測に費せる日数が4日程度のためその範囲内で十分終了するよう処理の並列化を行います。\n\n\n\n4.6. 目的・背景\n\n(前提) PoC として1店舗毎にベイズ統計モデルで客数予測を行うプログラムが作成されており、客数予測処理は1店舗あたり4時間程度かかる状況でした。\n\nその上で4日程度で約200店舗分の客数予測を出す環境構築を求められていました。\nインスタンス性能を上げるための AWS 移行となります。\n\n\n\n\n4.7. 課題\n\n要求を満たすためには EC2 高性能インスタンスを利用する必要がありコストは最小限とする必要がありました。\n前任者の作成した並列処理に問題があり総実行時間が長くなってしまいまう。\n経験の浅い作業者に運用を直ちに引き継ぐことになっていたため、手動実行するプロセスを挟むと不具合や遅延が想定されました。\n\n\n\n4.8. 工夫した点\n\n前任者の作成していた並列処理は先にコア数に基づきジョブを分割する形式のシェルスクリプトで構成していましたが、各店舗毎にデータ量が異なるため予測処理が早めに終了して遊びの出るコアが発生してしまっていました。\n\n改善のため xargs に並列処理を管理させることで空きコアに逐次ジョブを実行させる構成に改善させ総実行時間を短縮させることができました。\n\n\n\n\n4.9. 成果\n\n当初の構成に比べて総実行時間を短縮することができ EC2 インスタンス利用時間の削減に成功しました。\n総実行時間は2日程度に抑えることができ、顧客要求を満たすことができました。\n利用可能なリソースが EC2 のみという制約の中、スクリプトを活用し極力自動化し引継ぎ後の業務負荷を軽減させました。\n\n\n\n4.10. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n保守\n\n\n\n4.11. 開発環境\n\nAWS\n\nEC2\n\nSQL\n\nPostgreSQL\n\nGit\nPython 実行環境\n\nPython (公式)\nAnaconda\n\nシェルスクリプト"
  },
  {
    "objectID": "resume/03-cnsh.html#その他-開発業務以外の活動",
    "href": "resume/03-cnsh.html#その他-開発業務以外の活動",
    "title": "株式会社シイエヌエス北海道",
    "section": "5. [その他] 開発業務以外の活動",
    "text": "5. [その他] 開発業務以外の活動\n\n5.1. 新卒採用一次選考の面接官対応\n\n2024年新卒採用：学生6名分\n2025年新卒採用：学生6名分\n\n\n\n5.2. データ分析業務担当者育成\n\n育成用プログラム進捗管理 (2023/06 - 2023/12)\n\n利用教材：データサイエンス100本ノック\n育成対象者：7名 (2023年度)\n業務：環境構築手順作成・質疑応答対応・作業進捗管理 (すべて私1名で対応)\n\nローカル上の環境構築手順の共有 (随時)\n\n社内 Wiki にて記事作成\n具体例\n\nAmazon Linux (EC2) + Anaconda + PyStan 環境構築\nWindows + Anaconda + PyStan 環境構築\nUbuntu (WSL2) + Docker (Dockerfile) + CPython + venv 環境構築\nUbuntu (WSL2) + Docker 環境構築 (データサイエンス100本ノック向け)\nAmazon Linux (Cloud9) + pyenv 環境構築\nVSCode と Vim での Linter Formatter 導入方法\n\n\nデータ分析関連技術情報共有 (随時)\n\nニュースサイト・技術ブログ・技術コミュニティにて情報収集し、社内チャットにて随時共有"
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "職務経歴書",
    "section": "",
    "text": "職務経歴書公開先：https://i9wa4.github.io/resume",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#職務要約",
    "href": "resume/index.html#職務要約",
    "title": "職務経歴書",
    "section": "1. 職務要約",
    "text": "1. 職務要約\n北海道大学理学部数学科を卒業後、Windowsアプリエンジニアや組込エンジニアを6年間経験し、2022年以降はデータエンジニアとMLOpsエンジニアとして勤務しております。\n◆データエンジニアとしての経験： データ基盤の管理者・データ基盤の構築運用・データ基盤のIaC化・dbtによるデータマート構築運用・ダッシュボード作成運用のようにデータエンジニアリング全般に一気通貫で携わってきました。\n◆MLOpsエンジニアとしての経験： 二値分類による顧客の行動予測モデルの作成～ワークフロー構築運用保守・機械学習基盤のCI整備・機械学習基盤上でのプログラム実行エラー対応などに取り組んできました。\n◆チームの中での役割： シイエヌエス北海道にてプロジェクトのリーダーやサブリーダーを任されておりました。hacomonoでは一人データエンジニアとしてデータ基盤管理者・データ基盤や利活用に関するタスクの社内調整・データ基盤部の目標管理といったリーダー相当の業務を担当しておりました。現職GENDAではあるグループ企業のデータ利活用の窓口兼主担当として関係者との仕様調整やデータエンジニアリング全般を任されております。また複数名のメンバーの業務進捗管理やコードレビューなどデータエンジニアチームのリーダー業務を2025年4月から徐々に受け持っております。\n◆採用活動への関与： チームを成長させることに対する興味関心が強く、採用活動に積極的に参加しております。新卒採用選考・面接官・カジュアル面談者の募集と面談実施・リファラル採用・転職媒体での候補者選定・ジョブディスクリプションの修正・求人の宣伝を行ってきました。",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#自己pr",
    "href": "resume/index.html#自己pr",
    "title": "職務経歴書",
    "section": "2. 自己PR",
    "text": "2. 自己PR\n◆性格面： 周囲の社員に貢献できるような地道な業務にモチベーション高く取り組むことができます。具体的には CI/CD 整備・ドキュメント整備・勉強会開催・情報共有・採用活動などです。現在主に担当しているデータ利活用に向けた業務は、中長期的に周囲の社員に貢献できるものと信じて取り組めるため自分にマッチした業務であると感じています。",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#職務経歴",
    "href": "resume/index.html#職務経歴",
    "title": "職務経歴書",
    "section": "3. 職務経歴",
    "text": "3. 職務経歴\n\n\n\n\n\n\n詳細は社名リンク先をご確認ください。\n\n\n\n\n3.1. 正社員\n\n\n\n\n\n\nPeriod\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n2024/11 - 現在\n\n\n株式会社GENDA\n\n\nデータエンジニア・MLOps エンジニアとして以下に従事 - データパイプライン全体の変更対応 - データマート整備 - ダッシュボード作成・運用 - AWS から Databricks への機械学習開発基盤移行対応 - CI 導入など機械学習基盤の整備 \n\n\n\n\n\n\n2024/04 - 2024/10\n\n\n株式会社hacomono\n\n\nデータエンジニアとして以下に従事 - 自社環境・顧客環境の DWH 構築・運用 - 自社データ基盤の運用改善・機能追加 \n\n\n\n\n\n\n2022/04 - 2024/03\n\n\n株式会社シイエヌエス北海道\n\n\nデータエンジニア・MLOps エンジニアとして以下に従事 - データパイプライン構築 - データマート整備 - 機械学習ワークフロー構築 \n\n\n\n\n\n\n2018/08 - 2022/03\n\n\n新光商事LSIデザインセンター株式会社\n\n\n組込エンジニアとして以下に従事 - 車載マイコンの機能開発 - インバータやモータの制御開発 \n\n\n\n\n\n\n2016/04 - 2018/07\n\n\nオークマ株式会社\n\n\nWindows アプリエンジニアとして以下に従事 - Windows 用 CAD/CAM アプリ開発の要件定義・テスト \n\n\n\n\n\n\nNo matching items\n\n\n\n3.2. 業務委託\n\n\n\n\n\n\nPeriod\n\n\n\nTitle\n\n\n\nDescription\n\n\n\n\n\n\n\n\n2025/06 - 現在\n\n\nPIVOT株式会社\n\n\nデータエンジニア \n\n\n\n\n\n\nNo matching items\n\n\n\n3.3. 最も苦労したプロジェクト\n現職の株式会社GENDAにて取り組んでいる以下です。 データ基盤の改修・データマート構築・ダッシュボード作成・全体の運用・データ分析支援といったデータに関すること全てを私が対応しており、プロジェクト進行上人員不足の面での課題に向き合い解消に向かっている最中です。\n[データ] カラオケ事業会社のデータ利活用推進 | 株式会社GENDA",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#今後取り組みたいこと",
    "href": "resume/index.html#今後取り組みたいこと",
    "title": "職務経歴書",
    "section": "4. 今後取り組みたいこと",
    "text": "4. 今後取り組みたいこと\n◆役割面： 直近：リーダー経験・マネジメント経験を積む 3-5年後：データ組織でリーダーシップを発揮し横断的にコミュニケーションを取りながらビジネス上の課題解決を目指す\n◆技術面： データ基盤管理者として各種サービスの知見を深める データ活用に繋がる分野 (BIツール・データカタログ・データマート作成など) へ積極関与する 特徴量作成・データマート改善のようにデータの観点から機械学習に貢献する AIを活用して開発環境改善やデータ分析の簡易化 (民主化) に貢献する",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#スキルレベル",
    "href": "resume/index.html#スキルレベル",
    "title": "職務経歴書",
    "section": "5. スキルレベル",
    "text": "5. スキルレベル\n業務経験のある技術スタックのみ記載しています。\n\n\n\n\n\n\n\n\n\n項目\n種類\n使用期間\nレベル\n\n\n\n\nIaC\nCloudFormation\n0.1年 \n既存テンプレートの修正が可能\n\n\nIaC\nDocker\n4年 \nDockerfile や Docker Compose の記述・実行が可能\n\n\nIaC\nGitHub / CodeCommit\n5年 \nGit flow や GitHub flow に則った開発利用やレビューが可能\n\n\nIaC\nGitHub Actions\n2年 \n既存ワークフロー改修 / CI/CD 向けのワークフロー作成 / GitHub Pages 関連のワークフロー作成が可能\n\n\nIaC\nTerraform\n2年 \nAWS / Google Cloud (特に BigQuery) / Snowflake を用いた基盤の修正作業や IaC 化が可能\n\n\nData\nBigQuery\n1年 \n管理者業務や IaC 化作業が可能\n\n\nData\nEmbulk\n0.5年 \n転送元 DB や 利用するインスタンス性能に応じたパフォーマンス改善が可能\n\n\nData\nTROCCO\n0.5年 \nジョブ作成・運用が可能\n\n\nData\ndbt Cloud\n1年 \nジョブ作成・運用が可能\n\n\nData\ndbt Core\n2年 \nプロジェクト新規作成から運用まで可能\n\n\nData / ML\nDatabricks\n1年 \n管理者業務や dbt Core との連携によるデータマート構築・ダッシュボード作成・機械学習環境整備が可能\n\n\nData / ML\nSnowflake\n3年 \nデータマート作成 / SQL パフォーマンス改善 / Snowpark ML 利用 / パラメータ管理が可能\n\n\nML\nDataRobot\n2年 \nオートパイロットや blueprint 固定でのモデルデプロイ・運用、API を利用した各種評価指標の取得の実装が可能\n\n\nOS\nAmazon Linux / Ubuntu\n5年 \n要件に応じた環境構築や開発環境利用が可能\n\n\nOS\nWindows\n9年 \n開発利用が可能\n\n\nOS\nmacOS\n2年 \n開発利用が可能\n\n\n言語\nC\n3年 \n一人称で作業可能\n\n\n言語\nPython\n5年 \n一人称で作業可能\n\n\n言語\nSQL\n4年 \n一人称で作業可能\n\n\n言語\nShell Script\n5年 \n一人称で作業可能\n\n\nCloud\nAWS\n4年 \nEC2 / ECS / RDS / StepFunctions / SageMaker / Cloud9 / MWAA (Airflow) 等を含む環境構築や作業が可能\n\n\nCloud\nGoogle Cloud\n1年 \nBigQuery 中心としたプロジェクトの管理者業務や Compute Engine / Cloud Functions / Datastream / BigQuery (後述) 等を含む環境構築や作業が可能\n\n\nDB\nMySQL\n2年 \nパフォーマンス調整のために必要なパラメータ調整の指示やデータ閲覧が可能\n\n\nDB\nPostgreSQL\n0.5年 \nローカル環境でのデータベース作成・データ閲覧が可能",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#資格",
    "href": "resume/index.html#資格",
    "title": "職務経歴書",
    "section": "6. 資格",
    "text": "6. 資格\n\n[2023/04] 統計検定2級\n[2015/03] TOEIC スコア 805",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/index.html#通常業務以外の活動",
    "href": "resume/index.html#通常業務以外の活動",
    "title": "職務経歴書",
    "section": "7. 通常業務以外の活動",
    "text": "7. 通常業務以外の活動\n\n7.1. 記事執筆・掲載\n\n\n\n日付\n所属\n概要\nリンク\n\n\n\n\n2025/09/01\n株式会社GENDA\nGENDA テックブログ執筆\nGENDAのデータサイエンティスト開発体験向上の取り組み紹介―AWS ECSからDatabricksへの移行\n\n\n2025/06/25\n株式会社GENDA\nnote 掲載\n成長を支えるハブとなりたい。データドリブンな組織を加速させるデータ基盤とMLOps｜GENDA\n\n\n2024/12 - 現在\n株式会社GENDA\nGENDA テックブログ執筆\numa-chanさんの記事一覧 - Zenn\n\n\n2024/10/08\n株式会社hacomono\nFindy Tools 様 特集記事掲載\n39社のデータ基盤アーキテクチャ特集 - ツールの技術選定のポイントと活用術 - Findy Tools\n\n\n2024/08/21\n株式会社hacomono\nFindy Tools 様 レビュー執筆\n株式会社hacomonoのBigQuery導入事例 - Findy Tools\n\n\n2024/07/02\n株式会社hacomono\nhacomono テックブログ執筆\nhacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG\n\n\n\n\n\n7.2. その他技術記事等\n\numa-chanさんの記事一覧 - Zenn\numa-chan’s page\n\n\n\n7.3. 登壇\n\n\n\n日付\n所属\n概要\nリンク\n\n\n\n\n2025/05/22\n株式会社GENDA\n[登壇先] AIネイティブ開発 Tips 1000本ノック (ミダスキャピタル投資先企業勉強会)\nCursorのおすすめ設定 & Cursorにデータ分析を任せる方法",
    "crumbs": [
      "Content",
      "Resume"
    ]
  },
  {
    "objectID": "resume/02-sld.html",
    "href": "resume/02-sld.html",
    "title": "新光商事LSIデザインセンター株式会社",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2022年時点)\n\n\n\n\n\n\n\n\n\n事業内容\n組込ソフトウェア開発、ASIC/FPGA 開発\n\n\n資本金\n8000万円\n\n\n売上高\n16.7億円\n\n\n従業員数\n83名\n\n\n上場／非上場\n非上場\n\n\n勤務地\n北海道札幌市(2020年3月以降はリモートワーク・週2出社)\n\n\n雇用形態\n正社員\n\n\n所属\n[2018/08 - 2022/03] ソフト開発一部 開発二課"
  },
  {
    "objectID": "resume/02-sld.html#親会社向け車両通信プロトコル解説講義",
    "href": "resume/02-sld.html#親会社向け車両通信プロトコル解説講義",
    "title": "新光商事LSIデザインセンター株式会社",
    "section": "1. 親会社向け車両通信プロトコル解説講義",
    "text": "1. 親会社向け車両通信プロトコル解説講義\n\n1.1. 期間\n\n2022/02 - 2022/03\n\n\n\n1.2. 担当業務\n\n車両組込システムの通信プロトコル (CAN) の説明資料作成\n組込システムへのCAN通信実装\n上記を利用した講義実施\n\n\n\n1.3. 担当フェーズ\n\nなし\n\n\n\n1.4. 開発環境\n\nC\nアセンブラ\nRenesas CS+ V8.05.00\nRH850/C1M-A1\n\n\n\n1.5. 規模・役割\n\n2名\nメンバー"
  },
  {
    "objectID": "resume/02-sld.html#噴霧器システム開発",
    "href": "resume/02-sld.html#噴霧器システム開発",
    "title": "新光商事LSIデザインセンター株式会社",
    "section": "2. 噴霧器システム開発",
    "text": "2. 噴霧器システム開発\n\n2.1. 期間\n\n2021/06 - 2022/01\n\n\n\n2.2. 担当業務\n\nプロトタイプ向け汎用インバータ制御開発\n顧客インバータ制御開発\n噴霧器の操作器開発\n\n\n\n2.3. 実績・取り組み\n\n顧客要望で解析用グラフ資料作成業務が発生した際に、自主的に習得していたPythonを用いて満足いただける資料を作成できました。\n\n\n\n2.4. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\n\n\n\n2.5. 開発環境\n\nC\nアセンブラ\nRenesas CS+ V8.05.00\nRL78/G1F\nRL78/G12\n\n\n\n2.6. 規模・役割\n\n4名\nメンバー"
  },
  {
    "objectID": "resume/02-sld.html#車両緊急通報システムのマイコン移植",
    "href": "resume/02-sld.html#車両緊急通報システムのマイコン移植",
    "title": "新光商事LSIデザインセンター株式会社",
    "section": "3. 車両緊急通報システムのマイコン移植",
    "text": "3. 車両緊急通報システムのマイコン移植\n\n3.1. 期間\n\n2020/10 - 2021/05\n\n\n\n3.2. 担当業務\n\nマイコン移植による故障懸念点の洗い出し\nマイコンのリソース割当検討\n各種タイマ機能とシリアル通信機能の移植\nテスト仕様書作成\nテスト実施\n\n\n\n3.3. 実績・取り組み\n\n5名が各々実施していた30以上のテスト仕様書のフォーマット整備をExcel VBAで自動化することで全員の負担を軽減し、特に経験の浅い1名の負担軽減に大きく貢献できました。\n\n\n\n3.4. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n3.5. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2020.1.5\nQAC 7.2.3\nRH850/F1K\n\n\n\n3.6. 規模・役割\n\n9名\nメンバー"
  },
  {
    "objectID": "resume/02-sld.html#自動車トラクション制御ファームウェアの無線更新機能の開発",
    "href": "resume/02-sld.html#自動車トラクション制御ファームウェアの無線更新機能の開発",
    "title": "新光商事LSIデザインセンター株式会社",
    "section": "4. 自動車トラクション制御ファームウェアの無線更新機能の開発",
    "text": "4. 自動車トラクション制御ファームウェアの無線更新機能の開発\n\n4.0.1. 期間\n\n2020/04 - 2020/09\n\n\n\n4.1. 担当業務\n\nバックアップ・更新処理の設計開発\nカバレッジテスト・単体テスト・結合テストの仕様書作成\nテスト実施\n\n\n\n4.2. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n4.3. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2013.5.5\nQAC 8.1.1J\nwinAMS v6.3.1\nRH850/C1M\n\n\n\n4.4. 規模・役割\n\n8名\nメンバー"
  },
  {
    "objectID": "resume/02-sld.html#自動車トラクション制御開発用ファームウェアの更新機能開発",
    "href": "resume/02-sld.html#自動車トラクション制御開発用ファームウェアの更新機能開発",
    "title": "新光商事LSIデザインセンター株式会社",
    "section": "5. 自動車トラクション制御開発用ファームウェアの更新機能開発",
    "text": "5. 自動車トラクション制御開発用ファームウェアの更新機能開発\n\n5.1. 期間\n\n2019/10 - 2020/03\n\n\n\n5.2. 担当業務\n\nトラクションモータ開発基板側の通信機能・自身のROM書き換え機能の設計開発\nPCアプリ含めたシステムのテスト仕様作成\nテスト実施\n\n\n\n5.3. 担当フェーズ\n\n要件分析\n基本設計\n詳細設計\n開発\nテスト\n\n\n\n5.4. 開発環境\n\nC\nアセンブラ\nGHS MULTI V2015.1.7\nRH850/C1M-A1\n\n\n\n5.5. 規模・役割\n\n6名\nメンバー"
  },
  {
    "objectID": "resume/01-okuma.html",
    "href": "resume/01-okuma.html",
    "title": "オークマ株式会社",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2018年時点)\n\n\n\n\n\n\n\n\n\n事業内容\nCNC工作機械、CNC装置・サーボモータ・位置検出器・ソフトウェアの開発・製造、販売\n\n\n資本金\n180億円\n\n\n売上高\n1600億円\n\n\n従業員数\n3407名\n\n\n上場／非上場\n上場\n\n\n勤務地\n愛知県\n\n\n雇用形態\n正社員\n\n\n所属\n[2016/04 - 2017/03] 人事部付[2017/04 - 2018/07] FAシステム本部 FA開発部 ITプラザ開発課"
  },
  {
    "objectID": "resume/01-okuma.html#windows7-向け対話形式-3d-cadcam-アプリケーション開発",
    "href": "resume/01-okuma.html#windows7-向け対話形式-3d-cadcam-アプリケーション開発",
    "title": "オークマ株式会社",
    "section": "1. Windows7 向け対話形式 3D-CAD/CAM アプリケーション開発",
    "text": "1. Windows7 向け対話形式 3D-CAD/CAM アプリケーション開発\n\n1.1. 期間\n\n2017/04 - 2018/07\n\n\n\n1.2. 担当業務\n\n大型アップデート用UI要件定義\nテスト仕様書作成\n結合テスト・システムテスト実施\nユーザ問い合わせ対応\n不具合対応\n\n\n\n1.3. 担当フェーズ\n\n要件定義\nテスト\n保守\n\n\n\n1.4. 開発環境\n\nWindows7\nC++\n\n\n\n1.5. 規模・役割\n\n10名\nメンバー"
  },
  {
    "objectID": "resume/01-okuma.html#windows7-向け-2d-cadcam-アプリケーション開発",
    "href": "resume/01-okuma.html#windows7-向け-2d-cadcam-アプリケーション開発",
    "title": "オークマ株式会社",
    "section": "2. Windows7 向け 2D-CAD/CAM アプリケーション開発",
    "text": "2. Windows7 向け 2D-CAD/CAM アプリケーション開発\n\n2.1. 期間\n\n2017/04 - 2018/07\n\n\n\n2.2. 担当業務\n\nテスト仕様書作成\n結合テスト・システムテスト実施\nユーザ問い合わせ対応\n受注先の工作機械に応じたチューニング\n\n\n\n2.3. 担当フェーズ\n\nテスト\n保守\n\n\n\n2.4. 開発環境\n\nWindows7\nC++\n\n\n\n2.5. 規模・役割\n\n5名\nメンバー"
  },
  {
    "objectID": "resume/04-hacomono.html",
    "href": "resume/04-hacomono.html",
    "title": "株式会社hacomono",
    "section": "",
    "text": "Table 1: 会社概要・雇用形態 (2024年時点)\n\n\n\n\n\n\n\n\n\n事業内容\n月額型店舗のための会員管理・予約・キャッシュレス決済システム「hacomono」開発・販売\n\n\n資本金\n100百万円\n\n\n売上高\n非公開\n\n\n従業員数\n217名\n\n\n上場／非上場\n非上場\n\n\n雇用形態\n正社員\n\n\n勤務地\n東京都渋谷区 (フルリモート・年に数回出社)\n\n\n所属\n[2024/04 - 2024/08] 基盤本部 データ基盤部[2024/09 - 2024/10] データ本部 データ基盤部 (組織改編)"
  },
  {
    "objectID": "resume/04-hacomono.html#データ-顧客環境-bigquery-へのバッチ転送システム開発運用",
    "href": "resume/04-hacomono.html#データ-顧客環境-bigquery-へのバッチ転送システム開発運用",
    "title": "株式会社hacomono",
    "section": "1. [データ] 顧客環境 BigQuery へのバッチ転送システム開発・運用",
    "text": "1. [データ] 顧客環境 BigQuery へのバッチ転送システム開発・運用\n\n1.1. 概要\n\nhacomono アプリDBに蓄積されたデータを顧客環境 BigQuery へ日次バッチ転送するためのシステム開発・運用\n\n\n\n1.2. 期間\n\n2024/04 - 2024/10\n\n\n\n1.3. 規模・役割\n\n[2024/04 - 2024/05]\n\n役割：メンバー\n規模：2名\n\n[2024/06 - 2024/10]\n\n役割：リーダー\n規模：1名\n\n\n\n\n1.4. 担当業務\n\n[2024/04 - 2024/05] (2名) 定常運用業務・業務引き継ぎ\n[2024/06 - 2024/10] (私1名) 定常運用業務・障害対応\n\n\n\n1.5. 機能開発・実装詳細\n\nGitHub と Terraform (Terragrunt) を用いて以下の構成を実装します。\n\nRDS MySQL or Aurora MySQL をデータソースとして Embulk で顧客環境 BigQuery にデータ転送を行う\n\nシステム構成図は下記ブログをご参照ください。\n\nhacomonoデータ基盤におけるデータ転送の課題と今後の対応 - hacomono TECH BLOG\n\n\n\n\n1.6. 目的・背景\n\n顧客に向けて DWH 提供を行うサービスを開始するために暫定的に構築したシステムを運用し続けている状況です。\n\n\n\n1.7. 課題\n\n全量のデータを転送させているためデータ増加により転送時間が延びてしまい、具体的には以下の問題が起こるようになりました。\n\nRDS BurstBalance を使い切ることによる転送の不安定化が起こる\nデータソース側の DB で一時領域不足になる\n顧客約束の時刻に転送が間に合わなくなる\n\n\n\n\n1.8. 工夫した点\n\n問題発生源の特定のために Embulk のログやデータソースのメトリクスから真因を究明するよう努めました。\n\n\n\n1.9. 成果\n\n\nRDS BurstBalance を使い切ることによる転送の不安定化が起こる\n\n\nReadIOPS の数値が支配的だったため並列実行数を減らしたり、Embulk の読み込み量のパラメータを調整したりすることで BurstBalance を使い切らないまま可能な限り早く転送させるよう調整を行いました。\n\n\n1.10. 担当フェーズ\n\n運用\n保守\n\n\n\n1.11. 開発環境\n\nGitHub\nTerraform\nEmbulk\nAWS\n\nECS\nRDS MySQL\nAurora MySQL\nVPC\n\nGoogle Cloud\n\nBigQuery"
  },
  {
    "objectID": "resume/04-hacomono.html#データ-社内-bigquery-環境構築運用",
    "href": "resume/04-hacomono.html#データ-社内-bigquery-環境構築運用",
    "title": "株式会社hacomono",
    "section": "2. [データ] 社内 BigQuery 環境構築・運用",
    "text": "2. [データ] 社内 BigQuery 環境構築・運用\n\n2.1. 概要\n\nhacomono プロダクトのデータベースから BigQuery へデータを転送し社内向けに DWH を作成するシステムの運用・保守\n\n\n\n2.2. 期間\n\n2024/04 - 2024/10\n\n\n\n2.3. 規模・役割\n\n[2024/04 - 2024/05]\n\n役割：メンバー\n規模：2名\n\n[2024/06 - 2024/10]\n\n役割：リーダー\n規模：1名\n\n\n\n\n2.4. 担当業務\n\n[2024/04 - 2024/05] (2名) 定常運用業務・業務引き継ぎ\n[2024/06 - 2024/10] (私1名) 定常運用業務・運用改善業務\n\n\n\n2.5. 機能開発・実装詳細\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\n\n2.6. 目的・背景\n\n社内の分析需要に応えるために権限管理の行き届いた新しい BigQuery 環境を構築・運用が必要となりました。\n\n\n\n2.7. 課題\n\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\n概ね IaC 対応が済んでいましたが権限追加に関してはコンソールからの手動追加対応となっておりました。これにより環境差分が生じ terraform apply が通らなくなる状況でした。\n\n\n2.8. 工夫した点\n\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\n権限を最小限に留めるためにプロジェクトレベルでの権限付与をせず、データセット毎に権限を付与する運用に変更しました。\n\n\n2.9. 成果\n\n\n(新規実装) Google Cloud プロジェクトと BigQuery の権限管理機能\n\n\nIaC 化により権限の種類とユーザーを CSV ファイルに集約でき、権限付与状況をリポジトリで管理できるようになりました。\n\n\n2.10. 担当フェーズ\n\n運用\n保守\n\n\n\n2.11. 開発環境\n\nGitHub\nTerraform\nEmbulk\nAWS\n\nECS\nRDS MySQL\nAurora MySQL\nVPC\n\nGoogle Cloud\n\nBigQuery"
  },
  {
    "objectID": "resume/04-hacomono.html#データ-顧客環境-bigquery-へのリアルタイム転送システム開発運用",
    "href": "resume/04-hacomono.html#データ-顧客環境-bigquery-へのリアルタイム転送システム開発運用",
    "title": "株式会社hacomono",
    "section": "3. [データ] 顧客環境 BigQuery へのリアルタイム転送システム開発・運用",
    "text": "3. [データ] 顧客環境 BigQuery へのリアルタイム転送システム開発・運用\n\n3.1. 概要\n\nhacomono に蓄積されたデータを顧客環境 BigQuery へリアルタイム転送するためのシステム開発・運用\n2024年8月まで開発を続けていましたが、契約締結できず検証段階で開発を中断しています。\n\n\n\n3.2. 期間\n\n2024/04 - 2024/08\n\n\n\n3.3. 規模・役割\n\n[2024/04 - 2024/05]\n\n役割：メンバー\n規模：2名\n\n[2024/06 - 2024/08]\n\n役割：リーダー\n規模：2名\n\n\n\n\n3.4. 担当業務\n\n[2024/04 - 2024/05] (2名) 開発引き継ぎ\n[2024/06 - 2024/08] 主機能開発・進捗管理\n\n\n\n3.5. 機能開発・実装詳細\n\nGitHub と Terraform (Terragrunt) を用いて以下の構成を実装します。\n\n[主機能] RDS MySQL のデータを Datastream によってリアルタイムに転送させる\n\n(新規実装) [周辺機能] ログ出力\n\n\n\n\n\n3.6. 目的・背景\n\n顧客要望がありリアルタイム性を重視したテーブルに絞って機能を提供することとなりました。\n個社向け開発として進めていますが他社への展開も可能な状態に整備する必要があります。\n\n\n\n3.7. 課題\n\n前任者から引き継いだ状態のリポジトリが雑然としており各社向けの設定ファイルを切り替えることができず大規模なリファクタリングが必要でした。\nDatastream の知見のある方が社内にいないため障害発生時の対応のノウハウがない状態でした。\n\n\n\n3.8. 成果\n\n\nDatastream の知見のある方が社内にいないため障害発生時の対応のノウハウがない状態でした。\n\n\nRDS 再起動による接続断から復旧する必要がありストリームの復元を行うことがありましたが、この経験により障害発生時に欠損し得るデータに関して説明ができるようになりました。\n本機能のオプションサービス化にあたり懸念事項の解像度を上げ、サービスのマニュアル更新の準備に役立てることができました。\n\n\n3.9. 担当フェーズ\n\n詳細設計\n開発\nテスト\n運用\n保守\n\n\n\n3.10. 開発環境\n\nGitHub\nTerraform\nTerragrunt\nAWS\n\nRDS MySQL\nVPC\n\nGoogle Cloud\n\nBigQuery\nDatastream"
  },
  {
    "objectID": "resume/04-hacomono.html#その他-開発業務以外の活動",
    "href": "resume/04-hacomono.html#その他-開発業務以外の活動",
    "title": "株式会社hacomono",
    "section": "4. [その他] 開発業務以外の活動",
    "text": "4. [その他] 開発業務以外の活動\n\n4.1. 記事執筆\n下記ページをご確認ください。\n通常業務以外の活動 | 職務経歴書"
  },
  {
    "objectID": "slides/2025-06-03-self-introduction-1page.html#プロフィール",
    "href": "slides/2025-06-03-self-introduction-1page.html#プロフィール",
    "title": "自己紹介",
    "section": "1. プロフィール",
    "text": "1. プロフィール\n\n\nDaiki Mawatari / 馬渡大樹 / uma-chan\n\n職歴\n\n\n\n2016 - 2022\n組込エンジニアなど\n\n\n2022 - 2024\n2社でデータエンジニア・MLOpsエンジニア\n\n\n2024.11-\nGENDA データエンジニア・MLOpsエンジニア\n\n\n2025.06-\nPIVOT データエンジニア 業務委託\n\n\n\n好きなもの\n\n音楽ゲーム (DanceDanceRevolution・beatmania IIDX)\nテキストエディタ等のツール\n\n\n\n\n\n\n\n\n\n\n\nGitHub 等で利用しているアイコン"
  },
  {
    "objectID": "slides/2025-05-22-midas-cursor-tips.html#はじめに",
    "href": "slides/2025-05-22-midas-cursor-tips.html#はじめに",
    "title": "Cursorのおすすめ設定 & Cursorにデータ分析を任せる方法",
    "section": "1. はじめに",
    "text": "1. はじめに"
  },
  {
    "objectID": "slides/2025-05-22-midas-cursor-tips.html#cursor-のおすすめ設定",
    "href": "slides/2025-05-22-midas-cursor-tips.html#cursor-のおすすめ設定",
    "title": "Cursorのおすすめ設定 & Cursorにデータ分析を任せる方法",
    "section": "2. Cursor のおすすめ設定",
    "text": "2. Cursor のおすすめ設定"
  },
  {
    "objectID": "slides/2025-05-22-midas-cursor-tips.html#まとめ",
    "href": "slides/2025-05-22-midas-cursor-tips.html#まとめ",
    "title": "Cursorのおすすめ設定 & Cursorにデータ分析を任せる方法",
    "section": "3. まとめ",
    "text": "3. まとめ"
  },
  {
    "objectID": "slides/2023-12-16-sapporo.vim.html#自己紹介",
    "href": "slides/2023-12-16-sapporo.vim.html#自己紹介",
    "title": "Sapporo.vim 自己紹介",
    "section": "1. 自己紹介",
    "text": "1. 自己紹介\n\n[HN] i9wa4 (いくわよ)\n[札幌在住歴] 9年\n[仕事] 直近1.5年は AWS データ分析基盤業務 (MLOps)\n[最近の Vim 活]\n\nLinter 利用構成変更 “mason.nvim + null-ls.nvim” -&gt; “makeprg”\nMarkdown Formatter (Denops プラグイン) 作成"
  },
  {
    "objectID": "slides/2023-12-16-sapporo.vim.html#本日のタスク",
    "href": "slides/2023-12-16-sapporo.vim.html#本日のタスク",
    "title": "Sapporo.vim 自己紹介",
    "section": "2. 本日のタスク",
    "text": "2. 本日のタスク\n\ndein.vim -&gt; dpp.vim 移行\nVim の LSP 環境整備\nefm-langserver 導入\nvital.vim の中身チェック\nddu.vim 導入\nfish 導入"
  },
  {
    "objectID": "slides/2023-12-16-sapporo.vim.html#本日の成果",
    "href": "slides/2023-12-16-sapporo.vim.html#本日の成果",
    "title": "Sapporo.vim 自己紹介",
    "section": "3. 本日の成果",
    "text": "3. 本日の成果\n\ndein.vim -&gt; dpp.vim 移行\n\n\n遅延なしプラグインの起動までできた\nこのあとは遅延起動プラグイン対応のために設定ファイル (TypeScript) を書きたい"
  },
  {
    "objectID": "blog/2024-12-23-my-first-dashboard-building.html",
    "href": "blog/2024-12-23-my-first-dashboard-building.html",
    "title": "データエンジニアが初めてダッシュボードを作成して気づいたこと",
    "section": "",
    "text": "データエンジニア3年目にして初めてダッシュボードを作成する機会を得たので時系列順に思ったことを書いていきます。"
  },
  {
    "objectID": "blog/2024-12-23-my-first-dashboard-building.html#はじめに",
    "href": "blog/2024-12-23-my-first-dashboard-building.html#はじめに",
    "title": "データエンジニアが初めてダッシュボードを作成して気づいたこと",
    "section": "",
    "text": "データエンジニア3年目にして初めてダッシュボードを作成する機会を得たので時系列順に思ったことを書いていきます。"
  },
  {
    "objectID": "blog/2024-12-23-my-first-dashboard-building.html#今回のダッシュボード作成の前提",
    "href": "blog/2024-12-23-my-first-dashboard-building.html#今回のダッシュボード作成の前提",
    "title": "データエンジニアが初めてダッシュボードを作成して気づいたこと",
    "section": "2. 今回のダッシュボード作成の前提",
    "text": "2. 今回のダッシュボード作成の前提\n\n2.1. 要望\n弊社グループ企業の担当者が毎日 Excel で KPI 算出や社内に向けたサマリ配信を行っており、ダッシュボード導入によりこの作業を自動化していこうという要望がありました。所謂 DX の一環です。\n\n\n2.2. 技術要素\n\nダッシュボードは Databricks で作成する\nその他要素は主題ではないので割愛する"
  },
  {
    "objectID": "blog/2024-12-23-my-first-dashboard-building.html#ダッシュボード作成前に考えていたこと",
    "href": "blog/2024-12-23-my-first-dashboard-building.html#ダッシュボード作成前に考えていたこと",
    "title": "データエンジニアが初めてダッシュボードを作成して気づいたこと",
    "section": "3. ダッシュボード作成前に考えていたこと",
    "text": "3. ダッシュボード作成前に考えていたこと\n\n3.1. なぜ今までダッシュボード作成をしてこなかったのか\n\n3.1.1. データエンジニアはデータ基盤タスクに追われている\nダッシュボードは SQL が理解できれば作成できますが、データ基盤に関するタスクはデータエンジニアでないと対応できません。そしてデータエンジニアは人員不足であることが多いので基本的にデータエンジニアはデータ基盤に張り付くことになります。\n私はこのような経験をしてきましたが実際多くの企業で普遍的に起きていることではないでしょうか。\n\n\n3.1.2. そもそもダッシュボードを新規作成する機会が少ない\n一旦主要なダッシュボードを作成してしまえば作業が落ち着いてしまうことが多く、ダッシュボードを新規作成する機会を継続的にもてる方は少ないと思います。\n私の経験してきた中では新しくダッシュボードが作られる場面は少なかったです。\n\n\n\n3.2. 業務に対する心境の変化\nこれまではエンジニアとしてこの先生きのこるにはできるだけ技術を身につけていくべき、という強迫観念に突き動かされていたので技術的に新規性が少ないダッシュボード作成には積極的に手を挙げようとはあまり思っていませんでした。\nただ、データエンジニアが自分しかいない環境を経験して、自分でもやれば何とかなるという自己効力感をもてたことでこの強迫観念に関しては一定程度薄れたと思います。やればできるのであれば焦る必要もないという気持ちをもてるようになりました。\nそして社会人として働く自分の実際のモチベーションとしては、目の前の同僚の役に立つことをしたい、あるいは苦労して構築運用がなされているデータ基盤の価値を高めたい、といった思いが強いことを自覚するようになりました。ダッシュボード作成はこのような自分の特性に結構マッチしたタスクだと思います。\nこのような経緯があり今回のダッシュボード作成タスクに手を挙げて取り組むことになりました。"
  },
  {
    "objectID": "blog/2024-12-23-my-first-dashboard-building.html#ダッシュボード作成中に考えていること",
    "href": "blog/2024-12-23-my-first-dashboard-building.html#ダッシュボード作成中に考えていること",
    "title": "データエンジニアが初めてダッシュボードを作成して気づいたこと",
    "section": "4. ダッシュボード作成中に考えていること",
    "text": "4. ダッシュボード作成中に考えていること\n実は自分が携わっているダッシュボードは現在作成中です。作成して利用いただいた後の状況は今後追いかけていきます。\n\n4.1. Databricks 上でのダッシュボード作成 Tips\n本記事中唯一の技術要素です。 いずれも特に Databricks 特有のものではありませんが、使ってみて良いなと思った機能を一応メモしておきます。\n\nパラメータ\n\nドロップダウンリストで選択した値やフォームに入力した値をパラメータ経由でクエリに組み込むことができます。\n\nWork with dashboard parameters | Databricks on AWS\n\n\nピボットテーブル\n\nサクッと集計テーブルを作成できます。Excel やスプレッドシートで活用してたので特に抵抗なく使えました。\n\nDashboard visualizations types | Databricks on AWS\n\n\nSQL フォーマット\n\n残念ながらダッシュボード内では利用できませんが Databricks で SQL フォーマットが利用できるので時々利用しています。\n\nWrite queries and explore data in the SQL editor | Databricks on AWS\n\nノートブックのセルでも利用できます。私は使い捨てのクエリをノートブックで管理してるので助かります。\nちょっとクセの強いフォーマットをしてくるので賛否両論あると思います。\n\n\n\n\n4.2. 弊社におけるダッシュボード作成の感想\n今回のダッシュボード作成作業は弊社本社メンバーと当該グループ企業メンバーとで取り組んでいます。全員当事者意識をもっているため、本当に意味のあるものを充実感をもって作れる環境であると感じました。\nまたデータチームにノウハウが蓄積していくため新たな企業をグループに迎え入れる際にはもっとスムーズに一連の作業を進めていけそうです。\nダッシュボードを一気に新規作成する機会も弊社の成長と共に継続的に訪れるのではないかと思います。\n\n\n4.3. データエンジニアはダッシュボードを作るべきか\nデータ利用者の立場に立った考え方ができるようになるので、データ基盤により磨きをかけて使いやすくしようと思える効果はありました。\nまたデータ自体に対する知識を深めていけるのもダッシュボード作成の良さで、さらなるデータ活用のための過程と捉えることもできます。私の場合はデータサイエンス系業務にも関わっているのでデータの知識を深めることはデータ分析や機械学習に活かすことのできる経験になっています。\nとはいえデータエンジニアリングスキルをもつ人間がデータ基盤タスクではなくデータ活用タスクに時間を投入しても許される環境でないと取り組むのは難しいので、ある種贅沢なことかもしれません。"
  },
  {
    "objectID": "blog/2024-12-23-my-first-dashboard-building.html#おわりに",
    "href": "blog/2024-12-23-my-first-dashboard-building.html#おわりに",
    "title": "データエンジニアが初めてダッシュボードを作成して気づいたこと",
    "section": "5. おわりに",
    "text": "5. おわりに\n結局やってみたいことに取り組んで納得感を得ることは良いことですね。今後もできるだけそうしたいです。"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html",
    "href": "blog/2025-07-28-article2-python-env.html",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "",
    "text": "本記事は3部構成の2本目です。"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#はじめに",
    "href": "blog/2025-07-28-article2-python-env.html#はじめに",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "1. はじめに",
    "text": "1. はじめに\n前回の Dev Container 環境に Python 開発環境を追加します。\nuv によるパッケージ管理と pre-commit による品質管理で、チーム開発でも個人開発でも快適な Python 環境を構築できます。"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#対象読者",
    "href": "blog/2025-07-28-article2-python-env.html#対象読者",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "2. 対象読者",
    "text": "2. 対象読者\n\nPython開発環境を効率化したい方\nチーム開発でコード品質を統一したい方\nVS Code以外のエディタでも同じ環境を使いたい方"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#uv-とは",
    "href": "blog/2025-07-28-article2-python-env.html#uv-とは",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "3. uv とは",
    "text": "3. uv とは\n今回利用している Python 環境管理ツールです。\nhttps://github.com/astral-sh/uv\n最低限理解しておくべき要点は以下です。\n\nuv 自体は Python エコシステムの外にあるツール\nインストールしたい Python パッケージを pyproject.toml で管理する\npyproject.toml のパッケージの依存関係解決結果を uv.lock に保存し環境の再現性を担保している"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#python-環境設定",
    "href": "blog/2025-07-28-article2-python-env.html#python-環境設定",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "4. Python 環境設定",
    "text": "4. Python 環境設定\nPython コーディング向け環境設定について説明していきます。\n基本的なライブラリと pre-commit で Black isort, flake8 を利用していきます。\n\n4.1. pyproject.toml\n\n\npyproject.toml\n\n[project]\nname = \"your-project-name\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \"~=3.13.0\"\ndependencies = [\n  \"ipykernel\",\n  \"jupyterlab\",\n  \"matplotlib\",\n  \"numpy\",\n  \"pandas\",\n  \"python-dotenv\",\n  \"requests\",\n  \"seaborn\",\n]\n\n[dependency-groups]\ndev = [\n  \"pre-commit~=4.2.0\",\n  \"black==25.1.0\",\n  \"isort==6.0.0\",\n  \"flake8==7.3.0\",\n  \"flake8-pyproject\",\n]\n\n[tool.black]\nline-length = 88\ntarget-version = ['py313']\n\n[tool.isort]\nprofile = \"black\"\nline_length = 88\n\n[tool.flake8]\nmax-line-length = 88\nextend-exclude = [\".venv\"]\nextend-ignore = [\n    \"E203\",  # Whitespace before ':'\n    \"E701\",  # Multiple statements on one line (colon)\n]\n\n\n\n4.2. pre-commit 設定\nFormatter設定をVS Codeから切り離すことでVS Code以外のエディタやGitHub Actionsでも利用できるようになります。\n\n\n.pre-commit-config.yaml\n\ndefault_stages: [pre-commit]\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-added-large-files\n      - id: check-json\n      - id: check-yaml\n      - id: detect-private-key\n      - id: end-of-file-fixer\n      - id: mixed-line-ending\n        args: [--fix=no]\n      - id: trailing-whitespace\n        args: [--markdown-linebreak-ext=md]\n\n  - repo: local\n    hooks:\n      - id: black\n        name: black\n        entry: uv run --no-sync black\n        language: system\n        types: [python]\n\n  - repo: local\n    hooks:\n      - id: isort\n        name: isort (python)\n        entry: uv run --no-sync isort\n        language: system\n        types: [python]\n\n  - repo: local\n    hooks:\n      - id: flake8\n        name: flake8\n        entry: uv run --no-sync flake8\n        language: system\n        types: [python]\n\n  - repo: https://github.com/gitleaks/gitleaks\n    rev: v8.28.0\n    hooks:\n      - id: gitleaks\n\n\n\n4.3. GitHub Actions での pre-commit\nGitHub Actionsでpre-commitを実行するための設定です。\n\n\n.github/workflows/pre-commit.yaml\n\nname: pre-commit\nrun-name: ${{ github.event_name }} on ${{ github.ref_name }} by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n    types:\n      - opened\n      - synchronize\n      - reopened\n\npermissions: {}\n\ndefaults:\n  run:\n    shell: bash\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  pre-commit:\n    runs-on: ubuntu-latest\n    timeout-minutes: 5\n    permissions:\n      contents: read\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          # プルリクエスト時はソースブランチ(github.head_ref)を、\n          # 手動実行時は実行対象ブランチ(github.ref_name)をチェックアウト\n          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref_name }}\n          persist-credentials: false\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v6\n        with:\n          version: \"0.8.3\"\n\n      - name: Set up Python\n        run: |\n          uv sync --only-group dev\n\n      - name: Cache pre-commit\n        uses: actions/cache@v4\n        with:\n          path: ~/.cache/pre-commit\n          key: |\n            pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}-${{ hashFiles('uv.lock') }}\n          # NOTE: 設定ファイルの変更時に必ずキャッシュを更新する\n          restore-keys: |\n            pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}-${{ hashFiles('uv.lock') }}\n\n      - name: Install pre-commit\n        run: |\n          uv run --no-sync pre-commit install\n\n      - name: Run pre-commit\n        run: |\n          uv run --no-sync pre-commit run --all-files"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#dev-container-への統合",
    "href": "blog/2025-07-28-article2-python-env.html#dev-container-への統合",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "5. Dev Container への統合",
    "text": "5. Dev Container への統合\n\n5.1. devcontainer.json の更新\n前回の devcontainer.json に以下の設定を追加します。\n{\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\n                \"editorconfig.editorconfig\",\n                \"elagil.pre-commit-helper\",\n                \"ms-python.python\",\n                \"ms-toolsai.jupyter\"\n            ]\n        }\n    },\n    \"remoteEnv\": {\n        \"UV_LINK_MODE\": \"copy\"\n    },\n    \"postStartCommand\": \"uv sync --frozen --group dev && uv run pre-commit install\"\n}\n\n\n5.2. JupyterLab 起動スクリプト\nVS Code ユーザーは不要ですが一応 JupyterLab を起動するスクリプトも用意しました。\nポートは自動割り当てにしています。\n\n\n\n\n\n\n5.2.1. .devcontainer/start-jupyter.sh\n\n\n\n\n\n\n\n.devcontainer/start-jupyter.sh\n\n#!/usr/bin/env bash\nset -o errexit\n\n# JupyterLab起動スクリプト\n# 快適な開発用\n\necho \"🔥 JupyterLab 環境を起動中...\"\n\n# ポート設定（環境変数または自動割り当て）\n# JUPYTER_PORT=8888 # NOTE: この行をコメントアウトすると自動ポート検索が有効になります\nJUPYTER_PORT=${JUPYTER_PORT:-0}\n\nif [ \"$JUPYTER_PORT\" = \"0\" ]; then\n  echo \"📡 利用可能なポートを自動検索中...\"\nelse\n  echo \"📡 指定ポート ${JUPYTER_PORT} で起動します\"\nfi\n\n# Python環境の確認\nif [ -f \"uv.lock\" ]; then\n  echo \"📦 uv環境を使用してJupyterLabを起動します\"\n  uv sync --frozen\n  nohup uv run jupyter lab --ip=0.0.0.0 --port=${JUPYTER_PORT} --no-browser --allow-root \\\n    --NotebookApp.token='' --NotebookApp.password='' \\\n    --ServerApp.allow_origin='*' --ServerApp.disable_check_xsrf=True &gt;/dev/null 2&gt;&1 &\nelif [ -d \".venv\" ]; then\n  echo \"📦 venv環境を使用してJupyterLabを起動します\"\n  source .venv/bin/activate\n  nohup jupyter lab --ip=0.0.0.0 --port=${JUPYTER_PORT} --no-browser --allow-root \\\n    --NotebookApp.token='' --NotebookApp.password='' \\\n    --ServerApp.allow_origin='*' --ServerApp.disable_check_xsrf=True &gt;/dev/null 2&gt;&1 &\nelse\n  echo \"❌ Python仮想環境が見つかりません\"\n  echo \"uvまたはvenvで環境をセットアップしてください\"\n  exit 1\nfi\n\n# 実際に割り当てられたポートを取得（リトライ機能付き）\nfor i in {1..10}; do\n  sleep 1\n  ACTUAL_PORT=$(ss -tlnp 2&gt;/dev/null | grep jupyter-lab | awk '{print $4}' | cut -d: -f2 | head -1)\n  if [ -n \"$ACTUAL_PORT\" ]; then\n    break\n  fi\ndone\n\nif [ \"$JUPYTER_PORT\" = \"0\" ] && [ -n \"$ACTUAL_PORT\" ]; then\n  echo \"🌐 JupyterLabは http://localhost:${ACTUAL_PORT}/lab でアクセス可能です\"\nelse\n  echo \"🌐 JupyterLabは http://localhost:${JUPYTER_PORT}/lab でアクセス可能です\"\nfi"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#python-仮想環境更新手順",
    "href": "blog/2025-07-28-article2-python-env.html#python-仮想環境更新手順",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "6. Python 仮想環境更新手順",
    "text": "6. Python 仮想環境更新手順\n\n必要に応じて .python-version や pyproject.toml を更新します。\nuv.lock を更新します。\n$ uv lock --upgrade\n.venv を更新します。\n$ uv sync --frozen --group dev\n\n\n6.1. パッケージ追加手順\n# 新しいパッケージを追加\nuv add pandas matplotlib\n\n# 開発用パッケージを追加\nuv add --group dev pytest"
  },
  {
    "objectID": "blog/2025-07-28-article2-python-env.html#おわりに",
    "href": "blog/2025-07-28-article2-python-env.html#おわりに",
    "title": "Python 開発環境最適化編 - uv + pre-commit + GitHub Actions",
    "section": "7. おわりに",
    "text": "7. おわりに\nこれで Python 開発環境が完成しました。\n次回はこの環境に Databricks Connect を追加してクラウドデータウェアハウスと連携する方法を紹介します。\nDatabricks Connect 実践編 - ローカルから Databricks コンピュートを利用"
  },
  {
    "objectID": "blog/2024-05-05-deploy-quarto.html",
    "href": "blog/2024-05-05-deploy-quarto.html",
    "title": "Quarto で作ったスライドを GitHub Pages にデプロイする",
    "section": "",
    "text": "スライドをできるだけ Git で管理したいので Markdown をスライドに変換する方向性で色々なツールを比較検討していて、 Quarto (https://quarto.org/) に決めました。\n.qmd ファイルという見慣れないファイルを利用しますが、利点としては以下ですね。\n\n環境構築が pip で完了する\nVS Code で開くと Jupyter Notebook っぽくセルを実行できる"
  },
  {
    "objectID": "blog/2024-05-05-deploy-quarto.html#前提",
    "href": "blog/2024-05-05-deploy-quarto.html#前提",
    "title": "Quarto で作ったスライドを GitHub Pages にデプロイする",
    "section": "",
    "text": "スライドをできるだけ Git で管理したいので Markdown をスライドに変換する方向性で色々なツールを比較検討していて、 Quarto (https://quarto.org/) に決めました。\n.qmd ファイルという見慣れないファイルを利用しますが、利点としては以下ですね。\n\n環境構築が pip で完了する\nVS Code で開くと Jupyter Notebook っぽくセルを実行できる"
  },
  {
    "objectID": "blog/2024-05-05-deploy-quarto.html#やったこと",
    "href": "blog/2024-05-05-deploy-quarto.html#やったこと",
    "title": "Quarto で作ったスライドを GitHub Pages にデプロイする",
    "section": "2. やったこと",
    "text": "2. やったこと\n下記リポジトリを整備しました。\nhttps://github.com/i9wa4/slides\nREADME.md にも書いてますが\nQuartoでスライドを作ってGitHub Pagesで公開する #GitHubActions - Qiita\nを参考にしてます。"
  },
  {
    "objectID": "blog/2024-05-05-deploy-quarto.html#感想",
    "href": "blog/2024-05-05-deploy-quarto.html#感想",
    "title": "Quarto で作ったスライドを GitHub Pages にデプロイする",
    "section": "3. 感想",
    "text": "3. 感想\nGitHub Actions はまだよく分かってないままなのですが、一旦動くようになってよかったです。"
  },
  {
    "objectID": "blog/2024-07-20-minecraft-note.html",
    "href": "blog/2024-07-20-minecraft-note.html",
    "title": "自分用 Minecraft メモ",
    "section": "",
    "text": "Minecraft の自分用メモを公開しておきます。"
  },
  {
    "objectID": "blog/2024-07-20-minecraft-note.html#todo",
    "href": "blog/2024-07-20-minecraft-note.html#todo",
    "title": "自分用 Minecraft メモ",
    "section": "1. TODO",
    "text": "1. TODO\n\n地下トラップタワー (経験値自動取得)\n倉庫チェスト再設計\n武器防具予備作成\nエンチャント本予備作成\n羊毛仕分け\n山削り\n苔式骨粉製造機\n襲撃者トラップ@前哨基地 1880 632\n弓作り直し\nエンダーチェスト\nエンダードラゴン\nポーション醸造所\nウーパールーパー"
  },
  {
    "objectID": "blog/2024-07-20-minecraft-note.html#座標メモ",
    "href": "blog/2024-07-20-minecraft-note.html#座標メモ",
    "title": "自分用 Minecraft メモ",
    "section": "2. 座標メモ",
    "text": "2. 座標メモ\n\n\n\nX\nY\nZ\nDescription\n\n\n\n\n-32\n15\n26\nゾンビスポナー\n\n\n112\n59\n8\nゾンビスポナー\n\n\n338\n-28\n-148\nゾンビスポナー"
  },
  {
    "objectID": "blog/2024-07-20-minecraft-note.html#エンチャント",
    "href": "blog/2024-07-20-minecraft-note.html#エンチャント",
    "title": "自分用 Minecraft メモ",
    "section": "3. エンチャント",
    "text": "3. エンチャント\n\n3.1. 防具\n\n共通\n\n修繕I\n耐久力III\nダメージ軽減IV\n\nヘルメット\n\n水中採掘\n水中呼吸III\n\nチェストプレート\nレギンス\n\nスニーク速度上昇\n\nブーツ\n\n水中歩行III\n落下耐性IV\n\n\n\n\n3.2. 武器\n\n共通\n\n修繕I\n耐久力III\n\n剣\n\n火属性II\nドロップ増加III\nノックバックII\nダメージ増加V\n\n弓\n\nフレイム\n射撃ダメージ増加V\nパンチII\n無限\n\nクロスボウ\n\n高速充填III\n貫通IV\n\nトライデント\n\n水性特攻V\n忠誠III\n召雷\n\n\n\n\n3.3. 道具\n\n共通\n\n修繕I\n耐久力III\n効率強化V\n幸運III or シルクタッチ"
  },
  {
    "objectID": "blog/2024-07-20-minecraft-note.html#村人職業設計",
    "href": "blog/2024-07-20-minecraft-note.html#村人職業設計",
    "title": "自分用 Minecraft メモ",
    "section": "4. 村人職業設計",
    "text": "4. 村人職業設計\n\n司書 書見台 (20)\n\nTier1 (10)\n\n修繕I (2)\n耐久力III (2)\n効率強化V (2)\n幸運III (1)\nシルクタッチ (1)\nダメージ軽減IV (2)\n\nTier2 (10)\n\n水中採掘\n水中呼吸III\n水中歩行III\n落下耐性IV\n火属性II\nドロップ増加III\nノックバックII\nダメージ増加V\nフレイム\n射撃ダメージ増加V\n\n\n武器鍛冶 石臼 (1)\n防具鍛冶 溶鉱炉 (2)\n道具鍛冶 鍛冶台 (1+6)\n石工 石切台 ()\n\nクォーツブロック\nテラコッタ\nレンガ"
  },
  {
    "objectID": "blog/2025-04-16-issue-with-python-libraries.html",
    "href": "blog/2025-04-16-issue-with-python-libraries.html",
    "title": "Python でありがちな本体バージョンとライブラリバージョンの不整合の例",
    "section": "",
    "text": "ライブラリのバージョンを固定した上で最新のバージョンの Python を使おうとすると色々とエラーが発生しがちです。\n直近遭遇したエラーを記録に残しておきます。"
  },
  {
    "objectID": "blog/2025-04-16-issue-with-python-libraries.html#はじめに",
    "href": "blog/2025-04-16-issue-with-python-libraries.html#はじめに",
    "title": "Python でありがちな本体バージョンとライブラリバージョンの不整合の例",
    "section": "",
    "text": "ライブラリのバージョンを固定した上で最新のバージョンの Python を使おうとすると色々とエラーが発生しがちです。\n直近遭遇したエラーを記録に残しておきます。"
  },
  {
    "objectID": "blog/2025-04-16-issue-with-python-libraries.html#背景",
    "href": "blog/2025-04-16-issue-with-python-libraries.html#背景",
    "title": "Python でありがちな本体バージョンとライブラリバージョンの不整合の例",
    "section": "2. 背景",
    "text": "2. 背景\ndbt-databricks==1.7.17 のインストールを試みました。\n本来は最新バージョンをインストールすべきで、執筆時点では 1.10.0 です。 このコマンドを知らなかったのでメモ代わりに残しておきます。\n$ pip index versions dbt-databricks\nWARNING: pip index is currently an experimental command. It may be removed/changed in a future release without prior warning.\ndbt-databricks (1.10.0)\nAvailable versions: 1.10.0, 1.9.7, 1.9.6, 1.9.5, 1.9.4, 1.9.2, 1.9.1, 1.9.0, 1.8.7, 1.8.6, 1.8.5, 1.8.4, 1.8.3, 1.8.2, 1.8.1, 1.8.0, 1.7.17, 1.7.16, 1.7.15, 1.7.14, 1.7.13, 1.7.11, 1.7.10, 1.7.9, 1.7.8, 1.7.7, 1.7.3, 1.7.2, 1.7.1, 1.7.0, 1.6.9, 1.6.8, 1.6.7, 1.6.6, 1.6.5, 1.6.4, 1.6.3, 1.6.2, 1.6.1, 1.6.0, 1.5.7, 1.5.6, 1.5.5, 1.5.4, 1.5.3, 1.5.2, 1.5.1, 1.5.0, 1.4.3, 1.4.2, 1.4.1, 1.4.0, 1.3.2, 1.3.1, 1.3.0, 1.2.5, 1.2.4, 1.2.3, 1.2.2, 1.2.1, 1.2.0, 1.1.7, 1.1.6, 1.1.5, 1.1.4, 1.1.3, 1.1.2, 1.1.1, 1.1.0, 1.0.3, 1.0.2, 1.0.1, 1.0.0, 0.21.1\n以下では Python 3.13 と 3.12 の両方で試してみます。"
  },
  {
    "objectID": "blog/2025-04-16-issue-with-python-libraries.html#python-3.13.3-との相性",
    "href": "blog/2025-04-16-issue-with-python-libraries.html#python-3.13.3-との相性",
    "title": "Python でありがちな本体バージョンとライブラリバージョンの不整合の例",
    "section": "3. Python 3.13.3 との相性",
    "text": "3. Python 3.13.3 との相性\n\n\n\n\n\n\n3.1. details エラーログ詳細\n\n\n\n\n\n$ python --version\nPython 3.13.3\n\n$ python -m venv my-venv-3.13.3\n\n$ source my-venv-3.13.3/bin/activate\n(my-venv-3.13.3)\n$ pip install dbt-databricks==1.7.17\nCollecting dbt-databricks==1.7.17\n  Using cached dbt_databricks-1.7.17-py3-none-any.whl.metadata (5.6 kB)\nCollecting dbt-spark~=1.7.1 (from dbt-databricks==1.7.17)\n  Using cached dbt_spark-1.7.1-py3-none-any.whl.metadata (5.3 kB)\nCollecting databricks-sql-connector&lt;3.0.0,&gt;=2.9.3 (from dbt-databricks==1.7.17)\n  Using cached databricks_sql_connector-2.9.6-py3-none-any.whl.metadata (4.3 kB)\nCollecting databricks-sdk==0.17.0 (from dbt-databricks==1.7.17)\n  Using cached databricks_sdk-0.17.0-py3-none-any.whl.metadata (34 kB)\nCollecting keyring&gt;=23.13.0 (from dbt-databricks==1.7.17)\n  Using cached keyring-25.6.0-py3-none-any.whl.metadata (20 kB)\nCollecting pandas&lt;2.2.0 (from dbt-databricks==1.7.17)\n  Using cached pandas-2.1.4.tar.gz (4.3 MB)\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... error\n  error: subprocess-exited-with-error\n\n  × Preparing metadata (pyproject.toml) did not run successfully.\n  │ exit code: 1\n  ╰─&gt; [115 lines of output]\n      + meson setup /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88 /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/.mesonpy-iz9fcfer/build -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=/private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/.mesonpy-iz9fcfer/build/meson-python-native-file.ini\n      The Meson build system\n      Version: 1.2.1\n      Source dir: /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88\n      Build dir: /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/.mesonpy-iz9fcfer/build\n      Build type: native build\n      Project name: pandas\n      Project version: 2.1.4\n      C compiler for the host machine: cc (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.3)\")\n      C linker for the host machine: cc ld64 1167.4.1\n      C++ compiler for the host machine: c++ (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.3)\")\n      C++ linker for the host machine: c++ ld64 1167.4.1\n      Cython compiler for the host machine: cython (cython 0.29.37)\n      Host machine cpu family: aarch64\n      Host machine cpu: aarch64\n      Program python found: YES (/Users/uma-chan/.venv/my-venv-3.13.3/bin/python)\n      Did not find pkg-config by name 'pkg-config'\n      Found Pkg-config: NO\n      Run-time dependency python found: YES 3.13\n      Build targets in project: 53\n\n      pandas 2.1.4\n\n        User defined options\n          Native files: /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/.mesonpy-iz9fcfer/build/meson-python-native-file.ini\n          buildtype   : release\n          vsenv       : True\n          b_ndebug    : if-release\n          b_vscrt     : md\n\n      Found ninja-1.12.1 at /opt/homebrew/bin/ninja\n\n      Visual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:\n      /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-build-env-i26gzs0z/overlay/bin/meson compile -C .\n      + /opt/homebrew/bin/ninja\n      [1/151] Generating pandas/_libs/index_class_helper_pxi with a custom command\n      [2/151] Generating pandas/_libs/hashtable_class_helper_pxi with a custom command\n      [3/151] Generating pandas/_libs/algos_common_helper_pxi with a custom command\n      [4/151] Generating pandas/_libs/algos_take_helper_pxi with a custom command\n      [5/151] Generating pandas/_libs/intervaltree_helper_pxi with a custom command\n      [6/151] Generating pandas/_libs/hashtable_func_helper_pxi with a custom command\n      [7/151] Generating pandas/_libs/khash_primitive_helper_pxi with a custom command\n      [8/151] Generating pandas/_libs/sparse_op_helper_pxi with a custom command\n      [9/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/base.pyx\n      [10/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/ccalendar.pyx\n      [11/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/dtypes.pyx\n      [12/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/np_datetime.pyx\n      [13/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/nattype.pyx\n      [14/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/conversion.pyx\n      [15/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/strptime.pyx\n      [16/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/fields.pyx\n      [17/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/parsing.pyx\n      [18/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/offsets.pyx\n      [19/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/timezones.pyx\n      [20/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/timedeltas.pyx\n      [21/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/period.pyx\n      [22/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/vectorized.pyx\n      [23/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/tzconversion.pyx\n      [24/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/indexing.pyx\n      [25/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/arrays.pyx\n      [26/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslibs/timestamps.pyx\n      [27/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/missing.pyx\n      [28/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/hashing.pyx\n      [29/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/ops_dispatch.pyx\n      [30/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/properties.pyx\n      [31/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/ops.pyx\n      [32/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/internals.pyx\n      [33/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/byteswap.pyx\n      [34/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/parsers.pyx\n      [35/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/index.pyx\n      [36/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/sas.pyx\n      [37/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/lib.pyx\n      [38/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/reshape.pyx\n      [39/151] Compiling C object pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o\n      FAILED: pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o\n      cc -Ipandas/_libs/tslibs/base.cpython-313-darwin.so.p -Ipandas/_libs/tslibs -I../../pandas/_libs/tslibs -I../../../../pip-build-env-i26gzs0z/overlay/lib/python3.13/site-packages/numpy/core/include -I../../pandas/_libs/include -I/Users/uma-chan/.pyenv/versions/3.13.3/include/python3.13 -fvisibility=hidden -fcolor-diagnostics -DNDEBUG -w -std=c99 -O3 -DNPY_NO_DEPRECATED_API=0 -DNPY_TARGET_VERSION=NPY_1_21_API_VERSION -MD -MQ pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o -MF pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o.d -o pandas/_libs/tslibs/base.cpython-313-darwin.so.p/meson-generated_pandas__libs_tslibs_base.pyx.c.o -c pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c\n      pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c:5399:70: error: too few arguments to function call, expected 6, have 5\n       5397 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n            |                           ~~~~~~~~~~~~~~~~~~~\n       5398 |                                               bytes, sizeof(val),\n       5399 |                                               is_little, !is_unsigned);\n            |                                                                      ^\n      /Users/uma-chan/.pyenv/versions/3.13.3/include/python3.13/cpython/longobject.h:111:17: note: '_PyLong_AsByteArray' declared here\n        111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n            |                 ^                   ~~~~~~~~~~~~~~~~\n        112 |     unsigned char* bytes, size_t n,\n            |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        113 |     int little_endian, int is_signed, int with_exceptions);\n            |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n      pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c:5633:70: error: too few arguments to function call, expected 6, have 5\n       5631 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n            |                           ~~~~~~~~~~~~~~~~~~~\n       5632 |                                               bytes, sizeof(val),\n       5633 |                                               is_little, !is_unsigned);\n            |                                                                      ^\n      /Users/uma-chan/.pyenv/versions/3.13.3/include/python3.13/cpython/longobject.h:111:17: note: '_PyLong_AsByteArray' declared here\n        111 | PyAPI_FUNC(int) _PyLong_AsByteArray(PyLongObject* v,\n            |                 ^                   ~~~~~~~~~~~~~~~~\n        112 |     unsigned char* bytes, size_t n,\n            |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        113 |     int little_endian, int is_signed, int with_exceptions);\n            |     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n      2 errors generated.\n      [40/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/testing.pyx\n      [41/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/tslib.pyx\n      [42/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/interval.pyx\n      [43/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/writers.pyx\n      [44/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/window/indexers.pyx\n      [45/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/window/aggregations.pyx\n      [46/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/algos.pyx\n      [47/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/hashtable.pyx\n      [48/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/sparse.pyx\n      [49/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/join.pyx\n      [50/151] Compiling Cython source /private/var/folders/xc/_1gjnwkd25j8hynw16xskg3r0000gn/T/pip-install-glb02n1x/pandas_d6eab0be3ccb474ba209bf6b5865cf88/pandas/_libs/groupby.pyx\n      ninja: build stopped: subcommand failed.\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\nerror: metadata-generation-failed\n\n× Encountered error while generating package metadata.\n╰─&gt; See above for output.\n\nnote: This is an issue with the package mentioned above, not pip.\nhint: See above for details.\n(my-venv-3.13.3)\n$\n\n\n\n\n3.2. エラー原因追跡\n執筆時点では Pandas の最新バージョンは 2.2.3 なのですが dbt-databricks のバージョンを固定したことで 2.2.0 未満をインストールするようになっています。 そして 2.1.4 をインストールすることになります。\n\nCollecting pandas&lt;2.2.0 (from dbt-databricks==1.7.17)\n\nPandas 2.2.3 では Python 3.13 用の wheel が用意されているのですが 2.1.4 時点では用意されておらず Pandas をソースコードからビルドしようとします。\nしかし Pandas 2.1.4 のビルドに利用している関数が Python 3.13.0 では削除されてしまったためビルドに失敗します。\n\n      pandas/_libs/tslibs/base.cpython-313-darwin.so.p/pandas/_libs/tslibs/base.pyx.c:5399:70: error: too few arguments to function call, expected 6, have 5\n       5397 |                 int ret = _PyLong_AsByteArray((PyLongObject *)v,\n            |                           ~~~~~~~~~~~~~~~~~~~\n       5398 |                                               bytes, sizeof(val),\n       5399 |                                               is_little, !is_unsigned);\n            |                                                                      ^\n\nPandas 側の Issue: https://github.com/pandas-dev/pandas/issues/58734\nCPython 側の Pull Request: https://github.com/python/cpython/pull/108429\nというわけで dbt-databricks==1.7.17 と Python 3.13 は相性が悪いということになります。"
  },
  {
    "objectID": "blog/2025-04-16-issue-with-python-libraries.html#python-3.12.10-との相性",
    "href": "blog/2025-04-16-issue-with-python-libraries.html#python-3.12.10-との相性",
    "title": "Python でありがちな本体バージョンとライブラリバージョンの不整合の例",
    "section": "4. Python 3.12.10 との相性",
    "text": "4. Python 3.12.10 との相性\n\n\n\n\n\n\n4.1. Python 3.12.10 のエラーログ詳細\n\n\n\n\n\n$ python --version\nPython 3.12.10\n\n$ python -m venv my-venv-3.12.10\n\n$ source my-venv-3.12.10/bin/activate\n((my-venv-3.12.10) )\n$ pip install dbt-databricks==1.7.17\nCollecting dbt-databricks==1.7.17\n  Using cached dbt_databricks-1.7.17-py3-none-any.whl.metadata (5.6 kB)\nCollecting dbt-spark~=1.7.1 (from dbt-databricks==1.7.17)\n  Using cached dbt_spark-1.7.1-py3-none-any.whl.metadata (5.3 kB)\nCollecting databricks-sql-connector&lt;3.0.0,&gt;=2.9.3 (from dbt-databricks==1.7.17)\n  Using cached databricks_sql_connector-2.9.6-py3-none-any.whl.metadata (4.3 kB)\nCollecting databricks-sdk==0.17.0 (from dbt-databricks==1.7.17)\n  Using cached databricks_sdk-0.17.0-py3-none-any.whl.metadata (34 kB)\nCollecting keyring&gt;=23.13.0 (from dbt-databricks==1.7.17)\n  Using cached keyring-25.6.0-py3-none-any.whl.metadata (20 kB)\nCollecting pandas&lt;2.2.0 (from dbt-databricks==1.7.17)\n  Using cached pandas-2.1.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\nCollecting protobuf&lt;5.0.0 (from dbt-databricks==1.7.17)\n  Using cached protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\nCollecting google-auth~=2.0 (from databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\nCollecting requests&lt;3,&gt;=2.28.1 (from databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nCollecting alembic&lt;2.0.0,&gt;=1.0.11 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\nCollecting lz4&lt;5.0.0,&gt;=4.0.2 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached lz4-4.4.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\nCollecting numpy&gt;=1.23.4 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached numpy-2.2.4-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\nCollecting oauthlib&lt;4.0.0,&gt;=3.1.0 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\nCollecting openpyxl&lt;4.0.0,&gt;=3.0.10 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting pyarrow&gt;=10.0.1 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached pyarrow-19.0.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\nCollecting sqlalchemy&lt;2.0.0,&gt;=1.3.24 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached SQLAlchemy-1.4.54-cp312-cp312-macosx_10_9_universal2.whl.metadata (10 kB)\nCollecting thrift&lt;0.17.0,&gt;=0.16.0 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached thrift-0.16.0-cp312-cp312-macosx_15_0_arm64.whl\nCollecting urllib3&gt;=1.0 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting dbt-core~=1.7.0 (from dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Downloading dbt_core-1.7.19-py3-none-any.whl.metadata (3.9 kB)\nCollecting sqlparams&gt;=3.0.0 (from dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached sqlparams-6.2.0-py3-none-any.whl.metadata (8.8 kB)\nCollecting jaraco.classes (from keyring&gt;=23.13.0-&gt;dbt-databricks==1.7.17)\n  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting jaraco.functools (from keyring&gt;=23.13.0-&gt;dbt-databricks==1.7.17)\n  Using cached jaraco.functools-4.1.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting jaraco.context (from keyring&gt;=23.13.0-&gt;dbt-databricks==1.7.17)\n  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\nCollecting numpy&gt;=1.23.4 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\nCollecting python-dateutil&gt;=2.8.2 (from pandas&lt;2.2.0-&gt;dbt-databricks==1.7.17)\n  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting pytz&gt;=2020.1 (from pandas&lt;2.2.0-&gt;dbt-databricks==1.7.17)\n  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting tzdata&gt;=2022.1 (from pandas&lt;2.2.0-&gt;dbt-databricks==1.7.17)\n  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting Mako (from alembic&lt;2.0.0,&gt;=1.0.11-&gt;databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nCollecting typing-extensions&gt;=4.12 (from alembic&lt;2.0.0,&gt;=1.0.11-&gt;databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\nCollecting agate~=1.7.0 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached agate-1.7.1-py2.py3-none-any.whl.metadata (3.1 kB)\nCollecting Jinja2&lt;4,&gt;=3.1.3 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting mashumaro&lt;3.15,&gt;=3.9 (from mashumaro[msgpack]&lt;3.15,&gt;=3.9-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Downloading mashumaro-3.14-py3-none-any.whl.metadata (114 kB)\nCollecting logbook&lt;1.6,&gt;=1.5 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached logbook-1.5.3-cp312-cp312-macosx_15_0_arm64.whl\nCollecting click&lt;9,&gt;=8.0.2 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\nCollecting networkx&lt;4,&gt;=2.3 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\nCollecting colorama&lt;0.5,&gt;=0.3.9 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\nCollecting pathspec&lt;0.12,&gt;=0.9 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached pathspec-0.11.2-py3-none-any.whl.metadata (19 kB)\nCollecting isodate&lt;0.7,&gt;=0.6 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\nCollecting sqlparse&lt;0.6.0,&gt;=0.5.0 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting dbt-extractor~=0.5.0 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached dbt_extractor-0.5.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.2 kB)\nCollecting minimal-snowplow-tracker~=0.0.2 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached minimal_snowplow_tracker-0.0.2-py3-none-any.whl\nCollecting dbt-semantic-interfaces~=0.4.2 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached dbt_semantic_interfaces-0.4.4-py3-none-any.whl.metadata (2.5 kB)\nCollecting jsonschema&gt;=3.0 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\nCollecting packaging&gt;20.9 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting pyyaml&gt;=6.0 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\nCollecting cffi&lt;2.0.0,&gt;=1.9 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\nCollecting idna&lt;4,&gt;=2.5 (from dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\nCollecting urllib3&gt;=1.0 (from databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\nCollecting cachetools&lt;6.0,&gt;=2.0.0 (from google-auth~=2.0-&gt;databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting pyasn1-modules&gt;=0.2.1 (from google-auth~=2.0-&gt;databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa&lt;5,&gt;=3.1.4 (from google-auth~=2.0-&gt;databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting et-xmlfile (from openpyxl&lt;4.0.0,&gt;=3.0.10-&gt;databricks-sql-connector&lt;3.0.0,&gt;=2.9.3-&gt;dbt-databricks==1.7.17)\n  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting six&gt;=1.5 (from python-dateutil&gt;=2.8.2-&gt;pandas&lt;2.2.0-&gt;dbt-databricks==1.7.17)\n  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting charset-normalizer&lt;4,&gt;=2 (from requests&lt;3,&gt;=2.28.1-&gt;databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\nCollecting certifi&gt;=2017.4.17 (from requests&lt;3,&gt;=2.28.1-&gt;databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\nCollecting more-itertools (from jaraco.classes-&gt;keyring&gt;=23.13.0-&gt;dbt-databricks==1.7.17)\n  Using cached more_itertools-10.6.0-py3-none-any.whl.metadata (37 kB)\nCollecting Babel&gt;=2.0 (from agate~=1.7.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\nCollecting leather&gt;=0.3.2 (from agate~=1.7.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached leather-0.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting parsedatetime!=2.5,&gt;=2.1 (from agate~=1.7.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached parsedatetime-2.6-py3-none-any.whl.metadata (4.7 kB)\nCollecting python-slugify&gt;=1.2.1 (from agate~=1.7.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\nCollecting pytimeparse&gt;=1.1.5 (from agate~=1.7.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached pytimeparse-1.1.8-py2.py3-none-any.whl.metadata (3.4 kB)\nCollecting pycparser (from cffi&lt;2.0.0,&gt;=1.9-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\nCollecting importlib-metadata~=6.0 (from dbt-semantic-interfaces~=0.4.2-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting pydantic&lt;3,&gt;=1.10 (from dbt-semantic-interfaces~=0.4.2-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\nCollecting MarkupSafe&gt;=2.0 (from Jinja2&lt;4,&gt;=3.1.3-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\nCollecting attrs&gt;=22.2.0 (from jsonschema&gt;=3.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\nCollecting jsonschema-specifications&gt;=2023.03.6 (from jsonschema&gt;=3.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting referencing&gt;=0.28.4 (from jsonschema&gt;=3.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\nCollecting rpds-py&gt;=0.7.1 (from jsonschema&gt;=3.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached rpds_py-0.24.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\nCollecting msgpack&gt;=0.5.6 (from mashumaro[msgpack]&lt;3.15,&gt;=3.9-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\nCollecting pyasn1&lt;0.7.0,&gt;=0.6.1 (from pyasn1-modules&gt;=0.2.1-&gt;google-auth~=2.0-&gt;databricks-sdk==0.17.0-&gt;dbt-databricks==1.7.17)\n  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nCollecting zipp&gt;=0.5 (from importlib-metadata~=6.0-&gt;dbt-semantic-interfaces~=0.4.2-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting annotated-types&gt;=0.6.0 (from pydantic&lt;3,&gt;=1.10-&gt;dbt-semantic-interfaces~=0.4.2-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.33.1 (from pydantic&lt;3,&gt;=1.10-&gt;dbt-semantic-interfaces~=0.4.2-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached pydantic_core-2.33.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\nCollecting typing-inspection&gt;=0.4.0 (from pydantic&lt;3,&gt;=1.10-&gt;dbt-semantic-interfaces~=0.4.2-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting text-unidecode&gt;=1.3 (from python-slugify&gt;=1.2.1-&gt;agate~=1.7.0-&gt;dbt-core~=1.7.0-&gt;dbt-spark~=1.7.1-&gt;dbt-databricks==1.7.17)\n  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\nUsing cached dbt_databricks-1.7.17-py3-none-any.whl (68 kB)\nUsing cached databricks_sdk-0.17.0-py3-none-any.whl (429 kB)\nUsing cached databricks_sql_connector-2.9.6-py3-none-any.whl (298 kB)\nUsing cached dbt_spark-1.7.1-py3-none-any.whl (44 kB)\nUsing cached keyring-25.6.0-py3-none-any.whl (39 kB)\nUsing cached pandas-2.1.4-cp312-cp312-macosx_11_0_arm64.whl (10.6 MB)\nUsing cached protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\nUsing cached alembic-1.15.2-py3-none-any.whl (231 kB)\nDownloading dbt_core-1.7.19-py3-none-any.whl (1.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 14.6 MB/s eta 0:00:00\nUsing cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\nUsing cached lz4-4.4.4-cp312-cp312-macosx_11_0_arm64.whl (189 kB)\nUsing cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\nUsing cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\nUsing cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\nUsing cached pyarrow-19.0.1-cp312-cp312-macosx_12_0_arm64.whl (30.7 MB)\nUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\nUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\nUsing cached SQLAlchemy-1.4.54-cp312-cp312-macosx_10_9_universal2.whl (1.6 MB)\nUsing cached sqlparams-6.2.0-py3-none-any.whl (17 kB)\nUsing cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nUsing cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\nUsing cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\nUsing cached jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\nUsing cached jaraco.functools-4.1.0-py3-none-any.whl (10 kB)\nUsing cached agate-1.7.1-py2.py3-none-any.whl (97 kB)\nUsing cached cachetools-5.5.2-py3-none-any.whl (10 kB)\nUsing cached certifi-2025.1.31-py3-none-any.whl (166 kB)\nUsing cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\nUsing cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\nUsing cached click-8.1.8-py3-none-any.whl (98 kB)\nUsing cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nUsing cached dbt_extractor-0.5.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (865 kB)\nUsing cached dbt_semantic_interfaces-0.4.4-py3-none-any.whl (118 kB)\nUsing cached idna-3.10-py3-none-any.whl (70 kB)\nUsing cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\nUsing cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\nDownloading mashumaro-3.14-py3-none-any.whl (92 kB)\nUsing cached more_itertools-10.6.0-py3-none-any.whl (63 kB)\nUsing cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\nUsing cached packaging-24.2-py3-none-any.whl (65 kB)\nUsing cached pathspec-0.11.2-py3-none-any.whl (29 kB)\nUsing cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\nUsing cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\nDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\nUsing cached six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\nUsing cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\nUsing cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\nUsing cached mako-1.3.10-py3-none-any.whl (78 kB)\nUsing cached attrs-25.3.0-py3-none-any.whl (63 kB)\nUsing cached babel-2.17.0-py3-none-any.whl (10.2 MB)\nUsing cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\nUsing cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\nUsing cached leather-0.4.0-py2.py3-none-any.whl (30 kB)\nUsing cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\nUsing cached msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl (82 kB)\nUsing cached parsedatetime-2.6-py3-none-any.whl (42 kB)\nUsing cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\nUsing cached pydantic-2.11.3-py3-none-any.whl (443 kB)\nUsing cached pydantic_core-2.33.1-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\nUsing cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\nUsing cached pytimeparse-1.1.8-py2.py3-none-any.whl (10.0 kB)\nUsing cached referencing-0.36.2-py3-none-any.whl (26 kB)\nUsing cached rpds_py-0.24.0-cp312-cp312-macosx_11_0_arm64.whl (351 kB)\nUsing cached pycparser-2.22-py3-none-any.whl (117 kB)\nUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\nUsing cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\nUsing cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\nUsing cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\nInstalling collected packages: text-unidecode, pytz, pytimeparse, parsedatetime, logbook, leather, zipp, urllib3, tzdata, typing-extensions, sqlparse, sqlparams, sqlalchemy, six, rpds-py, pyyaml, python-slugify, pycparser, pyasn1, pyarrow, protobuf, pathspec, packaging, oauthlib, numpy, networkx, msgpack, more-itertools, MarkupSafe, lz4, jaraco.context, idna, et-xmlfile, dbt-extractor, colorama, click, charset-normalizer, certifi, cachetools, Babel, attrs, annotated-types, typing-inspection, thrift, rsa, requests, referencing, python-dateutil, pydantic-core, pyasn1-modules, openpyxl, mashumaro, Mako, Jinja2, jaraco.functools, jaraco.classes, isodate, importlib-metadata, cffi, pydantic, pandas, minimal-snowplow-tracker, keyring, jsonschema-specifications, google-auth, alembic, agate, jsonschema, databricks-sql-connector, databricks-sdk, dbt-semantic-interfaces, dbt-core, dbt-spark, dbt-databricks\nSuccessfully installed Babel-2.17.0 Jinja2-3.1.6 Mako-1.3.10 MarkupSafe-3.0.2 agate-1.7.1 alembic-1.15.2 annotated-types-0.7.0 attrs-25.3.0 cachetools-5.5.2 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 colorama-0.4.6 databricks-sdk-0.17.0 databricks-sql-connector-2.9.6 dbt-core-1.7.19 dbt-databricks-1.7.17 dbt-extractor-0.5.1 dbt-semantic-interfaces-0.4.4 dbt-spark-1.7.1 et-xmlfile-2.0.0 google-auth-2.39.0 idna-3.10 importlib-metadata-6.11.0 isodate-0.6.1 jaraco.classes-3.4.0 jaraco.context-6.0.1 jaraco.functools-4.1.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 keyring-25.6.0 leather-0.4.0 logbook-1.5.3 lz4-4.4.4 mashumaro-3.14 minimal-snowplow-tracker-0.0.2 more-itertools-10.6.0 msgpack-1.1.0 networkx-3.4.2 numpy-1.26.4 oauthlib-3.2.2 openpyxl-3.1.5 packaging-24.2 pandas-2.1.4 parsedatetime-2.6 pathspec-0.11.2 protobuf-4.25.6 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.22 pydantic-2.11.3 pydantic-core-2.33.1 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytimeparse-1.1.8 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.3 rpds-py-0.24.0 rsa-4.9.1 six-1.17.0 sqlalchemy-1.4.54 sqlparams-6.2.0 sqlparse-0.5.3 text-unidecode-1.3 thrift-0.16.0 typing-extensions-4.13.2 typing-inspection-0.4.0 tzdata-2025.2 urllib3-1.26.20 zipp-3.21.0\n\n\n\n\n4.2. Python 3.12.10 でのインストール結果\ndbt-databricks==1.7.17 のインストールに成功しました。\nただし以下のようにプロンプト部分の括弧が2重になってしまうのがとても気になりますね。\n\n$ source my-venv-3.12.10/bin/activate\n((my-venv-3.12.10) )\n$ pip install dbt-databricks==1.7.17\n\n対応する Issue はこちらなのですが Python 3.12 ではもうバグ修正をしないようなのでこの2重括弧と共に生きていくしかないです。 メンテナーの方も仰っていますが目立つバグなのでどうしても気になってしまいます。\nhttps://github.com/python/cpython/issues/132361"
  },
  {
    "objectID": "blog/2025-04-16-issue-with-python-libraries.html#まとめ",
    "href": "blog/2025-04-16-issue-with-python-libraries.html#まとめ",
    "title": "Python でありがちな本体バージョンとライブラリバージョンの不整合の例",
    "section": "5. まとめ",
    "text": "5. まとめ\nライブラリのバージョンを固定した後色々と帳尻合わせしようとすると大変なことが起きがちですね。"
  },
  {
    "objectID": "blog/2024-12-05-setup-snowsql-mac.html",
    "href": "blog/2024-12-05-setup-snowsql-mac.html",
    "title": "SnowSQL セットアップ (Mac)",
    "section": "",
    "text": "PC を新調するとセットアップがつきものですね。\nではいきます。"
  },
  {
    "objectID": "blog/2024-12-05-setup-snowsql-mac.html#snowsql-インストール",
    "href": "blog/2024-12-05-setup-snowsql-mac.html#snowsql-インストール",
    "title": "SnowSQL セットアップ (Mac)",
    "section": "1. SnowSQL インストール",
    "text": "1. SnowSQL インストール\nSnowSQL のインストール | Snowflake Documentation\n\nHomebrew でインストールします。\nbrew install --cask snowflake-snowsql\nエイリアス設定を ~/.zshrc に記載して再読み込み or シェルの再起動を行います。\nalias snowsql=/Applications/SnowSQL.app/Contents/MacOS/snowsql"
  },
  {
    "objectID": "blog/2024-12-05-setup-snowsql-mac.html#snowsqlconfig-作成",
    "href": "blog/2024-12-05-setup-snowsql-mac.html#snowsqlconfig-作成",
    "title": "SnowSQL セットアップ (Mac)",
    "section": "2. ~/.snowsql/config 作成",
    "text": "2. ~/.snowsql/config 作成\nSnowSQL を介した接続 | Snowflake Documentation\n\nsnowsql コマンドを実行します。\n$ snowsql\nUsage: snowsql [OPTIONS]\n~/.snowsql/config が作成されているので編集していきます。\n[connections.connection_name1]\naccountname = myorganization-myaccount\nusername = jsmith\npassword = xxxxx\nrolename = myrole\nwarehousename = mywh"
  },
  {
    "objectID": "blog/2024-12-05-setup-snowsql-mac.html#コマンド実行",
    "href": "blog/2024-12-05-setup-snowsql-mac.html#コマンド実行",
    "title": "SnowSQL セットアップ (Mac)",
    "section": "3. コマンド実行",
    "text": "3. コマンド実行\nSnowSQLの使用 | Snowflake Documentation\n\n以下のコマンドで接続します。\n# どちらでも OK\nsnowsql --connection connection_name1\nsnowsql -c connection_name1\n接続後は SQL 文を直接実行できます。\n\n必要に応じて USE ROLE xxxxxx; で権限を切り替えることができます。\n\n各種コマンドは !help で参照できます。"
  },
  {
    "objectID": "blog/2025-05-06-editorconfig-vim.html",
    "href": "blog/2025-05-06-editorconfig-vim.html",
    "title": "今更ながら Vim に EditorConfig を導入しました",
    "section": "",
    "text": "dotfiles で .editorconfig を置いたままにしていたのですが利用できていなかったので今回利用していくこととしました。"
  },
  {
    "objectID": "blog/2025-05-06-editorconfig-vim.html#はじめに",
    "href": "blog/2025-05-06-editorconfig-vim.html#はじめに",
    "title": "今更ながら Vim に EditorConfig を導入しました",
    "section": "",
    "text": "dotfiles で .editorconfig を置いたままにしていたのですが利用できていなかったので今回利用していくこととしました。"
  },
  {
    "objectID": "blog/2025-05-06-editorconfig-vim.html#導入手順",
    "href": "blog/2025-05-06-editorconfig-vim.html#導入手順",
    "title": "今更ながら Vim に EditorConfig を導入しました",
    "section": "2. 導入手順",
    "text": "2. 導入手順\nEditorConfig プラグインが Vim 本体にビルトインされているのでインストールは不要です。\n:h editorconfig-install\nで説明されていますが vimrc に以下を追加すればよいです。\npackadd! editorconfig\nまた ~/.editorconfig を以下のように作成しました。\n設定可能な項目は\neditorconfig/editorconfig-vim: EditorConfig plugin for Vim\nに記載されています。\n\n\n.editorconfig\n\n# EditorConfig is awesome: https://EditorConfig.org\n# top-most EditorConfig file\nroot = true\n\n# https://github.com/editorconfig/editorconfig-vim\n[*]\ncharset = utf-8\nend_of_line = lf\nindent_size = 4\nindent_style = space\ninsert_final_newline = true\nmax_line_length = 80\ntrim_trailing_whitespace = true\n\n# 2 space indentation\n[{*.{css,mmd,sh,tf,tftpl,tfvars,toml,ts,vim,yaml,zshenv,zshrc},vimrc}]\nindent_size = 2\n\n# Tab indentation (no size specified)\n[{*.go,Makefile}]\nindent_style = tab\n\n# Windows\n[{*.{bat,cmd}]\nend_of_line = crlf\n\n最後に vimrc で FileType イベントで設定していた上記と重複している設定を削除しました。"
  },
  {
    "objectID": "blog/2025-05-06-editorconfig-vim.html#感想",
    "href": "blog/2025-05-06-editorconfig-vim.html#感想",
    "title": "今更ながら Vim に EditorConfig を導入しました",
    "section": "3. 感想",
    "text": "3. 感想\nこの設定は VS Code 等の他のエディタでも使えるので育成のしがいがあります。\nEditorConfig プラグインの help ファイルを見ると色々設定ができるっぽいのですが、あまり凝ったことはしなくていいかなと思っています。\n設定項目を見回してみたのですが max_line_length の効き方があまり理解できていないので追々学んでいきます。"
  },
  {
    "objectID": "blog/2024-01-02-vim-plugin-mnh.html",
    "href": "blog/2024-01-02-vim-plugin-mnh.html",
    "title": "自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介",
    "section": "",
    "text": "少し前に作った Vim/Neovim プラグインの紹介記事となります。"
  },
  {
    "objectID": "blog/2024-01-02-vim-plugin-mnh.html#プラグイン概要",
    "href": "blog/2024-01-02-vim-plugin-mnh.html#プラグイン概要",
    "title": "自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介",
    "section": "1. プラグイン概要",
    "text": "1. プラグイン概要\n\nhttps://github.com/i9wa4/markdown-number-header.vim\n\nMarkdown の見出し番号を付ける or 更新するプラグインです。\nDeno と Denops に依存しています。"
  },
  {
    "objectID": "blog/2024-01-02-vim-plugin-mnh.html#プラグインを作ることになったきっかけ",
    "href": "blog/2024-01-02-vim-plugin-mnh.html#プラグインを作ることになったきっかけ",
    "title": "自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介",
    "section": "2. プラグインを作ることになったきっかけ",
    "text": "2. プラグインを作ることになったきっかけ\nMarkdown All in One という VSCode 拡張の Markdown 見出し番号を付ける機能を Vim でも使いたかったのですが、CLI アプリケーション (Formatter) や Vim プラグインを探しても見つからなかったので自作しようと思い至りました。"
  },
  {
    "objectID": "blog/2024-01-02-vim-plugin-mnh.html#denops-プラグインとして作ろうと思った理由",
    "href": "blog/2024-01-02-vim-plugin-mnh.html#denops-プラグインとして作ろうと思った理由",
    "title": "自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介",
    "section": "3. Denops プラグインとして作ろうと思った理由",
    "text": "3. Denops プラグインとして作ろうと思った理由\nまず、自分が Vim 上でしか使わないため CLI アプリケーションとしてではなく Vim プラグインとして作ろうとは思ってました。 そして私は Vim 使いなので Vim script で書くか Denops プラグインとして TypeScript で書くかの二択で、楽しそうなので後者を選びました。"
  },
  {
    "objectID": "blog/2024-01-02-vim-plugin-mnh.html#denops-プラグイン開発体験について",
    "href": "blog/2024-01-02-vim-plugin-mnh.html#denops-プラグイン開発体験について",
    "title": "自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介",
    "section": "4. Denops プラグイン開発体験について",
    "text": "4. Denops プラグイン開発体験について\n初めて Denops プラグインを作ったし、しかも TypeScript にも触れたことがなかったのですが意外と困ることは少なかったです。 核となる見出し番号を振る処理は TypeScript の本領発揮という感じで楽に書けましたね。 まず以下のドキュメントに従ってチュートリアルを終えて、あとは先人の Denops プラグインのリポジトリを覗いてお作法を学びつつプラグインを完成させました。\n\n参考ページ:\n\nDeno で Vim/Neovim のプラグインを書く (denops.vim) | Zenn\nIntroduction - Denops Documentation (英語版)"
  },
  {
    "objectID": "blog/2024-01-02-vim-plugin-mnh.html#感想",
    "href": "blog/2024-01-02-vim-plugin-mnh.html#感想",
    "title": "自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介",
    "section": "5. 感想",
    "text": "5. 感想\n今も毎日使っているプラグインなので「無いんだったら作ればいい」精神でフッ軽に作れたことを嬉しく思ってます。 今後も必要なものは自分で作っていたいですね。"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた\n\n\n\ntech\n\ntech-data\n\ntech-dbt\n\n\n\nBigQuery 上で dbt incremental モデルの dbt run 実行時間を40分短縮した手順を共有する\n\n\n\n2025-09-28\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodex CLI の設定ファイルを dotfiles で管理する\n\n\n\nblog\n\ntech-ai\n\n\n\nCodex CLI の設定ファイルを dotfiles で管理する方法について説明します。\n\n\n\n2025-09-14\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025年のアウトプットまとめ with LAPRAS\n\n\n\nblog\n\ndiary\n\n\n\n2025年のアウトプットを LAPRAS に出力してもらいました。\n\n\n\n2025-09-02\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025-08-23 日誌\n\n\n\nblog\n\ndiary\n\n\n\n2025-08-23 日誌\n\n\n\n2025-08-23\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatabricks Connect 実践編 - ローカルから Databricks コンピュートを利用\n\n\n\nblog\n\ntech\n\ntech-python\n\ntech-databricks\n\n\n\nDatabricks Connect でローカル開発環境から Databricks の Spark セッションを制御します\n\n\n\n2025-07-28\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython 開発環境最適化編 - uv + pre-commit + GitHub Actions\n\n\n\nblog\n\ntech\n\ntech-python\n\ntech-vscode\n\n\n\nuv と pre-commit で Python 開発環境を最適化。 VS Code 以外のエディタや GitHub Actions でも統一された品質を保てます\n\n\n\n2025-07-28\n\n\n\n\n\n\n\n\n\n\n\n\n\nClaude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-vscode\n\n\n\nClaude Code 対応の Dev Container 環境をサクッと構築。VS Code 以外のエディタでも恩恵を受けられます\n\n\n\n2025-07-28\n\n\n\n\n\n\n\n\n\n\n\n\n\n個人的ターミナル最適化 for Claude Code\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-tmux\n\ntech-vim\n\n\n\nClaude Code を便利に使うためのターミナル環境について共有します\n\n\n\n2025-07-14\n\n\n\n\n\n\n\n\n\n\n\n\n\nVimへの初コントリビューションの経緯と学び\n\n\n\nblog\n\ntech\n\ntech-vim\n\nvim-jp\n\n\n\nVim 本体への初コントリビューションの経緯と学びを共有します\n\n\n\n2025-07-14\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmux で Vim から Claude Code にテキストを送信するプラグインを作った\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-tmux\n\ntech-vim\n\n\n\ntmux で Vim から Claude Code にテキストを送信する Vim プラグインの紹介\n\n\n\n2025-06-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nローカル dbt で BigQuery への認証を行う\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nローカル dbt で BigQuery への認証を行う\n\n\n\n2025-06-15\n\n\n\n\n\n\n\n\n\n\n\n\n\nuv で Python のグローバルインストールを行う\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nuv を使って Python のグローバルインストールを行う\n\n\n\n2025-06-10\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoetry の pyproject.toml を使って uv で .venv を作成する\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nPoetry の pyproject.toml を使って uv で .venv を作成する\n\n\n\n2025-06-08\n\n\n\n\n\n\n\n\n\n\n\n\n\nVim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\nVim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法\n\n\n\n2025-06-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatabricks AI/BI ダッシュボードの Git 連携の運用方法\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nDatabricks AI/BI ダッシュボードを Git flow で運用することにした経緯と実際の運用について\n\n\n\n2025-05-21\n\n\n\n\n\n\n\n\n\n\n\n\n\nAWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions\n\n\n\nblog\n\ntech\n\n\n\nAWS Lambda で ECR にあるコンテナイメージを実行するために必要な全てのリソースを Terraform で構築し GitHub Actions でデプロイできるようにします\n\n\n\n2025-05-12\n\n\n\n\n\n\n\n\n\n\n\n\n\nBash/Zsh でコマンドをエディタで編集する\n\n\n\nblog\n\ntech\n\n\n\nBash/Zsh で入力中のコマンドをエディタで編集して実行する方法について書いています\n\n\n\n2025-05-10\n\n\n\n\n\n\n\n\n\n\n\n\n\n今更ながら Vim に EditorConfig を導入しました\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n今更ながら Vim に EditorConfig を導入しました。設定方法と感想を書いています。\n\n\n\n2025-05-06\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython venv インストール・更新スクリプトの供養\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nPython venv 仮想環境のインストール・更新スクリプトを供養します\n\n\n\n2025-05-06\n\n\n\n\n\n\n\n\n\n\n\nMarkdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nMarkdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する方法を紹介します\n\n\n\n2025-05-06\n\n\n\n\n\n\n\n\n\n\n\ntmux と Zsh に Git リポジトリのステータスを表示する\n\n\n\nblog\n\ntech\n\ntech-tmux\n\n\n\ntmux のステータスラインと Zsh プロンプトに Git リポジトリのステータスを表示させる方法を紹介します\n\n\n\n2025-05-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatabricks MCP Server を Service Principal 認証対応させた\n\n\n\nblog\n\ntech\n\ntech-ai\n\ntech-data\n\n\n\nDatabricks MCP Server を Service Principal 認証対応させたものを公開しました\n\n\n\n2025-04-29\n\n\n\n\n\n\n\n\n\n\n\n\n\nlefthook 設定の供養\n\n\n\nblog\n\ntech\n\n\n\nGitHub Profile 用のリポジトリで lefthook を活用していましたが、不要になり削除しようと思うのでここに知見を残します\n\n\n\n2025-04-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython でありがちな本体バージョンとライブラリバージョンの不整合の例\n\n\n\nblog\n\ntech\n\ntech-python\n\n\n\nPython のバージョンとライブラリのバージョンの不整合で発生したエラーの例を記録に残しておきます\n\n\n\n2025-04-16\n\n\n\n\n\n\n\n\n\n\n\nMCP に入門した\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nMCP (Model Context Protocol) に入門してみました\n\n\n\n2025-04-11\n\n\n\n\n\n\n\n\n\n\n\n\n\nGemini API に課金した\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nGemini API に課金したので手順をメモしておきます\n\n\n\n2025-04-10\n\n\n\n\n\n\n\n\n\n\n\n\n\n個人的ブックマーク\n\n\n\nblog\n\nmemo\n\n\n\n個人的な重要記事などをまとめておきます\n\n\n\n2025-04-07\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevin に週報を書いてもらった\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nDevin に週報を書いてもらうためのプロンプトを用意して実際に週報を書いてもらったのでその内容を共有します\n\n\n\n2025-04-05\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevin 週報作成用プロンプト\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nDevin に週報を書いてもらうためのプロンプト\n\n\n\n2025-04-05\n\n\n\n\n\n\n\n\n\n\n\n\n\n2024年度を振り返る\n\n\n\nblog\n\ndiary\n\n\n\n2024年度に初めて経験したことを振り返ってみます\n\n\n\n2025-04-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nAider を使ってみる\n\n\n\nblog\n\ntech\n\ntech-ai\n\n\n\nAI エージェント Aider を使ってみました\n\n\n\n2025-04-01\n\n\n\n\n\n\n\n\n\n\n\nNotion データベースでリレーション元のプロパティを表示する (2025年3月28日時点)\n\n\n\nblog\n\ntech\n\n\n\nNotion データベースでリレーションプロパティ (列) にリレーション元のプロパティも併せて表示させる方法を紹介します\n\n\n\n2025-03-23\n\n\n\n\n\n\n\n\n\n\n\n\n\n見やすい SQL を書くための Tips\n\n\n\nblog\n\ntech\n\n\n\ndbt モデルやダッシュボード向けの SQL を書くことが多いので戒めの意味も込めて見やすい SQL を書くための Tips をまとめてみました\n\n\n\n2025-02-21\n\n\n\n\n\n\n\n\n\n\n\n\n\n最近の Vim プラグイン開発のアイデア\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n最近の Vim プラグイン開発のアイデアを振り返ります\n\n\n\n2025-02-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstagram API のアクセストークンを取得する\n\n\n\nblog\n\ntech\n\n\n\n失敗していますが Instagram API のアクセストークンを取得する手順を途中まで書いておきます\n\n\n\n2025-01-31\n\n\n\n\n\n\n\n\n\n\n\n\n\nデータエンジニアが初めてダッシュボードを作成して気づいたこと\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nデータエンジニア3年目にして初めてダッシュボードを作成する機会を得たので時系列順に思ったことを書いていきます\n\n\n\n2024-12-23\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto の YAML ヘッダにコードを埋め込みたい\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nQuarto の YAML ヘッダにコードを埋め込む方法についてのメモです。GitHub Actions で生成した値を埋め込むことができます。\n\n\n\n2024-12-07\n\n\n\n\n\n\n\n\n\n\n\n\n\n事故らない OneDrive 設定変更手順\n\n\n\nblog\n\ntech\n\n\n\nOneDrive の設定変更手順をまとめました。デスクトップやドキュメントの同期を避けたい場合に役立つ内容です。\n\n\n\n2024-12-07\n\n\n\n\n\n\n\n\n\n\n\n\n\nSnowSQL セットアップ (Mac)\n\n\n\nblog\n\ntech\n\ntech-data\n\n\n\nMac で SnowSQL をセットアップする手順をまとめました\n\n\n\n2024-12-05\n\n\n\n\n\n\n\n\n\n\n\n\n\nVim/Neovim の dbt 開発環境の現状と Vim を救う話\n\n\n\nblog\n\ntech\n\ntech-data\n\ntech-vim\n\n\n\n私が業務でよく利用する dbt のローカル開発環境の話をしていきます\n\n\n\n2024-12-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nZennの記事をGitHubリポジトリで管理する\n\n\n\nblog\n\ntech\n\n\n\nZenn の記事を GitHub リポジトリで管理する方法をまとめました\n\n\n\n2024-11-20\n\n\n\n\n\n\n\n\n\n\n\n\n\nnektos/act を使ってみた\n\n\n\nblog\n\ntech\n\n\n\nGitHub Actions をローカルで実行できる便利な OSS nektos/act を使ってみました\n\n\n\n2024-11-12\n\n\n\n\n\n\n\n\n\n\n\n\n\nキャリアについてぼんやり考えていたことを時系列順にまとめる\n\n\n\nblog\n\ndiary\n\n\n\n自分のキャリアについてぼんやり考えていたことを時系列順にまとめてみました\n\n\n\n2024-10-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n:%s/i9wa4/uma-chan/g\n\n\n\nblog\n\ndiary\n\n\n\nRenaming i9wa4 to uma-chan\n\n\n\n2024-10-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n最近の Vim プラグイン開発のアイデア\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n最近の Vim プラグイン開発のアイデアをメモしておきます\n\n\n\n2024-09-22\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto による DataFrame の表示テスト\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nPandas の DataFrame をウェブサイト一覧表作成に転用するための実験記事\n\n\n\n2024-09-08\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nGitHub でブログやスライドを管理したい方にオススメな Quarto による GitHub Pages 公開手順を紹介します\n\n\n\n2024-08-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n自分用千年戦争アイギスメモ\n\n\n\nblog\n\ngame\n\nmemo\n\n\n\n千年戦争アイギスの自分用メモ\n\n\n\n2024-07-20\n\n\n\n\n\n\n\n\n\n\n\n\n\n自分用 Minecraft メモ\n\n\n\nblog\n\ngame\n\nmemo\n\n\n\nMinecraft の自分用メモ\n\n\n\n2024-07-20\n\n\n\n\n\n\n\n\n\n\n\n\n\n技術系 Tips まとめ\n\n\n\nblog\n\ntech\n\n\n\nたまに使うけど忘れてしまうような技術系の小ネタ (コマンド・設定) まとめ記事です\n\n\n\n2024-07-15\n\n\n\n\n\n\n\n\n\n\n\n\n\nsystemd がユーザー権限でも使える\n\n\n\nblog\n\ntech\n\n\n\nsystemd がユーザー権限でも設定できる\n\n\n\n2024-06-28\n\n\n\n\n\n\n\n\n\n\n\n\n\n購入したガジェットの紹介\n\n\n\nblog\n\ndiary\n\n\n\nこれまで購入したガジェットの一覧\n\n\n\n2024-06-17\n\n\n\n\n\n\n\n\n\n\n\n\n\nMac 環境構築手順\n\n\n\nblog\n\ntech\n\nmemo\n\n\n\n私の Mac 環境構築手順をまとめておきます\n\n\n\n2024-06-17\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto で作ったスライドを GitHub Pages にデプロイする\n\n\n\nblog\n\ntech\n\ntech-quarto\n\n\n\nQuarto で作ったスライドを GitHub Pages にデプロイする方法について書いています\n\n\n\n2024-05-05\n\n\n\n\n\n\n\n\n\n\n\n\n\nVim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみた\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\nVim script で Git ブランチ名を取得するプラグインを Gemini を使って書いてみました\n\n\n\n2024-05-04\n\n\n\n\n\n\n\n\n\n\n\n\n\nデータサイエンス100本ノックの実行環境構築 (WSL2)\n\n\n\nblog\n\ntech\n\n\n\nデータサイエンス100本ノックの実行環境構築 (WSL2)\n\n\n\n2024-03-26\n\n\n\n\n\n\n\n\n\n\n\n\n\nWSL2 のセットアップ\n\n\n\nblog\n\ntech\n\n\n\n\n\n\n\n2024-03-25\n\n\n\n\n\n\n\n\n\n\n\n\n\nefm-langserver を Vim/Neovim で利用する\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n\n\n\n\n2024-01-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n自作 Vim/Neovim プラグイン markdown-number-header.vim の紹介\n\n\n\nblog\n\ntech\n\ntech-vim\n\n\n\n\n\n\n\n2024-01-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Pages (Jekyll) blog のタグ追加対応\n\n\n\nblog\n\ntech\n\n\n\n\n\n\n\n2024-01-02\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Post\n\n\n\nblog\n\ndiary\n\n\n\n\n\n\n\n2024-01-01\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Content",
      "Blog"
    ]
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html",
    "href": "blog/2024-09-22-vim-plugin-idea.html",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "",
    "text": "dotfiles から切り離したくなってきたらそれがプラグインの作り時。\n今温めているアイデアをメモしておきます。"
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#ローカル設定の読み込み",
    "href": "blog/2024-09-22-vim-plugin-idea.html#ローカル設定の読み込み",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "1. ローカル設定の読み込み",
    "text": "1. ローカル設定の読み込み\nおそらく以下が近い気がしていて、自分の dotfiles の設定を切り出しつつ自分が使いやすい形で作りたいです。\nthinca/vim-localrc: Enable configuration file of each directory."
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#terminal-管理",
    "href": "blog/2024-09-22-vim-plugin-idea.html#terminal-管理",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "2. Terminal 管理",
    "text": "2. Terminal 管理\nVim/Neovim のターミナルを気軽に開いたり選択範囲のコマンドを流し込むためのプラグイン。\ndotfiles の中で温めてはいるものの、tmux に対する優位性を見い出せずあまり使ってません。\n他には REPL (IPython) 向けの設定もあります。ただ、細々とした Python コードを Vim で動作確認したいユースケースがあるのかなあ？"
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#jupytext-と-ipynb-の同期",
    "href": "blog/2024-09-22-vim-plugin-idea.html#jupytext-と-ipynb-の同期",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "3. Jupytext と ipynb の同期",
    "text": "3. Jupytext と ipynb の同期\nJupytext で ipynb と py を同期させるプラグイン。\n通常は Jupytext をコマンドで実行させると思いますが、非同期で同期させる (？) 挙動をさせたいですね。\nJupytext に変換しておくと Git 管理しやすくなるものの、Jupytext がマイナー過ぎてチーム開発で自分が他人に推奨できない点がネックで最近あまり使わなくなりつつあります。\nみんな ipynb の管理どうしているんだろう。。"
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#tabline-設定",
    "href": "blog/2024-09-22-vim-plugin-idea.html#tabline-設定",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "4. Tabline 設定",
    "text": "4. Tabline 設定\n頑張って書き上げたため切り離してもよいかも。\nちなみに最近 Statusline は使ってません！"
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#追記-virtualtext-を活用したメモプラグイン",
    "href": "blog/2024-09-22-vim-plugin-idea.html#追記-virtualtext-を活用したメモプラグイン",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "5. [2024-10-25 追記] virtualtext を活用したメモプラグイン",
    "text": "5. [2024-10-25 追記] virtualtext を活用したメモプラグイン\nコードリーディング中にメモを残すためのプラグイン。\nメモ一覧をリポジトリ内に保持しておきたい。\nLinter を参考にすればいけそうだけど、コードの行追加削除に追従させるのは自分の技術力では難しそう。"
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#追記-dbt-プラグイン-deno",
    "href": "blog/2024-09-22-vim-plugin-idea.html#追記-dbt-プラグイン-deno",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "6. [2024-11-25 追記] dbt プラグイン (Deno)",
    "text": "6. [2024-11-25 追記] dbt プラグイン (Deno)\nVim/Neovim 両対応で最低限の機能をもったものがほしい。"
  },
  {
    "objectID": "blog/2024-09-22-vim-plugin-idea.html#追記-zenn-quarto-の本文変換",
    "href": "blog/2024-09-22-vim-plugin-idea.html#追記-zenn-quarto-の本文変換",
    "title": "最近の Vim プラグイン開発のアイデア",
    "section": "7. [2024-11-25 追記] Zenn <–> Quarto の本文変換",
    "text": "7. [2024-11-25 追記] Zenn &lt;–&gt; Quarto の本文変換\nコードブロックの書き方を変換するだけで足りる？"
  },
  {
    "objectID": "blog/2024-10-25-s-i9wa4-umachan-g.html",
    "href": "blog/2024-10-25-s-i9wa4-umachan-g.html",
    "title": ":%s/i9wa4/uma-chan/g",
    "section": "",
    "text": "元々 i9wa4 (いくわよ) を名乗っていましたが、現職でのニックネームに引きずられ、バーチャルがリアルに侵食された末に uma-chan (うまちゃん) と名乗っていくことを決めました。\nそれに伴いブログの記事も修正しています。\nというわけでよろしくお願いします！"
  },
  {
    "objectID": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html",
    "href": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html",
    "title": "Poetry の pyproject.toml を使って uv で .venv を作成する",
    "section": "",
    "text": "最近 Python の仮想環境構築に uv を利用し始めて以来 pyenv を削除してしまったりとすっかり uv が気に入っています。\nとはいえ全てのプロジェクトを直ちに uv へ移行するのも全員の学習コストがかかるため難しいと思います。\n過渡期の対応としてローカルで Poetry の pyproject.toml を使用して uv で仮想環境構築する方法をメモしておきます。"
  },
  {
    "objectID": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html#はじめに",
    "href": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html#はじめに",
    "title": "Poetry の pyproject.toml を使って uv で .venv を作成する",
    "section": "",
    "text": "最近 Python の仮想環境構築に uv を利用し始めて以来 pyenv を削除してしまったりとすっかり uv が気に入っています。\nとはいえ全てのプロジェクトを直ちに uv へ移行するのも全員の学習コストがかかるため難しいと思います。\n過渡期の対応としてローカルで Poetry の pyproject.toml を使用して uv で仮想環境構築する方法をメモしておきます。"
  },
  {
    "objectID": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html#仮想環境構築手順",
    "href": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html#仮想環境構築手順",
    "title": "Poetry の pyproject.toml を使って uv で .venv を作成する",
    "section": "2. 仮想環境構築手順",
    "text": "2. 仮想環境構築手順\n# .venv を作成する\n# このとき .python-version に記載された Python で構築される\n$ uv venv\nUsing CPython 3.12.1\nCreating virtual environment at: .venv\nActivate with: source .venv/bin/activate\n\n# 仮想環境にパッケージをインストールする\n$ uv pip install --requirement pyproject.toml"
  },
  {
    "objectID": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html#おわりに",
    "href": "blog/2025-06-08-create-uv-venv-with-poetry-pyproject-toml.html#おわりに",
    "title": "Poetry の pyproject.toml を使って uv で .venv を作成する",
    "section": "3. おわりに",
    "text": "3. おわりに\n$ uv pip install --requirement pyproject.toml ここ爆速すぎて uv が好きになると思うのでちょっとやってみてほしいです。\nちなみにこの方法だと poetry.lock に従うわけではないので完全に同じ環境を再現するわけではありません。\nとはいえほとんど齟齬のない環境を構築できます。\nしばらくすると忘れそうなのでメモ代わりの記事でした。"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html",
    "href": "blog/2025-07-28-article3-databricks-connect.html",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "",
    "text": "本記事は3部構成の3本目です。"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#はじめに",
    "href": "blog/2025-07-28-article3-databricks-connect.html#はじめに",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "1. はじめに",
    "text": "1. はじめに\n前回までの環境に Databricks Connect を追加して、ローカル開発環境から Databricks の Spark セッションを利用できるようにします。\nDatabricks 上でもローカルでも同じコードが動作する汎用的なライブラリも紹介します。"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#対象読者",
    "href": "blog/2025-07-28-article3-databricks-connect.html#対象読者",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "2. 対象読者",
    "text": "2. 対象読者\n\nDatabricks のコンピュートをローカルから利用したい方\nDatabricks 上での開発に Claude Code を利用したい方\nDatabricks 以外の DWH サービスを使っているが参考にしたい方"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#databricks-connect-とは",
    "href": "blog/2025-07-28-article3-databricks-connect.html#databricks-connect-とは",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "3. Databricks Connect とは",
    "text": "3. Databricks Connect とは\nDatabricks Connect は、ローカル開発環境から Databricks クラスタに接続できるライブラリです。\nこれにより以下のメリットが得られます。\n\nVS Code や Claude Code などのローカル開発環境が利用できる\nローカルでの開発と Databricks 上での実行で同じコードが使える"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#環境設定",
    "href": "blog/2025-07-28-article3-databricks-connect.html#環境設定",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "4. 環境設定",
    "text": "4. 環境設定\n\n4.1. pyproject.toml への追加\n前回の pyproject.toml に以下の依存関係を追加します。\n\n\npyproject.toml\n\n[project]\ndependencies = [\n    \"databricks-connect~=16.4.0\",\n    \"ipykernel\",\n    \"jupyterlab\",\n    \"matplotlib\",\n    \"numpy\",\n    \"pandas\",\n    \"python-dotenv\",\n    \"requests\",\n    \"seaborn\",\n]\n\n[tool.flake8]\nextend-ignore = [\n    \"E203\",  # Whitespace before ':'\n    \"E701\",  # Multiple statements on one line (colon)\n    \"F821\"   # undefined name (Databricks-specific module)\n]\n\n\n\n4.2. Dev Container設定の更新\ndevcontainer.json に以下の設定を追加します。\n\n\n.devcontainer/devcontainer.json\n\n{\n    \"runArgs\": [\n        \"--cap-add=NET_ADMIN\",\n        \"--cap-add=NET_RAW\",\n        \"--network=host\"\n    ],\n    \"mounts\": [\n        \"source=${localEnv:HOME}/.databrickscfg,target=/home/node/.databrickscfg,type=bind,consistency=cached\",\n    ]\n}\n\n\n\n4.3. 環境変数設定\n.env.example ファイルを作成します。\n\n\n.env.example\n\n# Databricks設定\n\n# .databrickscfgのプロファイル名（推奨）\nDATABRICKS_CONFIG_PROFILE=DEFAULT\n\n# クラスター使用の場合（どちらか一方を設定）\n# DATABRICKS_CLUSTER_ID=\n\n# Serverless Compute使用の場合\nDATABRICKS_SERVERLESS_COMPUTE_ID=auto\n\n# バージョンチェック無効化\nDATABRICKS_CONNECT_DISABLE_VERSION_CHECK=true"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#spark-セッション管理ライブラリ",
    "href": "blog/2025-07-28-article3-databricks-connect.html#spark-セッション管理ライブラリ",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "5. Spark セッション管理ライブラリ",
    "text": "5. Spark セッション管理ライブラリ\nDev Container (ローカル) と Databricks の両方で同じように Spark セッションを作成するためのライブラリを用意しました。\n\n5.1. 使用方法\nfrom databricks_spark import create_spark_session\n\n# 新しいSparkセッションを作成\nspark = create_spark_session()\ndf = spark.sql(\"SHOW CATALOGS\")\ndf.show()\n\n\n5.2. ライブラリ実装\n\n\n\n\n\n\n5.2.1. databricks_spark.py\n\n\n\n\n\n\n\ndatabricks_spark.py\n\n\"\"\"\nDatabricks Spark セッション管理\nDatabricksとローカル両対応の1ファイル完結型ライブラリ\n\n使用方法:\n    from databricks_spark import create_spark_session\n\n    # 新しいSparkセッションを作成\n    spark = create_spark_session()\n    df = spark.sql(\"SHOW CATALOGS\")\n    df.show()\n\"\"\"\n\nimport logging\nimport os\nimport sys\n\n# ロガー設定\n_logger = logging.getLogger(__name__)\nif not _logger.handlers:\n    _logger.setLevel(logging.INFO)\n    formatter = logging.Formatter(\"%(asctime)s %(name)s [%(levelname)s] %(message)s\")\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(formatter)\n    _logger.addHandler(handler)\n\n\ndef is_databricks_environment() -&gt; bool:\n    \"\"\"Databricks環境で実行されているかを判定\"\"\"\n    return os.environ.get(\"DATABRICKS_RUNTIME_VERSION\") is not None\n\n\ndef get_environment_type() -&gt; str:\n    \"\"\"実行環境のタイプを取得\"\"\"\n    if is_databricks_environment():\n        return \"databricks\"\n    else:\n        return \"local\"\n\n\ndef create_databricks_native_session():\n    \"\"\"Databricks上でのネイティブSparkセッション作成\"\"\"\n    try:\n        from pyspark.sql import SparkSession\n\n        spark = SparkSession.getActiveSession()\n        if spark is None:\n            spark = SparkSession.builder.appName(\"DatabricksNotebook\").getOrCreate()\n\n        _logger.info(\"✅ Databricks native Sparkセッション取得完了\")\n        _logger.info(f\"📊 Spark version: {spark.version}\")\n        return spark\n\n    except ImportError:\n        raise ImportError(\"Databricks環境でPySparkが利用できません\")\n\n\ndef create_local_connect_session():\n    \"\"\"ローカルでのDatabricksConnect Sparkセッション作成\"\"\"\n    try:\n        from databricks.connect import DatabricksSession\n\n        # 環境変数のデフォルト値を設定\n        os.environ.setdefault(\"DATABRICKS_CONFIG_PROFILE\", \"DEFAULT\")\n        os.environ.setdefault(\"DATABRICKS_SERVERLESS_COMPUTE_ID\", \"auto\")\n        os.environ.setdefault(\"DATABRICKS_CONNECT_DISABLE_VERSION_CHECK\", \"true\")\n\n        # .env読み込み（オプション）\n        try:\n            from dotenv import find_dotenv, load_dotenv\n\n            env_file = find_dotenv()\n            if env_file:\n                load_dotenv(env_file)\n                _logger.info(f\"📁 .env読み込み: {env_file}\")\n        except ImportError:\n            _logger.info(\"📁 dotenvモジュールなし - 環境変数のみ使用\")\n\n        # プロファイル指定チェック\n        profile_name = os.environ.get(\"DATABRICKS_CONFIG_PROFILE\")\n\n        if profile_name:\n            _logger.info(f\"🔧 .databrickscfgプロファイル使用: {profile_name}\")\n\n            if os.environ.get(\"DATABRICKS_CLUSTER_ID\"):\n                cluster_id = os.environ.get(\"DATABRICKS_CLUSTER_ID\")\n                spark = (\n                    DatabricksSession.builder.profile(profile_name)\n                    .clusterId(cluster_id)\n                    .getOrCreate()\n                )\n                _logger.info(f\"🆔 クラスター使用: {cluster_id}\")\n            else:\n                spark = (\n                    DatabricksSession.builder.profile(profile_name)\n                    .serverless(True)\n                    .getOrCreate()\n                )\n                _logger.info(\"🚀 Serverless Compute使用\")\n        else:\n            _logger.info(\"🔧 環境変数から直接接続\")\n\n            required_vars = [\"DATABRICKS_HOST\", \"DATABRICKS_TOKEN\"]\n            missing_vars = [var for var in required_vars if not os.environ.get(var)]\n\n            if missing_vars:\n                raise ValueError(f\"環境変数が未設定: {missing_vars}\")\n\n            if os.environ.get(\"DATABRICKS_CLUSTER_ID\"):\n                cluster_id = os.environ.get(\"DATABRICKS_CLUSTER_ID\")\n                spark = DatabricksSession.builder.clusterId(cluster_id).getOrCreate()\n                _logger.info(f\"🆔 クラスター使用: {cluster_id}\")\n            else:\n                spark = DatabricksSession.builder.serverless(True).getOrCreate()\n                _logger.info(\"🚀 Serverless Compute使用\")\n\n        # DataFrame表示最適化（Serverless環境では一部設定が制限される）\n        try:\n            spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n        except Exception:\n            # Serverless Computeでは設定できない場合があるのでスキップ\n            pass\n\n        _logger.info(\"✅ Databricks Connect Sparkセッション作成完了\")\n        _logger.info(f\"📊 Spark version: {spark.version}\")\n        _logger.info(f\"🌐 接続先: {spark.client.host}\")\n        return spark\n\n    except ImportError as e:\n        raise ImportError(f\"databricks-connectが利用できません: {e}\")\n\n\ndef create_spark_session():\n    \"\"\"実行環境に応じて適切なSparkセッションを作成\"\"\"\n    env_type = get_environment_type()\n    _logger.info(f\"🔍 実行環境検出: {env_type}\")\n\n    try:\n        if env_type == \"databricks\":\n            return create_databricks_native_session()\n        else:  # local環境（VS Code、Cursor、Dev Container CLI等）\n            return create_local_connect_session()\n\n    except Exception as e:\n        error_msg = str(e)\n        _logger.error(f\"❌ Sparkセッション作成失敗: {error_msg}\")\n\n        # バージョン不整合の検出と対応提案\n        if \"Unsupported combination\" in error_msg and \"Databricks Runtime\" in error_msg:\n            _logger.error(\"🔧 バージョン不整合が検出されました\")\n            _logger.error(\"💡 以下のいずれかの対応を行ってください:\")\n            _logger.error(\n                \"   1. DatabricksConnectをクラスターのランタイムに合わせてダウングレード:\"\n            )\n            _logger.error(\n                \"      uv add 'databricks-connect~=[クラスターのランタイムバージョン]'\"\n            )\n            _logger.error(\"   2. Databricksクラスターのランタイムをアップグレード\")\n\n        _logger.error(f\"💡 環境タイプ: {env_type}\")\n        raise\n\n\n# 明示的にcreate_spark_session()を呼び出してセッションを作成してください\n# 例: spark = create_spark_session()"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#databricks側の設定",
    "href": "blog/2025-07-28-article3-databricks-connect.html#databricks側の設定",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "6. Databricks側の設定",
    "text": "6. Databricks側の設定\n\n6.1. 接続先クラスタ設定\nSpark config で以下を設定します。\nspark.databricks.service.server.enabled true\n\n\n6.2. Databricks 接続設定\nDatabricks へ接続する場合は ~/.databrickscfg に以下の内容を記述します。\n[DEFAULT]\nhost = https://your-databricks-workspace.cloud.databricks.com\ntoken = your-access-token\n\nhost: Databricks ワークスペースの URL\ntoken: Databricks アクセストークン"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#利用手順",
    "href": "blog/2025-07-28-article3-databricks-connect.html#利用手順",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "7. 利用手順",
    "text": "7. 利用手順\n\n7.1. .env 作成\n\n.env ファイルを作成します\ncp .env.example .env\n必要であれば .env ファイルの内容を変更してください\n\n\n\n7.2. 開発ワークフロー\n\nDev Container を起動\nPython カーネルを選択\nSpark セッションを作成して開発開始\n\nfrom databricks_spark import create_spark_session\n\n# Sparkセッション作成\nspark = create_spark_session()\n\n# データの取得\ndf = spark.sql(\"SELECT * FROM your_table LIMIT 10\")\ndf.show()\n\n# データ分析\ndf.groupBy(\"category\").count().show()"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#ノートブックでの-python-モジュールインストール方法",
    "href": "blog/2025-07-28-article3-databricks-connect.html#ノートブックでの-python-モジュールインストール方法",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "8. ノートブックでの Python モジュールインストール方法",
    "text": "8. ノートブックでの Python モジュールインストール方法\nDatabricks での実行時のみ Python パッケージをインストールする HACK な方法です。\nuv を使っていない場合は %pip install &lt;package&gt; で大丈夫です。\nimport os\nif os.environ.get(\"DATABRICKS_RUNTIME_VERSION\"):\n    %pip install uv\n    %pip install -r &lt;(uv pip compile pyproject.toml --color never)"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#トラブルシューティング",
    "href": "blog/2025-07-28-article3-databricks-connect.html#トラブルシューティング",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "9. トラブルシューティング",
    "text": "9. トラブルシューティング\n\n9.1. バージョン不整合エラー\nDatabricks Connect のバージョンとクラスタのランタイムバージョンが合わない場合があります\n# クラスタのランタイムに合わせてダウングレード\nuv add 'databricks-connect~=14.3.0'  # この場合は DBR 14.3 に対応\n\n\n9.2. 接続エラー\n設定ファイルが存在せずマウントされていない場合が考えられるので、devcontainer.json の mounts 設定を確認してください。"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#おわりに",
    "href": "blog/2025-07-28-article3-databricks-connect.html#おわりに",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "10. おわりに",
    "text": "10. おわりに\nこれでローカル開発環境から Databricks の Spark クラスタを利用できるようになりました。\nClaude Code にノートブック実行とデバッグを任せることでデータサイエンスや機械学習の作業効率が爆上がりですね！\nClaude Code にこの手の作業を任せるときは時間がかかるので並行して他の作業に取り組むのがオススメです。"
  },
  {
    "objectID": "blog/2025-07-28-article3-databricks-connect.html#おまけ-claude-code-に読ませると便利なルール",
    "href": "blog/2025-07-28-article3-databricks-connect.html#おまけ-claude-code-に読ませると便利なルール",
    "title": "Databricks Connect 実践編 - ローカルから Databricks コンピュートを利用",
    "section": "11. (おまけ) Claude Code に読ませると便利なルール",
    "text": "11. (おまけ) Claude Code に読ませると便利なルール\n\n\nCONTRIBUTING.md\n\n# CONTRIBUTING\n\n## 重要なルール\n\n### pre-commit 設定について\n\n- **NEVER**: pre-commit を無効化してはならない\n- **NEVER**: `pre-commit skip` や `git commit --no-verify` を使用してはならない\n- **IMPORTANT**: pre-commit のチェックに失敗した場合は、必ずコードを修正してからコミットする\n\n## Jupyter Notebook 実行方法\n\n### デフォルトの実行方法\n\nNotebook全体を実行する指示を受けた際は、以下のコマンドを使用する\n\n`uv run jupyter nbconvert --to notebook --execute &lt;notebook_path&gt; --inplace --ExecutePreprocessor.timeout=300`\n\n#### 使用例\n\n`uv run jupyter nbconvert --to notebook --execute /workspace/notebooks/databricks-connect-sample.ipynb --inplace --ExecutePreprocessor.timeout=300`\n\n#### オプション説明\n\n- `--to notebook`: Notebook形式で出力\n- `--execute`: セルを実際に実行\n- `--inplace`: 元のファイルに実行結果を上書き\n- `--ExecutePreprocessor.timeout=300`: タイムアウトを300秒に設定\n\n### 実行ログの確認\n\n実行時のログを確認したい場合は以下のように実行する\n\n`uv run jupyter nbconvert --to notebook --execute &lt;notebook_path&gt; --inplace --ExecutePreprocessor.timeout=300 2&gt;&1 | tee /tmp/notebook_execution.log`\n\n### 注意事項\n\n- 実行前に必要な環境変数（`.env`ファイル等）が適切に設定されていることを確認する\n- 長時間実行されるセルがある場合は`--ExecutePreprocessor.timeout`の値を調整する\n- VS Codeで開いている場合は実行後にファイルの更新を確認する"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "",
    "text": "Claude Code で並行作業を行いやすくなるための工夫ポイントを全て共有します！\n本当の私個人の趣味盛り盛りの内容なので役に立つ部分だけ読む形でお願いします。\nなお分量が多いので参考記事やリンクを用意していない部分もあります。\nインストール方法も各自で調べてください。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#はじめに",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#はじめに",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "",
    "text": "Claude Code で並行作業を行いやすくなるための工夫ポイントを全て共有します！\n本当の私個人の趣味盛り盛りの内容なので役に立つ部分だけ読む形でお願いします。\nなお分量が多いので参考記事やリンクを用意していない部分もあります。\nインストール方法も各自で調べてください。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#対象読者",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#対象読者",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "2. 対象読者",
    "text": "2. 対象読者\n\nClaude Code を使っている方\nGitHub を使っている方\nVim を使っている、もしくは使いたい方"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#ターミナル以前",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#ターミナル以前",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "3. ターミナル以前",
    "text": "3. ターミナル以前\n\n3.1. モニタ\n私は27インチ WQHD モニタを1枚使っていますが、やはりウルトラワイドモニタが良いらしいですね。\nとはいえ私は出先や出社時はPC内蔵モニタを使っており、その場合も以降の内容で十分に Claude Code で並行作業はできるのでモニタが整っていない勢も安心して読み進めてください。\n\n\n3.2. OS\n最近よく使っているという理由で macOS (MacBook) を前提に話しますが、適宜読み替えても同様の環境が構築できるはずです。\n一応 Ubuntu や Windows (WSL) も利用してはいるのである程度はクロスプラットフォームな内容にできていると思います。\n\n\n3.3. ウインドウマネージャー\nターミナルと他ウインドウとの行き来を快適にできるのであればウインドウマネージャーは必須ではないです。\nmacOS では Windows でいう「Win+数字」に相当する一手で表示アプリを切り替えるショートカットが無いので AeroSpace を利用しています。\nhttps://github.com/nikitabobko/AeroSpace\n導入時に以下の記事がとても参考になりました。\nデスクトップは「清く・正しく・美しく」AeroSpace, JankyBorders, SketchyBar, alt-tab\n\n\n3.4. ブラウザ\n私は複数ウインドウや仮想デスクトップを使いこなすのが苦手なので Chrome のタブグループ機能で並行作業に対応することが多いです。\n\n\n3.5. dotfiles\nClaude Code による生産性をいかに上げるかが注目されている昨今、いつでもどんな PC でも快適に作業するために設定を記述しておく dotfiles の重要性が増していると個人的に話題です。\ndotfiles にまだ入門できていない方は入門記事を参考にしてください。\n今回述べている内容はほとんど以下の dotfiles に記述したものとなります。\nhttps://github.com/i9wa4/dotfiles\n私の設定で気になる内容がある場合は以下の DeepWiki で質問してみると的確な回答が得られます。\nhttps://deepwiki.com/i9wa4/dotfiles"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#シェル",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#シェル",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "4. シェル",
    "text": "4. シェル\nZsh を愛用してます。\n以下で Zsh のおすすめプラグインを紹介します。\n\n4.1. Zinit\nZsh のプラグインマネージャーです。\nhttps://github.com/zdharma-continuum/zinit\n\n\n4.2. zeno.zsh (Zsh/Fish)\nZsh の操作体験を全般的に向上させるプラグインの zeno.zsh です。\nhttps://github.com/yuki-yano/zeno.zsh\n正直これが無いとターミナルを使う気になれないと思えるくらいに便利です。\n最近 Fish にも対応したようなので Fish ユーザーの方もぜひ試してみてください。\n作者の yuki-yano さんによる記事が参考になります。\nDeno + TypeScriptでzshプラグインを実装して最高になった\n以下で Claude Code と共に生きる上で zeno.zsh に担ってもらっている役割を紹介します。\nもちろんここに記述していない他の機能も便利です。\n\n4.2.1. ghq 管理リポジトリへの移動\nghq については後述します。\nzeno.zsh によって ghq + fzf の組み合わせでリポジトリへの移動がとても快適になります。\n\n\n4.2.2. tmux セッション名へのリポジトリ名自動反映\nghq でリポジトリ移動すると tmux セッション名が自動でリポジトリ名に変更されます。\nこれにより難なく複数セッションを扱えます。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#ターミナル",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#ターミナル",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "5. ターミナル",
    "text": "5. ターミナル\n何でもよいのですが私は Alacritty を使っています。\n通知音が鳴るように設定しておくとよいです。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#tmux",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#tmux",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "6. tmux",
    "text": "6. tmux\n複数ターミナルの管理について、タブ機能をもつターミナルもありますが私は tmux で複数ターミナルを管理するのが好きです。\nhttps://github.com/tmux/tmux/wiki/Installing\n\n6.1. tmux おすすめキーバインド\n\n\ntmux.conf\n\nbind-key -n M-Left previous-window\nbind-key -n M-Right next-window\nbind-key -n M-Up switch-client -p\nbind-key -n M-Down switch-client -n\n\nこちらは\n\ntmux のセッション間を Alt + 上下キーで切り替える\ntmux のウインドウ間を Alt + 左右キーで切り替える\n\nを実現するキーバインドです。\nこれにより Claude Code の並行作業の様子を片手でセッションやウインドウを切り替えながら確認できます。\n\n\ntmux.conf\n\nbind-key % split-window -h -c \"#{pane_current_path}\"\nbind-key '\"' split-window -v -c \"#{pane_current_path}\"\nbind-key c new-window -c \"#{pane_current_path}\"\n\nこちらは現在開いているディレクトリを継承して新しいペインやウインドウを作成するキーバインドです。\nClaude Code と同じディレクトリに移動した状態のターミナルを即座に起動できます。\n\n\n6.2. tmux おすすめプラグイン\nhttps://github.com/tmux-plugins/tpm\ntmux のプラグインマネージャーです。\nhttps://github.com/kristijanhusak/tmux-simple-git-status\ntmux のステータスバーに Git の状態を表示するプラグインです。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#git",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#git",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "7. Git",
    "text": "7. Git\n\n7.1. worktree\n最近注目されている git worktree を使いましょう。\nworktree 作成作業は定型化できると思うので worktree 作成用のスクリプトを作成しておくと便利です。\n\n\n7.2. gitignore\nリポジトリ内の作業ディレクトリ (tmp/ など) を gitignore して Claude Code の作業場にしておくことをおすすめします。\n指示用のドキュメントやログを格納して Claude Code に読ませるといった使い方ができます。\n\n\n7.3. ghq\nリポジトリの管理は ghq に任せたほうがよいです。\nhttps://github.com/x-motemen/ghq"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#エディタ",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#エディタ",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "8. エディタ",
    "text": "8. エディタ\n私は Vim が好きで使っています。\n以下で私が Claude Code のために利用している Vim プラグインを紹介します。\n\n8.1. vim-tmux-send-to-ai-cli\nhttps://github.com/i9wa4/vim-tmux-send-to-ai-cli\n拙作プラグインです。\nVim のバッファや複数行にわたる選択範囲などを自在に tmux の Claude Code ペインに送信できます。\n現時点では Claude Code と Gemini CLI に対応しています。\nこのプラグインを使うと基本的に AI への入力にまつわる問題を Vim での文章作成における問題に帰着できます。\nつまり何が言いたいかというと AI の入力欄の機能に依存せずに AI への入力を作成できるということです。\nVim に帰着させることで改行しづらい問題や Gemini CLI にカスタムスラッシュコマンドがない問題などを全て解決できます。\n\n\n8.2. ddc.vim\nhttps://github.com/Shougo/ddc.vim\n補完機能を強化するために ddc.vim を使っています。\n\n\n8.3. skkeleton\nhttps://github.com/vim-skk/skkeleton\nVim で日本語入力をしづらいという問題を解決するために SKK を利用できる skkeleton を使っています。\n私は ddc.vim の source として利用しています。\n\n\n8.4. ddc-source-file\nhttps://github.com/LumaKernel/ddc-source-file\nddc.vim の source です。ファイル名やパスを補完してくれます。\n一応 Vim の補完機能で\n\nCTRL-X CTRL-F\n\nhttps://vim-jp.org/vimdoc-ja/usr_24.html#24.3\nを使用すると同等の補完ができますが、より快適な ddc.vim の補完機能がよいと思います。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#claude-code-設定",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#claude-code-設定",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "9. Claude Code 設定",
    "text": "9. Claude Code 設定\n\n9.1. $CLAUDE_CONFIG_DIR\n必ず設定しましょう。\n私は以下のように設定しています。\nexport CLAUDE_CONFIG_DIR=\"${XDG_CONFIG_HOME}\"/claude\n\n\n9.2. CLAUDE.md\n私は CLAUDE.md は作成していません。\nCLAUDE.md を作成せず Claude Code に最適化しすぎないことで Gemini CLI などの他の AI ツールに移行しやすくしようと考えています。\nもう1つの理由としては再読み込みが必要になる場面では CLAUDE.md よりカスタムスラッシュコマンドの再実行の方が楽だと感じているからです。\n\n\n9.3. カスタムスラッシュコマンド\nここが AI とやりとりをする上での肝になります。\n私の dotfiles では以下のカスタムスラッシュコマンドを用意しています。\n.\n└── commands\n    ├── commit.md\n    ├── CONTRIBUTING.md\n    ├── issue-to-pr.md\n    ├── learn-bigquery.md\n    ├── learn-databricks.md\n    ├── learn-dbt.md\n    └── review.md\nissue-to-pr.md については、羃等性をもたせ Anthropic のベストプラクティスに沿った形で Pull Request 作成に誘導できるコマンドに仕上げている最中で、ノウハウが蓄積されてきたら別途記事にしようと思います。\n\n\n9.4. settings.json\nあまり凝ったことはしていません。\n\n\nsettings.json\n\n{\n    \"permissions\": {\n        \"allow\": [\n        ],\n        \"deny\": [\n            \"Bash(rm:*)\",\n            \"WebFetch(domain:github.com)\"\n        ]\n    },\n    \"env\": {\n        \"BASH_DEFAULT_TIMEOUT_MS\": 300000,\n        \"BASH_MAX_TIMEOUT_MS\": 300000\n    },\n    \"includeCoAuthoredBy\": false\n}\n\n基本的に\nclaude --dangerously-skip-permissions\nで起動するので permissions に関しては allow ではなく deny を充実させていく方針で設定しています。\nClaude Code はよくファイル削除を試みるので Bash(rm:*) は必須だと思います。\n\n\n9.5. .claude.json\n通知音を鳴らすための設定を行います。\nclaude config set --global preferredNotifChannel terminal_bell\nこのコマンドを実行すると以下のような設定が .claude.json に追加されます。\n\n\n.claude.json\n\n  \"preferredNotifChannel\": \"terminal_bell\",\n\nこれで足りなければ Hooks 設定の作り込みで対応していきましょう。\n通知音設定については勉強中です。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#dev-container",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#dev-container",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "10. Dev Container",
    "text": "10. Dev Container\nDev Container で Claude Code を利用することで安全に\nclaude --dangerously-skip-permissions\nができます。\nhttps://docs.anthropic.com/en/docs/claude-code/devcontainer\nAnthropic 公式が示す .devcontainer がそのまま使えます。\n以下のようにグローバルな Claude Code 設定をマウントするなどして利便性向上を図りつつ使っていきましょう。\n\n\n.devcontainer/devcontainer.json\n\n    \"mounts\": [\n        \"source=claude-code-bashhistory-${devcontainerId},target=/commandhistory,type=volume\",\n        \"source=claude-code-config-${devcontainerId},target=/home/node/.claude,type=volume\",\n        \"source=${localEnv:HOME}/ghq/github.com/i9wa4/dotfiles/dot.config/claude,target=/home/node/.claude,type=bind,consistency=cached\"\n    ],\n\nhttps://github.com/devcontainers/cli\nDev Container を CLI で利用する際は Dev Container CLI を利用しましょう。"
  },
  {
    "objectID": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#おわりに",
    "href": "blog/2025-07-14-optimize-your-teminal-for-claude-code.html#おわりに",
    "title": "個人的ターミナル最適化 for Claude Code",
    "section": "11. おわりに",
    "text": "11. おわりに\n各項目それだけでも記事になるくらいの内容で消化が大変かもしれませんが参考になれば幸いです。"
  },
  {
    "objectID": "blog/2024-12-07-configure-onedrive.html",
    "href": "blog/2024-12-07-configure-onedrive.html",
    "title": "事故らない OneDrive 設定変更手順",
    "section": "",
    "text": "OneDrive でありがちな勝手にデスクトップのファイルが同期されている状況の回避策をポストしたところ反響がまあまあありました。\nhttps://x.com/i9wa4_/status/1864940454409834645\n意外と OneDrive って難しいのでこういった手順は需要があると分かり記事に残しておこうと思います。\n業務用PCが Windows ではなく Mac になってしまい詳細手順をスクショ付きで書けないので日和って個人ブログに書きます。"
  },
  {
    "objectID": "blog/2024-12-07-configure-onedrive.html#はじめに",
    "href": "blog/2024-12-07-configure-onedrive.html#はじめに",
    "title": "事故らない OneDrive 設定変更手順",
    "section": "",
    "text": "OneDrive でありがちな勝手にデスクトップのファイルが同期されている状況の回避策をポストしたところ反響がまあまあありました。\nhttps://x.com/i9wa4_/status/1864940454409834645\n意外と OneDrive って難しいのでこういった手順は需要があると分かり記事に残しておこうと思います。\n業務用PCが Windows ではなく Mac になってしまい詳細手順をスクショ付きで書けないので日和って個人ブログに書きます。"
  },
  {
    "objectID": "blog/2024-12-07-configure-onedrive.html#想定するユースケース",
    "href": "blog/2024-12-07-configure-onedrive.html#想定するユースケース",
    "title": "事故らない OneDrive 設定変更手順",
    "section": "2. 想定するユースケース",
    "text": "2. 想定するユースケース\n同期対象を「デスクトップ」や「ドキュメント」そのものではなく、明示的に作成したフォルダだけとしたい場合です。"
  },
  {
    "objectID": "blog/2024-12-07-configure-onedrive.html#事故らない-onedrive-セットアップ手順",
    "href": "blog/2024-12-07-configure-onedrive.html#事故らない-onedrive-セットアップ手順",
    "title": "事故らない OneDrive 設定変更手順",
    "section": "3. 事故らない OneDrive セットアップ手順",
    "text": "3. 事故らない OneDrive セットアップ手順\n\n全フォルダを OneDrive の同期対象から外す\n同期対象から外した「デスクトップ」や「ドキュメント」はこの時点では OneDrive フォルダ配下に置かれているので右クリックして「プロパティ→場所→標準に戻す」で元の場所 (%USERPROFILE% 直下) に戻す\n明示的にバックアップ対象としたいフォルダを OneDrive の同期対象に設定する\nブラウザで OneDrive にアクセスして不要なデータを削除する\nOneDrive の同期を再開する"
  },
  {
    "objectID": "blog/2024-12-07-configure-onedrive.html#おわりに",
    "href": "blog/2024-12-07-configure-onedrive.html#おわりに",
    "title": "事故らない OneDrive 設定変更手順",
    "section": "4. おわりに",
    "text": "4. おわりに\nOneDrive の操作手順を詳細に書けず心苦しいのですが、きっと何とかなるはず。信じてます。"
  },
  {
    "objectID": "blog/2025-04-29-mcp-databricks-server-service-principal.html",
    "href": "blog/2025-04-29-mcp-databricks-server-service-principal.html",
    "title": "Databricks MCP Server を Service Principal 認証対応させた",
    "section": "",
    "text": "https://github.com/RafaelCartenet/mcp-databricks-server\n上記の Databricks MCP Server を Service Principal 対応させたものを以下に公開しました。\nhttps://github.com/i9wa4/mcp-databricks-server/\n存在意義と利用方法について説明します。"
  },
  {
    "objectID": "blog/2025-04-29-mcp-databricks-server-service-principal.html#はじめに",
    "href": "blog/2025-04-29-mcp-databricks-server-service-principal.html#はじめに",
    "title": "Databricks MCP Server を Service Principal 認証対応させた",
    "section": "",
    "text": "https://github.com/RafaelCartenet/mcp-databricks-server\n上記の Databricks MCP Server を Service Principal 対応させたものを以下に公開しました。\nhttps://github.com/i9wa4/mcp-databricks-server/\n存在意義と利用方法について説明します。"
  },
  {
    "objectID": "blog/2025-04-29-mcp-databricks-server-service-principal.html#service-principal-とは",
    "href": "blog/2025-04-29-mcp-databricks-server-service-principal.html#service-principal-とは",
    "title": "Databricks MCP Server を Service Principal 認証対応させた",
    "section": "2. Service Principal とは",
    "text": "2. Service Principal とは\nhttps://docs.databricks.com/gcp/ja/admin/users-groups/service-principals\n\nサービスプリンシパルは、自動化とプログラムによるアクセス用に設計された Databricks の特殊な ID です。 サービスプリンシパル は、自動化されたツールとスクリプトに API のみのアクセスを Databricks リソースに付与し、users アカウントを使用するよりも優れたセキュリティを提供します。\n\n一言でまとめると人間に紐付かない ID なので適切な権限管理ができます！"
  },
  {
    "objectID": "blog/2025-04-29-mcp-databricks-server-service-principal.html#存在意義",
    "href": "blog/2025-04-29-mcp-databricks-server-service-principal.html#存在意義",
    "title": "Databricks MCP Server を Service Principal 認証対応させた",
    "section": "3. 存在意義",
    "text": "3. 存在意義\nDatabricks MCP Server を含む AI エージェントを社内展開しようと思っています。\nただ、Databricks MCP Server に必要な Token として私のアカウントで作成する Personal Access Token を使うのは権限が強すぎるのとクエリ履歴管理上良くないため Service Principal を使うようにしたかったのです。"
  },
  {
    "objectID": "blog/2025-04-29-mcp-databricks-server-service-principal.html#利用方法",
    "href": "blog/2025-04-29-mcp-databricks-server-service-principal.html#利用方法",
    "title": "Databricks MCP Server を Service Principal 認証対応させた",
    "section": "4. 利用方法",
    "text": "4. 利用方法\nhttps://github.com/i9wa4/mcp-databricks-server/\nこちらの README に記載していますが、fork 元と異なる点は環境変数として下の3つを読み込める状態にすることです。\nちなみに Service Principal 認証の場合は DATABRICKS_TOKEN は不要です。\nexport DATABRICKS_HOST=\"your-databricks-instance.cloud.databricks.com\"\nexport DATABRICKS_TOKEN=\"your-databricks-access-token\"\nexport DATABRICKS_SQL_WAREHOUSE_ID=\"your-sql-warehouse-id\"\n# for OAuth authentication\nexport DATABRICKS_CLIENT_ID=\"your-client-id\"\nexport DATABRICKS_CLIENT_SECRET=\"your-client-secret\"\nexport DATABRICKS_AUTH_TYPE=\"oauth\"\nDATABRICKS_CLIENT_ID と DATABRICKS_CLIENT_SECRET の作成方法は以下のドキュメントを参考にしてください。\nhttps://docs.databricks.com/aws/ja/dev-tools/auth/oauth-m2m"
  },
  {
    "objectID": "blog/2025-04-29-mcp-databricks-server-service-principal.html#おまけ実装上の工夫",
    "href": "blog/2025-04-29-mcp-databricks-server-service-principal.html#おまけ実装上の工夫",
    "title": "Databricks MCP Server を Service Principal 認証対応させた",
    "section": "5. おまけ：実装上の工夫",
    "text": "5. おまけ：実装上の工夫\n手元で Formatter を効かせてしまった都合で fork 元に Pull Request を出すのはちょっと難しくなってしまったのですが、それでも差分をできるだけ小さくしておきました。\nヘッダ作成に必要なトークン取得部分を同期関数にして、その中で OAuth or PAT という形で分岐させる構成が結構良い感じに書けたのではないかと思います。 OAuth を優先してる都合でここは非同期にはできないですよね。"
  },
  {
    "objectID": "blog/2024-11-12-use-nektos-act.html",
    "href": "blog/2024-11-12-use-nektos-act.html",
    "title": "nektos/act を使ってみた",
    "section": "",
    "text": "GitHub Actions をローカルで実行できる便利な OSS https://github.com/nektos/act を使ってみました。\nインストールが難しかったので苦戦した部分もメモを残しておきます。"
  },
  {
    "objectID": "blog/2024-11-12-use-nektos-act.html#筆者の環境について",
    "href": "blog/2024-11-12-use-nektos-act.html#筆者の環境について",
    "title": "nektos/act を使ってみた",
    "section": "1. 筆者の環境について",
    "text": "1. 筆者の環境について\n\nOS: WSL2 Ubuntu 24.04\nShell: zsh"
  },
  {
    "objectID": "blog/2024-11-12-use-nektos-act.html#バイナリどこ",
    "href": "blog/2024-11-12-use-nektos-act.html#バイナリどこ",
    "title": "nektos/act を使ってみた",
    "section": "2. バイナリどこ？？",
    "text": "2. バイナリどこ？？\nインストール手順 https://nektosact.com/installation/index.html に従って\ncurl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash\nを実行したはいいもののインストール先が分からず which act で探しても見つからず。\n(2024-11-19 追記: コマンド実行したディレクトリに bin/act が生成されていました。自分にとっては嬉しくない挙動。)\n続いて GitHub CLI extension としてのインストール方法が簡単そうに見えました。\ngh extension install https://github.com/nektos/gh-act\nただ、 GitHub CLI extension ってなに？そもそもその仕様を知る必要性を感じなかったためスルー。\n仕方がないのでソースコードからビルドすることに。\ngit clone https://github.com/nektos/act.git\ncd act/\nmake build\n\n# 因みに私の環境では以下コマンドでクローンしてます。\n# ghq get -p nekotos/act\nビルド後 ./dist/local/act なるバイナリが生成されたためインストール完了。\n面倒なので PATH は通してませんがよい子は通しておきましょう。"
  },
  {
    "objectID": "blog/2024-11-12-use-nektos-act.html#動作確認",
    "href": "blog/2024-11-12-use-nektos-act.html#動作確認",
    "title": "nektos/act を使ってみた",
    "section": "3. 動作確認",
    "text": "3. 動作確認\nhttps://github.com/i9wa4/gha-sandbox のうち .github/workflows/4.6.actionlint.yml を実行してみます。\n$ ~/src/github.com/nektos/act/dist/local/act workflow_dispatch -W '.github/workflows/4.6.actionlint.yml'\nINFO[0000] Using docker host 'unix:///var/run/docker.sock', and daemon socket 'unix:///var/run/docker.sock'\n[4.6. Linting GitHub Actions/lint] 🚀  Start image=catthehacker/ubuntu:act-latest\n[4.6. Linting GitHub Actions/lint]   🐳  docker pull image=catthehacker/ubuntu:act-latest platform= username= forcePull=true\n[4.6. Linting GitHub Actions/lint]   🐳  docker create image=catthehacker/ubuntu:act-latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[] network=\"host\"\n[4.6. Linting GitHub Actions/lint]   🐳  docker run image=catthehacker/ubuntu:act-latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[] network=\"host\"\n[4.6. Linting GitHub Actions/lint]   🐳  docker exec cmd=[node --no-warnings -e console.log(process.execPath)] user= workdir=\n[4.6. Linting GitHub Actions/lint] ⭐ Run Main actions/checkout@v4\n[4.6. Linting GitHub Actions/lint]   🐳  docker cp src=/home/i9wa4/src/github.com/i9wa4/gha-sandbox/. dst=/home/i9wa4/src/github.com/i9wa4/gha-sandbox\n[4.6. Linting GitHub Actions/lint]   ✅  Success - Main actions/checkout@v4\n[4.6. Linting GitHub Actions/lint] ⭐ Run Main docker run --rm -v \"$(pwd):$(pwd)\" -w \"$(pwd)\" rhysd/actionlint:latest\n[4.6. Linting GitHub Actions/lint]   🐳  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/1.sh] user= workdir=\n| Unable to find image 'rhysd/actionlint:latest' locally\n| latest: Pulling from rhysd/actionlint\n43c4264eed91: Pull complete\n9ff7a0d1399a: Pull complete\nefbbf3bc777d: Pull complete\n290bb4d6a286: Pull complete\nDigest: sha256:82244e1db1c60d82c7792180a48dd0bcb838370bb589d53ff132503fc9485868\n| Status: Downloaded newer image for rhysd/actionlint:latest\n[4.6. Linting GitHub Actions/lint]   ✅  Success - Main docker run --rm -v \"$(pwd):$(pwd)\" -w \"$(pwd)\" rhysd/actionlint:latest\n[4.6. Linting GitHub Actions/lint] Cleaning up container for job lint\n[4.6. Linting GitHub Actions/lint] 🏁  Job succeeded\n\nINFO    ️ 📣 A newer version of 'act' is available - consider ugrading to 0.2.69.\nうまく動いてくれました。"
  },
  {
    "objectID": "blog/2024-11-12-use-nektos-act.html#追記-mac-でエラーが出た場合",
    "href": "blog/2024-11-12-use-nektos-act.html#追記-mac-でエラーが出た場合",
    "title": "nektos/act を使ってみた",
    "section": "4. [2024-12-05 追記] Mac でエラーが出た場合",
    "text": "4. [2024-12-05 追記] Mac でエラーが出た場合\n以下の記事が参考になりました。\nWSL2でDocker buildをすると止まる問題(“docker-credential-desktop.exe”: executable file not found in $PATH, out: ``) #Docker - Qiita"
  },
  {
    "objectID": "blog/2025-06-10-install-global-python-with-uv.html",
    "href": "blog/2025-06-10-install-global-python-with-uv.html",
    "title": "uv で Python のグローバルインストールを行う",
    "section": "",
    "text": "Python 環境管理に uv を使い始めて以来 pyenv が不要になりアンインストールしたのですが、スポット的に Python のグローバルインストールが必要になったので uv での手順をメモしておきます。"
  },
  {
    "objectID": "blog/2025-06-10-install-global-python-with-uv.html#はじめに",
    "href": "blog/2025-06-10-install-global-python-with-uv.html#はじめに",
    "title": "uv で Python のグローバルインストールを行う",
    "section": "",
    "text": "Python 環境管理に uv を使い始めて以来 pyenv が不要になりアンインストールしたのですが、スポット的に Python のグローバルインストールが必要になったので uv での手順をメモしておきます。"
  },
  {
    "objectID": "blog/2025-06-10-install-global-python-with-uv.html#手順",
    "href": "blog/2025-06-10-install-global-python-with-uv.html#手順",
    "title": "uv で Python のグローバルインストールを行う",
    "section": "2. 手順",
    "text": "2. 手順\nPython versions | uv\n$ uv python install 3.12 --default --preview"
  },
  {
    "objectID": "blog/2024-03-25-setup-wsl2.html",
    "href": "blog/2024-03-25-setup-wsl2.html",
    "title": "WSL2 のセットアップ",
    "section": "",
    "text": "Windows マシンを新調する度に WSL2 をインストールしているので手順を書き残しておきます。"
  },
  {
    "objectID": "blog/2024-03-25-setup-wsl2.html#wsl-コマンドのインストール",
    "href": "blog/2024-03-25-setup-wsl2.html#wsl-コマンドのインストール",
    "title": "WSL2 のセットアップ",
    "section": "1. WSL コマンドのインストール",
    "text": "1. WSL コマンドのインストール\nWSL のインストール | Microsoft Learn に従います。\n\n管理者権限で PowerShell or コマンドプロンプトを開きます。\nwsl --install を実行します。 \n以下のように表示されるのでマシンを再起動します。"
  },
  {
    "objectID": "blog/2024-03-25-setup-wsl2.html#ディストリビューションのインストール",
    "href": "blog/2024-03-25-setup-wsl2.html#ディストリビューションのインストール",
    "title": "WSL2 のセットアップ",
    "section": "2. ディストリビューションのインストール",
    "text": "2. ディストリビューションのインストール\n\nPowerShell or コマンドプロンプトを開きます。\nインストール可能なディストリビューションを表示します。\nwsl --list --online\nUbuntu 22.04 LTS をインストールする場合は以下のように入力します。\nwsl --install -d Ubuntu-22.04\n画面表示に従ってユーザー名とパスワードを入力します。\nUbuntu を終了します。\nexit\n(必要に応じて) 既定のディストリビューションを設定します。\nwsl --set-default Ubuntu-22.04"
  },
  {
    "objectID": "blog/2024-03-25-setup-wsl2.html#ディストリビューションのアンインストール",
    "href": "blog/2024-03-25-setup-wsl2.html#ディストリビューションのアンインストール",
    "title": "WSL2 のセットアップ",
    "section": "3. ディストリビューションのアンインストール",
    "text": "3. ディストリビューションのアンインストール\n\nPowerShell or コマンドプロンプトを開きます。\nインストール済みのディストリビューションを表示します。\nwsl --list\n不要なディストリビューションをアンインストールします。\nwsl --unregister Ubuntu-22.04"
  },
  {
    "objectID": "blog/2024-03-25-setup-wsl2.html#詳細設定",
    "href": "blog/2024-03-25-setup-wsl2.html#詳細設定",
    "title": "WSL2 のセットアップ",
    "section": "4. 詳細設定",
    "text": "4. 詳細設定\n設定ファイルや systemd に関しては以下のページを参考にするとよいです。\nWSL での詳細設定の構成 | Microsoft Learn"
  },
  {
    "objectID": "blog/2025-04-01-try-aider.html",
    "href": "blog/2025-04-01-try-aider.html",
    "title": "Aider を使ってみる",
    "section": "",
    "text": "最近チームの生産性向上のためにAIツールの更なる活用を検討をしています。そうすると選択肢に出てくるのは Cursor だったり VS Code 拡張活用だったりするんですよね。\nVimmer である私はチームの開発環境整備では VS Code を基準に考えるくらいの社会性は残してますが、ギリギリまで Vim と付き合い続けたいと思っていて最近もどかしさを感じてました。\nそんな中以下の光明が差したのです！\nVimmer にお勧めしたい AI エージェント「Aider」\nさっそく使ってみましょう。"
  },
  {
    "objectID": "blog/2025-04-01-try-aider.html#はじめに",
    "href": "blog/2025-04-01-try-aider.html#はじめに",
    "title": "Aider を使ってみる",
    "section": "",
    "text": "最近チームの生産性向上のためにAIツールの更なる活用を検討をしています。そうすると選択肢に出てくるのは Cursor だったり VS Code 拡張活用だったりするんですよね。\nVimmer である私はチームの開発環境整備では VS Code を基準に考えるくらいの社会性は残してますが、ギリギリまで Vim と付き合い続けたいと思っていて最近もどかしさを感じてました。\nそんな中以下の光明が差したのです！\nVimmer にお勧めしたい AI エージェント「Aider」\nさっそく使ってみましょう。"
  },
  {
    "objectID": "blog/2025-04-01-try-aider.html#aider-インストール",
    "href": "blog/2025-04-01-try-aider.html#aider-インストール",
    "title": "Aider を使ってみる",
    "section": "2. Aider インストール",
    "text": "2. Aider インストール\nhttps://aider.chat/docs/install.html\npython -m pip install aider-install\naider-install"
  },
  {
    "objectID": "blog/2025-04-01-try-aider.html#gemini-との接続",
    "href": "blog/2025-04-01-try-aider.html#gemini-との接続",
    "title": "Aider を使ってみる",
    "section": "3. Gemini との接続",
    "text": "3. Gemini との接続\nLLM 専用にアカウントを作るのがあまり好きではないので Google アカウントで使える Gemini に期待してます。\n手順としては以下です。\nhttps://aider.chat/docs/llms/gemini.html\nまず Gemini API キーを取得していきましょう。\n\n3.1. Gemini API キーの取得\n\nhttps://ai.google.dev/gemini-api/docs の “Get a Gemini API key” をクリックする\nプライバシーポリシーに同意する\nhttps://aistudio.google.com/apikey から API キーを取得する\nhttps://console.cloud.google.com/billing/projects で当該プロジェクトの請求先アカウントを確認する\n\nNOTE: 取り急ぎ私は課金したくないので請求が無効であることを確認しました\n\n\n\n\n3.2. Gemini の設定\n公式手順に沿って以下の準備をしておきます。\npython -m pip install -U aider-chat\npip install -U google-generativeai"
  },
  {
    "objectID": "blog/2025-04-01-try-aider.html#aider-の利用例",
    "href": "blog/2025-04-01-try-aider.html#aider-の利用例",
    "title": "Aider を使ってみる",
    "section": "4. Aider の利用例",
    "text": "4. Aider の利用例\nAider の利用例として私の自作プラグインの簡単なバグ修正をやってみます。\nissue は以下です。\nignore compiled model · Issue #1 · i9wa4/vim-dbt-jump2def\n\n4.1. GEMINI_API_KEY の読み込み\n# export GEMINI_API_KEY=xxxx を ~/.env に書いてます\n$ . ~/.env\n\n\n4.2. Gemini の利用可能なモデルの確認\n$ aider --list-models gemini/\n──────────────────────────────────────────────────────────────────────────────────────────────────────────\nModels which match \"gemini/\":\n- gemini/gemini-1.5-flash\n- gemini/gemini-1.5-flash-001\n- gemini/gemini-1.5-flash-002\n- gemini/gemini-1.5-flash-8b\n- gemini/gemini-1.5-flash-8b-exp-0827\n- gemini/gemini-1.5-flash-8b-exp-0924\n- gemini/gemini-1.5-flash-exp-0827\n- gemini/gemini-1.5-flash-latest\n- gemini/gemini-1.5-pro\n- gemini/gemini-1.5-pro-001\n- gemini/gemini-1.5-pro-002\n- gemini/gemini-1.5-pro-exp-0801\n- gemini/gemini-1.5-pro-exp-0827\n- gemini/gemini-1.5-pro-latest\n- gemini/gemini-2.0-flash\n- gemini/gemini-2.0-flash-001\n- gemini/gemini-2.0-flash-exp\n- gemini/gemini-2.0-flash-lite\n- gemini/gemini-2.0-flash-lite-preview-02-05\n- gemini/gemini-2.0-flash-thinking-exp\n- gemini/gemini-2.0-flash-thinking-exp-01-21\n- gemini/gemini-2.0-pro-exp-02-05\n- gemini/gemini-2.5-pro-exp-03-25\n- gemini/gemini-exp-1114\n- gemini/gemini-exp-1206\n- gemini/gemini-gemma-2-27b-it\n- gemini/gemini-gemma-2-9b-it\n- gemini/gemini-pro\n- gemini/gemini-pro-vision\n- gemini/gemma-3-27b-it\n- gemini/learnlm-1.5-pro-experimental\n\n\n4.3. gemini-2.0-flash-001 を利用する\n$ aider --model gemini/gemini-2.0-flash-001\n──────────────────────────────────────────────────────────────────────────────────────────────────────────\nAider v0.80.0\nModel: gemini/gemini-2.0-flash-001 with whole edit format\nGit repo: .git with 9 files\nRepo-map: using 4096 tokens, auto refresh\n──────────────────────────────────────────────────────────────────────────────────────────────────────────\n\n\n4.4. バグ修正のプロンプト\nここで修正コミットをしてくれました。すごいですね。\n&gt; in denops/dbt-jump2def/main.ts, I want to fix not to jump to the model in \"target\" directory.\n\n\ndenops/dbt-jump2def/main.ts\nAdd file to the chat? (Y)es/(N)o/(D)on't ask again [Yes]: yes\nOk, I understand. You want to modify the denops/dbt-jump2def/main.ts file so that it doesn't jump to\nmodels located in the \"target\" directory. I will achieve this by excluding the \"target\" directory from the\nsearch path when using fn.findfile.\n\nHere's the updated denops/dbt-jump2def/main.ts file:\n\ndenops/dbt-jump2def/main.ts\n\n\n@@ -1,4 +1,5 @@\n export const main: Entrypoint = (denops: Denops) =&gt; {\n'jumpToModelDefinition', [&lt;q-args&gt;])`,\n       }\n\n       // get the relative path of the target model\n+      // exclude the \"target\" directory\n       const targetModelRalativePath = await fn.findfile(\n         denops,\n         `${targetModelName}.sql`,\n-        dbtProjectRootPath + \"**\",\n+        dbtProjectRootPath + \"**,!target/**\",\n       );\n\n       // if the target model not found, show error message\n       if (!targetModelRalativePath) {\n         await helper.echoerr(\n@@ -64,5 +65,6 @@\n         );\n         return;\n       }\n\n       // get the absolute path of the target model\n+  68 /  84 lines [████████████████████████░░░░░░]  81%\n\n\nTokens: 1.5k sent, 782 received. Cost: $0.00046 message, $0.00046 session.\nApplied edit to denops/dbt-jump2def/main.ts\nCommit 3ba9cfb fix: Exclude \"target\" directory from model search path.\nYou can use /undo to undo and discard each aider commit.\n──────────────────────────────────────────────────────────────────────────────────────────────────────────\n\n\n4.5. 終わり\ndenops/dbt-jump2def/main.ts\n&gt; /exit\n\n\n4.6. 実は……\n上記コミットは Gemini 2.0 Pro が適当な修正してくれてたので動きませんでした。\n結局 Gemini 2.5 Pro に聞きながら正しい対応を入れました。\nまだ私が LLM に慣れてないんだなぁと感じました。"
  },
  {
    "objectID": "blog/2025-04-01-try-aider.html#感想",
    "href": "blog/2025-04-01-try-aider.html#感想",
    "title": "Aider を使ってみる",
    "section": "5. 感想",
    "text": "5. 感想\nAider すごいです。Aider に慣れていけば LLM をすげ替えるだけで流行りに乗り続けられるので安心して乗っかれますね。\nプロンプトの精度も磨いていく必要性を感じました。\nとにかく使い慣れていかねば！"
  },
  {
    "objectID": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html",
    "href": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html",
    "title": "Bash/Zsh でコマンドをエディタで編集する",
    "section": "",
    "text": "Bash/Zsh で入力中のコマンドの編集にエディタが使えるという便利機能の話です。名前がパッと出てこないのでメモ代わりに記事にしておきます。"
  },
  {
    "objectID": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#はじめに",
    "href": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#はじめに",
    "title": "Bash/Zsh でコマンドをエディタで編集する",
    "section": "",
    "text": "Bash/Zsh で入力中のコマンドの編集にエディタが使えるという便利機能の話です。名前がパッと出てこないのでメモ代わりに記事にしておきます。"
  },
  {
    "objectID": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#bash",
    "href": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#bash",
    "title": "Bash/Zsh でコマンドをエディタで編集する",
    "section": "2. Bash",
    "text": "2. Bash\nC-x C-e で $VISUAL で指定したエディタが開きます。\nbash で入力中のコマンドをエディタで編集して実行するショートカットキー #Bash - Qiita"
  },
  {
    "objectID": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#zsh",
    "href": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#zsh",
    "title": "Bash/Zsh でコマンドをエディタで編集する",
    "section": "3. Zsh",
    "text": "3. Zsh\nBash と同等の機能を実現させるには以下のように設定します。\n\n\n~/.zshrc\n\nautoload -Uz edit-command-line\nzle -N edit-command-line\nbindkey '^x^e' edit-command-line"
  },
  {
    "objectID": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#おわりに",
    "href": "blog/2025-05-10-bash-zsh-edit-and-execute-command.html#おわりに",
    "title": "Bash/Zsh でコマンドをエディタで編集する",
    "section": "4. おわりに",
    "text": "4. おわりに\nedit-and-execute-command あるいは edit-command-line と呼ばれる機能であると覚えましょう！"
  },
  {
    "objectID": "blog/2025-09-02-activity.html",
    "href": "blog/2025-09-02-activity.html",
    "title": "2025年のアウトプットまとめ with LAPRAS",
    "section": "",
    "text": "2025年のアウトプットと参加イベントをふりかえると\nアウトプットしたものや参加したイベントなどをまとめてみました。"
  },
  {
    "objectID": "blog/2025-09-02-activity.html#connpass",
    "href": "blog/2025-09-02-activity.html#connpass",
    "title": "2025年のアウトプットまとめ with LAPRAS",
    "section": "1. connpass",
    "text": "1. connpass\n\n2025/09/29\n\nDataOps Night #8 ～スケーラブルでAI-Readyなデータ基盤の最前線～\n\n2025/07/29\n\nエンタメ業界のデータエンジニアリング最前線＃2 ～SEGA、DeNA\n\n2025/07/28\n\nt-wadaさんに聞く！SQLアンチパターン第2版 - 全27章まとめて紹介！\n\n2025/07/18\n\n祝30回！過去登壇者と振り返るデータエンジニアの技術とキャリアのこれまでとこれから\n\n2025/07/17\n\nClaude Code Meetup\n\n2025/07/13\n\n【！現地参加枠あり！】CoLab Conf（コラコン）【U35限定テックカンファレンス】\n\n2025/07/08\n\nClaude Code Meetup Japan #1（Claude Code祭り！）\n\n2025/07/04\n\nData Modeling Night -「今」だからできる理論の実践事例 -\n\n2025/06/30\n\nClaude Code Deep Dive\n\n2025/06/25\n\nDatabase Engineering Meetup #7: データエンジニアリング\n\n2025/06/24\n\nエンタメ業界のデータエンジニアリング最前線＃１　～GENDA、バンダイナムコセブンズ\n\n2025/06/20\n\n【SREキャリア最前線】AIと共に進化する！SREの新たな役割とキャリア設計\n\n2025/06/17\n\nMCP導入における脅威モデリングのすゝめ\n\n2025/06/12\n\nエンジニアのためのMCP勉強会 #2\n\n2025/06/06\n\nCursor Meetup Tokyo\n\n2025/06/03\n\nITエンジニアの転職学 – “20代で年収800万円最速RTA”と“その罠”\n\n2025/06/02\n\nMCP Ops LT大会！！！\n\n2025/05/28\n\nCursorで創作小説を書こう！の会【女オタ生成AI部/株式会社エクスプラザ 共催】\n\n2025/05/27\n\nDataOps Night #7\n\n2025/05/16\n\n転職したらMCPサーバーだった件\n\n2025/05/14\n\nJEDAI Meetup! Databricks Apps特集 (ハイブリッド開催)\n\n2025/05/14\n\n【技術選定を突き詰める】Online Conferenc​​e 2025\n\n2025/05/13\n\nCursor導入でログラス社の現場はどう変わったか - Forkwell AI Study #1\n\n2025/05/12\n\n「データマネジメント」その先へ〜進化するデータと組織戦略～\n\n2025/04/25\n\nMCPでLLMはどう進化する？ 〜からあげさんに学ぶ、AI開発の最前線〜\n\n2025/04/25\n\nJEDAI in Osaka 2025 春 (オンサイト+オンライン)\n\n2025/04/24\n\nData Engineering Study #29 今だから学びたいDatabricks徹底活用術\n\n2025/04/10\n\nデータエンジニアの未来【サポーターズCoLab】\n\n2025/03/25\n\nABEMAの事例とともに学ぶ！セマンティックレイヤーで変わるデータエンジニアリングの世界\n\n2025/03/21\n\nITエンジニアの転職学 ー 40歳へのカウントダウンとの向き合い方\n\n2025/02/27\n\nData Engineering Study #28 データ基盤のCI/CD\n\n2025/02/04\n\n金融業界のデータマネジメント最前線 #6\n\n2025/01/30\n\nみんなの考えた最強のデータアーキテクチャ〜2025もやってきましょうSP！\n\n2025/01/27\n\nレイクハウスって結局何なのっていいました？じゃあ真のレイクハウスをみせてやりますよ！\n\n2025/01/24\n\nJR西日本・ファーストリテイリング・ZOZOが語るビジネス要件を踏まえたデータ基盤の構築\n\n2025/01/20\n\ndatatech-jp Casual Talks #6"
  },
  {
    "objectID": "blog/2025-09-02-activity.html#blog等",
    "href": "blog/2025-09-02-activity.html#blog等",
    "title": "2025年のアウトプットまとめ with LAPRAS",
    "section": "2. Blog等",
    "text": "2. Blog等\n\n2025/08/23\n\n2025-08-23 日誌\n\n2025/07/28\n\nDatabricks Connect 実践編 - ローカルから Databricks コンピュートを利用\n\n2025/07/28\n\nPython 開発環境最適化編 - uv + pre-commit + GitHub Actions\n\n2025/07/28\n\nClaude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも\n\n2025/07/14\n\n個人的ターミナル最適化 for Claude Code\n\n2025/07/14\n\nVimへの初コントリビューションの経緯と学び\n\n2025/06/20\n\ntmux で Vim から Claude Code にテキストを送信するプラグインを作った\n\n2025/06/15\n\nローカル dbt で BigQuery への認証を行う\n\n2025/06/10\n\nuv で Python のグローバルインストールを行う\n\n2025/06/08\n\nPoetry の pyproject.toml を使って uv で .venv を作成する\n\n2025/06/04\n\nVim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法\n\n2025/05/21\n\nDatabricks AI/BI ダッシュボードの Git 連携の運用方法\n\n2025/05/12\n\nAWS Lambda でコンテナイメージを実行する with Terraform & GitHub Actions\n\n2025/05/10\n\nBash/Zsh でコマンドをエディタで編集する\n\n2025/05/06\n\n今更ながら Vim に EditorConfig を導入しました\n\n2025/05/06\n\nPython venv インストール・更新スクリプトの供養\n\n2025/05/06\n\nMarkdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する\n\n2025/05/04\n\ntmux と Zsh に Git リポジトリのステータスを表示する\n\n2025/04/29\n\nDatabricks MCP Server を Service Principal 認証対応させた\n\n2025/04/20\n\nlefthook 設定の供養\n\n2025/04/11\n\nMCP に入門した\n\n2025/04/10\n\nGemini API に課金した\n\n2025/04/10\n\nGemini に課金した\n\n2025/04/07\n\n個人的ブックマーク\n\n2025/04/02\n\n2024年度を振り返る\n\n2025/04/01\n\nAider を使ってみる\n\n2025/02/21\n\n見やすい SQL を書くための Tips\n\n2025/02/20\n\n最近の Vim プラグイン開発のアイデア\n\n2025/01/31\n\nInstagram API のアクセストークンを取得する"
  },
  {
    "objectID": "blog/2025-09-02-activity.html#zenn",
    "href": "blog/2025-09-02-activity.html#zenn",
    "title": "2025年のアウトプットまとめ with LAPRAS",
    "section": "3. Zenn",
    "text": "3. Zenn\n\n2025/08/06\n\nDatabricks Connect 実践編 - ローカルから Databricks コンピュートを利用\n\n2025/08/06\n\nPython 開発環境最適化編 - uv + pre-commit + GitHub Actions\n\n2025/08/06\n\nClaude Code 対応 Dev Container 環境構築編 - VS Code でもそれ以外でも\n\n2025/07/16\n\n個人的ターミナル最適化 for Claude Code\n\n2025/05/06\n\nMarkdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する\n\n2025/05/04\n\ntmux と Zsh に Git リポジトリのステータスを表示する\n\n2025/04/29\n\nDatabricks MCP Server を Service Principal 認証対応させた\n\n2025/04/16\n\nPython でありがちな本体バージョンとライブラリバージョンの不整合の例\n\n2025/04/05\n\nDevin 週報作成用プロンプト\n\n2025/04/05\n\nDevin に週報を書いてもらった\n\n2025/03/28\n\nNotion データベースでリレーション元のプロパティを表示する (2025年3月28日時点)"
  },
  {
    "objectID": "blog/2025-09-02-activity.html#pr作成",
    "href": "blog/2025-09-02-activity.html#pr作成",
    "title": "2025年のアウトプットまとめ with LAPRAS",
    "section": "4. PR作成",
    "text": "4. PR作成\n\n2025/08/06\n\ni9wa4/zenn-i9wa4\n\n2025/07/28\n\ni9wa4/i9wa4.github.io\n\n2025/07/16\n\ni9wa4/zenn-i9wa4\n\n2025/07/14\n\ni9wa4/vim-tmux-send-to-ai-cli\n\n2025/07/14\n\ni9wa4/vim-markdown-number-header\n\n2025/07/14\n\ni9wa4/i9wa4.github.io\n\n2025/07/14\n\ni9wa4/dotfiles\n\n2025/07/13\n\ni9wa4/i9wa4.github.io\n\n2025/06/26\n\ni9wa4/vim-tmux-send-to-ai-cli\n\n2025/06/25\n\ni9wa4/vim-tmux-send-to-ai-cli\n\n2025/06/19\n\ni9wa4/mcp-databricks-server\n\n2025/05/19\n\ni9wa4/terraform-mono-repo\n\n2025/05/18\n\ni9wa4/terraform-mono-repo\n\n2025/05/10\n\ni9wa4/i9wa4.github.io\n\n2025/05/06\n\ni9wa4/zenn-i9wa4\n\n2025/05/06\n\ni9wa4/vim-markdown-number-header\n\n2025/05/04\n\ni9wa4/zenn-i9wa4\n\n2025/04/29\n\ni9wa4/zenn-i9wa4\n\n2025/04/29\n\ni9wa4/mcp-databricks-server\n\n2025/04/16\n\ni9wa4/zenn-i9wa4\n\n2025/04/08\n\ni9wa4/i9wa4.github.io\n\n2025/04/05\n\ni9wa4/zenn-i9wa4\n\n2025/04/02\n\ni9wa4/i9wa4.github.io\n\n2025/04/01\n\ni9wa4/vim-dbt-jump2def\n\n2025/03/31\n\ni9wa4/vim-dbt-jump2def\n\n2025/03/28\n\ni9wa4/zenn-i9wa4\n\n2025/03/15\n\ni9wa4/vim-markdown-number-header\n\n2025/03/15\n\ni9wa4/vim-dbt-jump2def"
  },
  {
    "objectID": "blog/2025-09-02-activity.html#リポジトリ作成",
    "href": "blog/2025-09-02-activity.html#リポジトリ作成",
    "title": "2025年のアウトプットまとめ with LAPRAS",
    "section": "5. リポジトリ作成",
    "text": "5. リポジトリ作成\n\n2025/06/20\n\ni9wa4/vim-tmux-send-to-ai-cli\n\n2025/05/03\n\ni9wa4/quarto-slides\n\n2025/04/29\n\ni9wa4/mcp-databricks-server\n\n2025/04/10\n\ni9wa4/mcp-hands-on\n\n2025/03/23\n\ni9wa4/terraform-mono-repo\n\n2025/02/06\n\ni9wa4/databricks-notebook-test\n\n\nLAPRASポートフォリオはこちらから"
  },
  {
    "objectID": "blog/2025-04-10-paid-for-gemini-api.html",
    "href": "blog/2025-04-10-paid-for-gemini-api.html",
    "title": "Gemini API に課金した",
    "section": "",
    "text": "個人的に試したいことの数に対して無料枠では流石に足りないので課金しました。\nCursor でもいいかと思いましたが Vim やコマンドラインでも使える汎用性を考えて Gemini API への課金としました。"
  },
  {
    "objectID": "blog/2025-04-10-paid-for-gemini-api.html#手順",
    "href": "blog/2025-04-10-paid-for-gemini-api.html#手順",
    "title": "Gemini API に課金した",
    "section": "1. 手順",
    "text": "1. 手順\n\nGoogle AI Studio の API Plan Billing から Gemini AI 向けの Google Cloud プロジェクトの支払い情報に飛ぶ\n\nhttps://aistudio.google.com/plan_information\n\nGemini AI プロジェクトに対して請求先アカウントをリンクさせる\n請求課金アカウントで予算とアラートを設定して課金額に敏感にしておく"
  },
  {
    "objectID": "blog/2025-02-21-plain-sql.html",
    "href": "blog/2025-02-21-plain-sql.html",
    "title": "見やすい SQL を書くための Tips",
    "section": "",
    "text": "dbt モデルやダッシュボード向けの SQL を書くことが多いので戒めの意味も込めて見やすい SQL を書くための Tips をまとめてみました。\n因みに私がよく書くダッシュボード向けの SQL は基本的に select, sum, avg, 日付操作くらいでレコード数もそんなに多くないので重い長大な SQL を書くような方とは観点が異なるはずです。\n勢いで書いたので思い出したらどんどん追記します"
  },
  {
    "objectID": "blog/2025-02-21-plain-sql.html#フォーマッタで整形する",
    "href": "blog/2025-02-21-plain-sql.html#フォーマッタで整形する",
    "title": "見やすい SQL を書くための Tips",
    "section": "1. フォーマッタで整形する",
    "text": "1. フォーマッタで整形する\nフォーマッタを使って統一感のある SQL を書きましょう。\nsqlfmt が個人的におすすめです。"
  },
  {
    "objectID": "blog/2025-02-21-plain-sql.html#with-句を使う",
    "href": "blog/2025-02-21-plain-sql.html#with-句を使う",
    "title": "見やすい SQL を書くための Tips",
    "section": "2. with 句を使う",
    "text": "2. with 句を使う\nネストすると認知負荷が高まるので使ったほうがいいと思ってます。\n良い例が全然浮かびませんが、以下のように最後の select 文が単純になっていると SQL 文をちょっと書き換えて様子見がしやすいです。\nwith\n    a as (select id, name from table_a),\n    b as (select id, common_id from table_b),\n    out as (\n        select a.id as `顧客ID`, a.name as `顧客名`, b.common_id as `共通ID`\n        from a\n        left outer join b on a.id = b.id\n        order by a.id\n    )\nselect *\nfrom out"
  },
  {
    "objectID": "blog/2025-02-21-plain-sql.html#つのサブクエリに1つの目的を持たせる",
    "href": "blog/2025-02-21-plain-sql.html#つのサブクエリに1つの目的を持たせる",
    "title": "見やすい SQL を書くための Tips",
    "section": "3. 1つのサブクエリに1つの目的を持たせる",
    "text": "3. 1つのサブクエリに1つの目的を持たせる\nもちろん with 句で名前をつけたサブクエリの話をしてます。\nごちゃごちゃとしたサブクエリは読みづらいし再利用しづらいので1つのサブクエリに1つの目的を持たせるようにしましょう。\n例えば最終出力のためにカラムをリネームするのであれば、そのためだけのサブクエリを作るといいです。"
  },
  {
    "objectID": "blog/2025-02-21-plain-sql.html#省略表現を減らす",
    "href": "blog/2025-02-21-plain-sql.html#省略表現を減らす",
    "title": "見やすい SQL を書くための Tips",
    "section": "4. 省略表現を減らす",
    "text": "4. 省略表現を減らす\nこれはもはや好みの問題かもしれません。\n例えば\nselect * from table_a\nと書いてしまうとデータカタログを参照してカラム名を確認する必要が出てくるので結果的に手間になることがあります。\n私は初登場するカラム名は明記するようにしてます。\norder by 1, 2\norder by all\nなども便利ではあるものの、再利用性を重視したい！と思ったら避けるのが吉です。\nleft outer join table_b using (id)\nもそうですね。いつも同じ書き方ができるとは限らないので\nleft outer join table_b on table_a.id = table_b.id\nと書いて書き味をいつも同じにしておきたいです。\nこれ重要な論点だと思うのですが、生成AIをコーディングの補助に使う場合は愚直にしつこく書いたほうが結果的に楽だったりします。"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html",
    "href": "blog/2025-05-06-quarto-slides.html",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "",
    "text": "最近 AI にスライドを生成させたいという声をよく聞くようになりましたので、私の好きな Markdown ライクなツールである Quarto でスライドを作成する方法を紹介します。\nOrganization のプライベートリポジトリでも気軽に使えるように GitHub Pages として公開する手順ではなく GitHub Actions で HTML 出力する方法を紹介していきます。"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#はじめに",
    "href": "blog/2025-05-06-quarto-slides.html#はじめに",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "",
    "text": "最近 AI にスライドを生成させたいという声をよく聞くようになりましたので、私の好きな Markdown ライクなツールである Quarto でスライドを作成する方法を紹介します。\nOrganization のプライベートリポジトリでも気軽に使えるように GitHub Pages として公開する手順ではなく GitHub Actions で HTML 出力する方法を紹介していきます。"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#想定読者",
    "href": "blog/2025-05-06-quarto-slides.html#想定読者",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "2. 想定読者",
    "text": "2. 想定読者\n\nGitHub や GitHub Actions の操作説明がなくても問題ない方"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#quarto-とは",
    "href": "blog/2025-05-06-quarto-slides.html#quarto-とは",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "3. Quarto とは",
    "text": "3. Quarto とは\nhttps://quarto.org/\n\nAn open-source scientific and technical publishing system\n\nオープンソースの科学技術出版システムです。Pandoc をベースにしていて手軽でありつつも拡張性があり細かいところに手が届くという印象です。 上記リンクのページも Quarto で作成されていると聞くと表現の幅広さが分かると思います。\nGitHub Pages でブログ・スライド・Wikiを公開することも非常に簡単にできます。私は個人ページを Quarto で作成しています。 GitHub Pages での公開方法が気になる方は以下の記事を参考にしてください。\nMarkdown ライクな Quarto でブログやスライドを作って GitHub Pages で公開する"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#この記事でやること",
    "href": "blog/2025-05-06-quarto-slides.html#この記事でやること",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "4. この記事でやること",
    "text": "4. この記事でやること\n\nQuarto 向けリポジトリを作成する\nQuarto (reveal.js) でスライドを作成する\nGitHub Actions で HTML 出力する"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#この記事でやらないこと",
    "href": "blog/2025-05-06-quarto-slides.html#この記事でやらないこと",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "5. この記事でやらないこと",
    "text": "5. この記事でやらないこと\n\n作成物を GitHub Pages として公開する"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#quarto-でスライドを作成する",
    "href": "blog/2025-05-06-quarto-slides.html#quarto-でスライドを作成する",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "6. Quarto でスライドを作成する",
    "text": "6. Quarto でスライドを作成する\nでは Quarto を使ってスライドを作成していきましょう！\n\n6.1. Quarto をインストールする\nPython 環境のある方は pip でインストールできます。\npip install quarto-cli\n公式からインストーラも提供されています。私は利用したことがないため詳細の説明は省きます。\nhttps://quarto.org/docs/get-started/\n\n\n6.2. (任意) VS Code の Quarto の拡張機能をインストールする\nhttps://marketplace.visualstudio.com/items?itemName=quarto.quarto\nQuarto では .qmd という拡張子のファイルを使用します。VS Code の場合は Quarto 拡張機能をインストールすることで編集体験が向上しますので是非検討してみてください。 ここでは誰でも再現可能な手順の説明に終始するため VS Code の Quarto 拡張機能に関する説明は省きます。\n\n\n6.3. GitHub リポジトリを作成する\n空のリポジトリを作ったあと以下の構成を作っていきます。\n./\n├── _quarto.yml\n├── .github/\n│   └── workflows/\n│       └── deploy.yml\n├── .gitignore\n├── assets/\n│   └── common/\n│       └── title-background.jpg\n├── custom.scss\n├── index.qmd\n└── slides/\n    └── 2025-05-05-initial-slide.qmd\n以下で各ファイルの説明をしていくので真似て作成してみてください。\n\n6.3.1. _quarto.yml\nプロジェクトの設定を記述しておくファイルです。\ntitle-slide-attributes でタイトルスライドの背景色や画像を指定できますが不要な方は削除してください。\n気になる項目は公式ドキュメント\nhttps://quarto.org/\nの検索欄から調べる、もしくは上記ページを管理しているリポジトリの DeepWiki\nhttps://deepwiki.com/quarto-dev/quarto-web\nに質問するとほとんど全て解決できると思います。\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: \"_output\"\n\ndate-format: iso\n\nwebsite:\n  title: \"quarto-slides\"\n  navbar: true\n  search: false\n\nformat:\n  revealjs:\n    code-copy: true\n    scrollable: true\n    self-contained: true\n    slide-level: 3\n    slide-number: true\n    theme:\n      - default\n      # - custom.scss\n    width: 1920\n    height: 1080\n    title-slide-attributes:\n      data-background-color: \"#000000\"\n      data-background-image: \"/assets/common/title-background.jpg\"\n      data-background-size: \"cover\"\n\n\n\n6.3.2. .github/workflows/deploy.yml\nHTML 出力させる GitHub Actions ワークフロー設定ファイルの例です。\nとりあえず下記で動くので、必要に応じて色々変更してください。\n\n\n.github/workflows/deploy.yml\n\nname: Build and Deploy Quarto Website\nrun-name: ${{ github.event_name }} on ${{ github.ref_name }} by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\npermissions: {}\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build-and-deploy:\n    name: Build and Deploy Quarto Slides\n    runs-on: ubuntu-24.04-arm\n    timeout-minutes: 5\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n      # - name: (Optional) Set up Python\n      #   uses: actions/setup-python@v5\n      # - name: (Optional) Set up Python Libraries\n      #   run: python3 -m pip install jupyter\n      - name: Render Quarto Website\n        run: |\n          quarto render\n      - name: Deploy to HTML branch\n        uses: JamesIves/github-pages-deploy-action@v4\n        with:\n          folder: _output\n          branch: html\n          clean: true\n\n\n\n6.3.3. .gitignore\nQuarto の生成物を無駄に GitHub に push したくないので作成しておきます。\n\n\n.gitignore\n\n/.quarto/\n/_output/\n\n\n\n6.3.4. assets/common/title-background.jpg\nタイトルスライドの背景画像を指定するための画像ファイルです。なくても良いです。\n\n\n6.3.5. custom.scss\nQuarto で作成するスライドの見た目をカスタマイズするためのファイルです。名前は任意です。\nここでは一旦不要ですが編集のコツを後述しますので所定のスライドテンプレートの反映に活用してください。\n\n\n6.3.6. index.qmd\nQuarto のトップページを作成するためのファイルです。\nリポジトリで管理するスライドが複数になったときにインデックスページとして役に立ってくれると思います。\n\n\nindex.qmd\n\n---\ntitle: \"quarto-slides\"\nlisting:\n  - id: \"list-all\"\n    contents:\n      - \"slides\"\n    sort:\n      - \"date desc\"\n      - \"title\"\nformat:\n  html:\n    self-contained: true\n---\n\n::: {#list-all}\n:::\n\n\n\n\n6.4. スライドを作成する\nよくある記法を記載しましたので参考にしてください。\nh2 レベル ## でタイトルのみのスライドを作成します。 h3 レベル ### を区切りにスライドを分けていきます。\nh3 レベル ### が区切りになっているのは _quarto.yml の以下の設定値によるものです。\n\nslide-level: 3\n\nスライドを左右に分割することも多いと思いますが、以下のファイルの記述を真似ることで簡単に作成できます。\n\n\nslides/2025-05-05-initial-slide.qmd\n\n---\ntitle: スライドタイトル スライドタイトル スライドタイトル\nauthor: uma-chan\ndate: 2025-05-05\n---\n\n## test\n\n### aaaa aaaaaaaaaaaaaaa aaaaaaaaaaaaaaa aaaaaaaaaaa\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n[https://example.com](https://example.com)\n\nhttps://example.com\n\nhttps://example.com\n\n- bbbbbbbbbbbbbb\n- ccccccccccc\n    1. aaaaaa\n    1. bbbbbb\n\n&gt; test test\n\n`test`\n\n&gt; ```{.yaml}\n&gt; format:\n&gt;   revealjs:\n&gt;     # incremental: true\n&gt;     # mainfont: \"Noto Sans JP\"\n&gt;     slide-level: 3\n&gt; ```\n\n:::\n\n::: {.column width=\"50%\"}\n\n&gt; test test\n\n`test`\n\n&gt; ```{.py}\n&gt; print(\"Hello, world!\")\n&gt; ```\n\n:::\n\n::::\n\n## test\n\n### aaaaaaaa\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\n| aaa | bbb | ccc |\n| --- | --- | --- |\n| aaa | bbb | ccc |\n| aaa | bbb | ccc |\n| aaa | bbb | ccc |\n| aaa | bbb | ccc |\n| aaa | bbb | ccc |\n| aaa | bbb | ccc |\n\n:::\n\n::: {.column width=\"70%\"}\n\n画像を表示する場合はこのように記述します。\n\n![](/assets/common/title-background.jpg)\n\n:::\n\n::::"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#手元でプレビューする",
    "href": "blog/2025-05-06-quarto-slides.html#手元でプレビューする",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "7. 手元でプレビューする",
    "text": "7. 手元でプレビューする\nリポジトリルートで以下のコマンドを実行することで手元でプレビューできます。\nquarto preview"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#手元で-html-出力する",
    "href": "blog/2025-05-06-quarto-slides.html#手元で-html-出力する",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "8. 手元で HTML 出力する",
    "text": "8. 手元で HTML 出力する\n手元で HTML 出力する場合は以下のコマンドを実行します。上記設定のままの場合、 _output ディレクトリ配下に HTML ファイルが格納されます。\nquarto render"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#github-actions-で-html-出力する",
    "href": "blog/2025-05-06-quarto-slides.html#github-actions-で-html-出力する",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "9. GitHub Actions で HTML 出力する",
    "text": "9. GitHub Actions で HTML 出力する\n前段で作成した GitHub Actions を実行することで HTML 出力できます。\n記載のままの場合以下の3イベントがトリガーとなり実行されます。\n\nmain ブランチへの push\nmain ブランチへの pull request のマージ\n手動実行\n\n処理が成功すると htmlブランチに HTML ファイルが格納されます。"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#html-ファイルの取り扱い",
    "href": "blog/2025-05-06-quarto-slides.html#html-ファイルの取り扱い",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "10. HTML ファイルの取り扱い",
    "text": "10. HTML ファイルの取り扱い\nreveal.js 形式の HTML ファイルとなります。\n以下のいずれかの方法で取得できます。\n\n手元で quarto render して HTML ファイルを生成する\nローカルリポジトリを html ブランチに切り替えて pull する\nGitHub から直接ダウンロードする\n\nHTML ファイルを Web ブラウザで開くと以下のような表示になります。左下のハンバーガーメニューをクリックします。\n\n複数のモードが選択できます。PDF Export Mode を選択すると PDF 印刷できる状態になります。\n\nその他詳細は下記ページを参照してください。\nhttps://quarto.org/docs/presentations/revealjs/presenting.html"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#スライドのテンプレートを-scss-に反映させる",
    "href": "blog/2025-05-06-quarto-slides.html#スライドのテンプレートを-scss-に反映させる",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "11. スライドのテンプレートを SCSS に反映させる",
    "text": "11. スライドのテンプレートを SCSS に反映させる\nスライドの配色などを SCSS で指定できます。\n一度作成すると再利用できるのでやる気のある方は頑張ってみましょう。\n_quarto.yml のコメントアウトを外して custom.scss を編集していくことになります。\n大本になるファイルが以下の SCSS ファイルです。\nhttps://github.com/quarto-dev/quarto-cli/blob/main/src/resources/formats/revealjs/quarto.scss\n基本的にはここに登場する変数の値のうちオーバーライドしたいものを custom.scss に記載していけばよいです。\n不明点がある場合は先述しましたが DeepWiki が便利なので活用できますね。\nhttps://deepwiki.com/quarto-dev/quarto-cli\nDeepWiki でなくともよいですが AI にスライド内で利用したい色や書式を提示しつつ quarto.scss や以下の themes のファイルを読み込ませて作っていけば上手く作成できると思います。\nhttps://github.com/quarto-dev/quarto-cli/tree/main/src/resources/formats/revealjs/themes\nコードブロックの配色など (正直どうでもよくて) 頭を使いたくない部分も今時の AI なら良い感じに作成してくれるのであまり苦労せず SCSS の編集をやっていけるでしょう。\n一つ言及しておくとすると以下のように SCSS を記載することで h2 レベルのタイトルスライドの背景色等を変更できるはずです。\n$anybgcolor: #000000;\n$anyfgcolor: #ffffff;\n\n.title-slide {\n  background-color: $anybgcolor !important;\n  color: $anyfgcolor !important;\n\n  h2 {\n    color: $anyfgcolor !important;\n  }\n}\n基本的には SCSS の変数をオーバーライドしていく形で事足りるとは思います。"
  },
  {
    "objectID": "blog/2025-05-06-quarto-slides.html#おわりに",
    "href": "blog/2025-05-06-quarto-slides.html#おわりに",
    "title": "Markdown ライクな Quarto でスライドを作成して GitHub Actions で HTML 出力する",
    "section": "12. おわりに",
    "text": "12. おわりに\nここまでリポジトリを整備できればあとはどんどん AI にスライドを生成してもらうだけですね！楽にスライドを量産していきましょう！"
  },
  {
    "objectID": "blog/2024-12-07-inline-r-code-in-yaml.html",
    "href": "blog/2024-12-07-inline-r-code-in-yaml.html",
    "title": "Quarto の YAML ヘッダにコードを埋め込みたい",
    "section": "",
    "text": "R Markdown では実現できてるんですが Quarto ではまだダメなんですねぇ。\nInline R code in YAML · quarto-dev/quarto-cli · Discussion #606\n変数対応していてそちらは上手く動いてくれました！\nhttps://github.com/quarto-dev/quarto-cli/discussions/606#discussioncomment-8351008\nということは GitHub Actions 内で生成できる値を Quarto で作ったページに埋め込むことができますね。\nQuarto 向けの Publish Workflow も対応させたいので PR 作りたいです。"
  },
  {
    "objectID": "blog/2024-01-01-init.html",
    "href": "blog/2024-01-01-init.html",
    "title": "Initial Post",
    "section": "",
    "text": "初投稿になります。"
  },
  {
    "objectID": "blog/2024-01-01-init.html#uma-chan-とは",
    "href": "blog/2024-01-01-init.html#uma-chan-とは",
    "title": "Initial Post",
    "section": "1. uma-chan とは",
    "text": "1. uma-chan とは\n\n読み：うまちゃん\n仕事：データエンジニア・MLOpsエンジニア\n\n業務知識は個人公開が難しいものが多いのでブログでは関係ない話ばかりになりそうです"
  },
  {
    "objectID": "blog/2024-01-01-init.html#このブログの運用方針",
    "href": "blog/2024-01-01-init.html#このブログの運用方針",
    "title": "Initial Post",
    "section": "2. このブログの運用方針",
    "text": "2. このブログの運用方針\n\n他サービスに流用するかもしれないけど記事の元データはここで一元管理したい\nこれまで色々書いてきた記事もここに集約していきたい"
  },
  {
    "objectID": "blog/2024-11-20-manage-zenn-with-github.html",
    "href": "blog/2024-11-20-manage-zenn-with-github.html",
    "title": "Zennの記事をGitHubリポジトリで管理する",
    "section": "",
    "text": "Zenn に書いた以下の記事と全く同じ内容です。\nZennの記事をGitHubリポジトリで管理する\n気の向くままにこちらの個人ブログの方で先に公開します。 Markdown で管理しているので流用しやすくて便利！"
  },
  {
    "objectID": "blog/2024-11-20-manage-zenn-with-github.html#はじめに",
    "href": "blog/2024-11-20-manage-zenn-with-github.html#はじめに",
    "title": "Zennの記事をGitHubリポジトリで管理する",
    "section": "1. はじめに",
    "text": "1. はじめに\n初投稿なので新鮮な気持ちで Zenn 公式の記事を見ながら GitHub リポジトリ経由で Zenn の記事を投稿するまでの手順をまとめます。"
  },
  {
    "objectID": "blog/2024-11-20-manage-zenn-with-github.html#手順",
    "href": "blog/2024-11-20-manage-zenn-with-github.html#手順",
    "title": "Zennの記事をGitHubリポジトリで管理する",
    "section": "2. 手順",
    "text": "2. 手順\n\n2.1. 前準備\n\nリポジトリ作成から連携までを済ませる。\n\nGitHubリポジトリでZennのコンテンツを管理する\n\nZenn CLI をインストールする。\n\nZenn CLIをインストールする\n\nリポジトリ内に作成されたファイルをコミットしておく。\n\n\n\n2.2. 記事の作成\n以下の記事に従うと記事を書くことができます。\nZenn CLIで記事・本を管理する方法"
  },
  {
    "objectID": "blog/2024-11-20-manage-zenn-with-github.html#実際に作成していて気付いた点",
    "href": "blog/2024-11-20-manage-zenn-with-github.html#実際に作成していて気付いた点",
    "title": "Zennの記事をGitHubリポジトリで管理する",
    "section": "3. 実際に作成していて気付いた点",
    "text": "3. 実際に作成していて気付いた点\n\n3.1. スラッグを最初に指定する\n$ npx zenn new:article\nで記事に対応する Markdown ファイルを作成するとスラッグ (記事IDのことで公開時のファイル名と思ってよい) としてランダムな文字列が割り当てられます。 リポジトリで記事を管理する上で無意味なファイル名が並ぶのは辛いので以下のどちらかの対応を取りましょう。\n\nスラッグを指定して記事作成コマンドを実行する\n$ npx zenn new:article --slug 2024-11-20-manage-zenn-with-github\n公開前に ファイル名を変更する\n\n\n\n3.2. YAML ヘッダの topics: の各要素はハイフンで書く\nYAML ヘッダの記載例として以下のように記載されています。\nZenn CLIで記事・本を管理する方法\n---\ntitle: \"\" # 記事のタイトル\nemoji: \"😸\" # アイキャッチとして使われる絵文字（1文字だけ）\ntype: \"tech\" # tech: 技術記事 / idea: アイデア記事\ntopics: [] # タグ。[\"markdown\", \"rust\", \"aws\"]のように指定する\npublished: true # 公開設定（falseにすると下書き）\n---\nここから本文を書く\n個人的には\n---\ntopics: [\"markdown\", \"rust\", \"aws\"]\n---\nよりも\n---\ntopics:\n  - \"markdown\"\n  - \"rust\"\n  - \"aws\"\n---\nの方が行ソートで重複を見つけやすいので好きです。\n\n\n3.3. 会社テックブログ向けの予約投稿\n会社の Publication から予約投稿するには以下でよさそうです。\n---\npublished: true\npublished_at: 2024-11-20 18:00\npublication_name: \"Publication Name\"\n---\n(参考) 【Zenn】PublicationでもGitHub連携したい！自由選択型アプローチのすゝめ\nただこれだといきなり投稿されて、かつ公開前のレビューのために個人のリポジトリのPRを見せる面倒臭さが発生します。 個人リポジトリの利用を前提として事前に内容を秘匿する場合はローカルで作成したプレビューを PDF 化していこうかなと考えています。"
  },
  {
    "objectID": "blog/2024-11-20-manage-zenn-with-github.html#おわりに",
    "href": "blog/2024-11-20-manage-zenn-with-github.html#おわりに",
    "title": "Zennの記事をGitHubリポジトリで管理する",
    "section": "4. おわりに",
    "text": "4. おわりに\n取り急ぎこの記事が無事投稿できていれば OK です！ 自分は新規投稿する度に本記事を見直すことになりそうです。"
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html",
    "href": "blog/2024-01-27-setup-efm-langserver.html",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "",
    "text": "最近 Vim と Neovim に efm-langserver を導入したので手順を説明していきます。"
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html#efm-langserver-とは",
    "href": "blog/2024-01-27-setup-efm-langserver.html#efm-langserver-とは",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "1. efm-langserver とは",
    "text": "1. efm-langserver とは\nmattn さんの記事を見るのが最良ですね。\nBig Sky :: Lint ツールを Language Server に対応させるコマンド efm-langserver 作った。\n\nどんな言語であろうとも Lint ツールが grep と同様の形式で結果を出力してくれさえすれば Language Server にしてしまうコマンド\n\nLinter をインストールした後 Vim/Neovim で Info や Error を画面内に表示させたいときに efm-langserver が活用できると思えばよいです。"
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html#efm-langserver-のインストール",
    "href": "blog/2024-01-27-setup-efm-langserver.html#efm-langserver-のインストール",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "2. efm-langserver のインストール",
    "text": "2. efm-langserver のインストール\nUbuntu 22.04 (WSL2) でのインストール手順を記載しておきます。\nGo 言語を Go Wiki: Ubuntu - The Go Programming Language に従ってインストールします。\nsudo add-apt-repository -y ppa:longsleep/golang-backports\nsudo apt update\nsudo apt install -y golang-go\nefm-langserver を GitHub - mattn/efm-langserver: General purpose Language Server に従ってインストールします。\ngo install github.com/mattn/efm-langserver@latest\n~/.profile などに以下を追記して PATH を通しておきます。\nexport PATH=\"${HOME}\"/go/bin:\"${PATH}\""
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html#config.yaml-の作成",
    "href": "blog/2024-01-27-setup-efm-langserver.html#config.yaml-の作成",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "3. config.yaml の作成",
    "text": "3. config.yaml の作成\nefm-langserver 用設定ファイル $XDG_CONFIG_HOME/efm-langserver/config.yaml に必要な設定を記述していきます。\nREADME を参考に shellcheck を使うための設定のみ抽出したものが以下です。\nversion: 2\nroot-markers:\n  - .git/\nlint-debounce: 1s\n\ntools:\n  sh-shellcheck: &sh-shellcheck\n    lint-command: 'shellcheck -f gcc -x'\n    lint-source: 'shellcheck'\n    lint-formats:\n      - '%f:%l:%c: %trror: %m'\n      - '%f:%l:%c: %tarning: %m'\n      - '%f:%l:%c: %tote: %m'\n\nlanguages:\n  sh:\n    - &lt;&lt;: *sh-shellcheck"
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html#vim-の設定",
    "href": "blog/2024-01-27-setup-efm-langserver.html#vim-の設定",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "4. Vim の設定",
    "text": "4. Vim の設定\nプラグインマネージャー dein.vim や dpp.vim などで採用されている TOML ファイルでのプラグイン設定箇所を抽出しました。遅延起動設定はお好みで。\n[[plugins]]\nrepo = 'prabirshrestha/vim-lsp'\non_event = ['VimEnter']\n\n[[plugins]]\nrepo = 'mattn/vim-lsp-settings'\non_source = ['vim-lsp']\nhook_source = '''\nlet g:lsp_auto_enable = 1\nlet g:lsp_log_file = ''\nlet g:lsp_settings = {\n  \\   'efm-langserver': {\n  \\     'disabled': v:false,\n  \\     'allowlist': ['sh'],\n  \\   }\n  \\ }\n'''"
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html#neovim-の設定",
    "href": "blog/2024-01-27-setup-efm-langserver.html#neovim-の設定",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "5. Neovim の設定",
    "text": "5. Neovim の設定\nVim 同様に TOML ファイルの記述を抽出しました。こちらも遅延起動設定はお好みで。\n[[plugins]]\nrepo = 'neovim/nvim-lspconfig'\non_event = ['VimEnter']\nlua_source = '''\nlocal lspconfig = require('lspconfig')\nlspconfig.efm.setup{}\n'''"
  },
  {
    "objectID": "blog/2024-01-27-setup-efm-langserver.html#感想",
    "href": "blog/2024-01-27-setup-efm-langserver.html#感想",
    "title": "efm-langserver を Vim/Neovim で利用する",
    "section": "6. 感想",
    "text": "6. 感想\nLinter をインストールできていれば出力形式を見て自力で Language Server として組み込める……素晴らしいですね！\nLinter は手動でインストールして設定ファイルを管理しておくのが結局一番分かりやすいなと実感しているのですが、その状態で簡単に Vim/Neovim に反映できる efm-langserver はかなり有り難いです。"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "",
    "text": "こんにちは。MLOps エンジニア/データエンジニアの uma-chan です。\n私が業務でよく利用する dbt のローカル開発環境の話をしていきます。"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#はじめに",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#はじめに",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "",
    "text": "こんにちは。MLOps エンジニア/データエンジニアの uma-chan です。\n私が業務でよく利用する dbt のローカル開発環境の話をしていきます。"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#dbt-とは",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#dbt-とは",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "2. dbt とは",
    "text": "2. dbt とは\ndbt について知りたい方がおそらく最初に読む記事から抜粋。\nhttps://zenn.dev/dbt_tokyo/books/537de43829f3a0/viewer/what_dbt\n\ndbt（正式名称はdata build tool）はデータアナリストやアナリティクスエンジニアが（ほぼ）SQLだけで、データを変換しデータウエアハウス、データマートを構築していくことができるツールです。\n\nFROM 句内のサブクエリの部分を別の SQL ファイルに切り出していく形で想像すると大体合ってるはず。 SELECT 文の書かれた SQL ファイル (モデルといいます) が複数あって FROM 句内で SQL ファイル名 (モデル) を指し示すことでモデル同士の依存関係を表現しています。"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#dbt-開発環境に求めること",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#dbt-開発環境に求めること",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "3. dbt 開発環境に求めること",
    "text": "3. dbt 開発環境に求めること\n個人の主観で列挙します。\n\ndbt 向け SQL ファイルのフォーマッタである sqlfmt が動くこと\n\nフォーマッタを動かすというテキストエディタとしては基本的な部分なので、重要ではあるものの今回は割愛します\n\ndbt コマンドとの連携\n\n手数少なく dbt run などのコマンドを実行できること\n\n定義参照・自動補完のようなモダンな編集機能 (LSP)\n\n最近の開発ではこれらがないと非効率ですが dbt 向け LSP (各テキストエディタが共通で利用できるコア機能) が提供されていないため各テキストエディタが自前で対応する必要があります"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#年現在の-dbt-開発環境",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#年現在の-dbt-開発環境",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "4. 2024年現在の dbt 開発環境",
    "text": "4. 2024年現在の dbt 開発環境\n\n4.1. VS Code\nベンチマークとして VS Code について言及します。 やはり圧倒的に使いやすいです。 以下の拡張機能を使用するのが現状の最適解です。\nhttps://marketplace.visualstudio.com/items?itemName=innoverio.vscode-dbt-power-user\n日本語解説記事は以下をはじめとして複数投稿されています。\nhttps://www.yasuhisay.info/entry/2023/07/09/120000\n\n\n4.2. Neovim\nVS Code 向け拡張機能に比べると提供されている機能の数は少ないものの十分に豊富な機能をもつプラグインが提供されています。\nhttps://github.com/PedramNavid/dbtpal\n\n\n4.3. Vim\n以下のプラグインでシンタックスハイライトといくつかの dbt コマンド連携機能が提供されています。\nhttps://github.com/chrismaher/vim-dbt\n正直なところ機能が少ないので Vim ではなく Neovim もしくは VS Code を使うことをおすすめします。"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#vim-の救済",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#vim-の救済",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "5. Vim の救済",
    "text": "5. Vim の救済\n……ですが Vim でも dbt 開発をしたいですよね！ なんといっても私の好きなエディタですし。 というわけで最低限欲しかったモデル定義へのジャンプ機能のプラグインを作りました。\nhttps://github.com/i9wa4/vim-dbt-jump2def\nインストール方法や使い方は README を参照してください。 ジャンプ機能はコマンドで提供したので各自好みのキーマッピングを設定することをオススメします。\nちなみに Vim/Neovim 両対応のフレームワークである Denops で書いたので Neovim でも使えます。 そしてこの際なので他の Denops プラグインの沼にもハマっていきましょう。。"
  },
  {
    "objectID": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#おわりに",
    "href": "blog/2024-12-02-vim-neovim-environment-for-dbt.html#おわりに",
    "title": "Vim/Neovim の dbt 開発環境の現状と Vim を救う話",
    "section": "6. おわりに",
    "text": "6. おわりに\n今回プラグインを作るために Denops や Deno の情報収集をしつつ、慣れない TypeScript を書いていたのですが結構楽しかったです。"
  },
  {
    "objectID": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html",
    "href": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html",
    "title": "Vim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法",
    "section": "",
    "text": "以下の記事を読んで Conform.nvim は使っていなかったものの悩みごとが解決する！！！！と思ったので自分の環境でも試してみました。\nConform.nvimの保存時フォーマットをスキップする方法 | Atusy’s blog"
  },
  {
    "objectID": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#はじめに",
    "href": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#はじめに",
    "title": "Vim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法",
    "section": "",
    "text": "以下の記事を読んで Conform.nvim は使っていなかったものの悩みごとが解決する！！！！と思ったので自分の環境でも試してみました。\nConform.nvimの保存時フォーマットをスキップする方法 | Atusy’s blog"
  },
  {
    "objectID": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#vim-での設定",
    "href": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#vim-での設定",
    "title": "Vim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法",
    "section": "2. Vim での設定",
    "text": "2. Vim での設定\ndpp.vim で管理している TOML ファイルから vim-lsp-settings 向け設定を抜粋しました。\nformat on save 設定に v:cmdbang を使うことで、:w! のときはフォーマットをスキップするようにしています。\n[[plugins]]\nrepo = 'mattn/vim-lsp-settings'\non_source = ['vim-lsp']\nhook_source = '''\nlet g:lsp_diagnostics_float_cursor = v:true\nlet g:lsp_diagnostics_virtual_text_align = \"after\"\nlet g:lsp_diagnostics_virtual_text_wrap = \"truncate\"\nlet g:lsp_log_file = ''\nlet g:lsp_settings_enable_suggestions = v:false\nlet g:lsp_settings = {\n\\   'deno': {\n\\     'disabled': v:false,\n\\   },\n\\   'efm-langserver': {\n\\     'disabled': v:false,\n\\   },\n\\   'pylsp': {\n\\     'disabled': v:true,\n\\   },\n\\   'pylsp-all': {\n\\     'disabled': v:true,\n\\   },\n\\ }\n\naugroup MyLspSetting\n  autocmd!\n  autocmd BufWritePost * if !v:cmdbang | execute 'LspDocumentFormatSync' | endif\naugroup END\n'''"
  },
  {
    "objectID": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#neovim-での設定",
    "href": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#neovim-での設定",
    "title": "Vim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法",
    "section": "3. Neovim での設定",
    "text": "3. Neovim での設定\n同様に TOML で管理している nvim-lspconfig 設定を抜粋しました。\nvim.v.cmdbang を使っています。\n[[plugins]]\nrepo = 'neovim/nvim-lspconfig'\non_event = ['VimEnter']\nlua_source = '''\n-- https://github.com/uga-rosa/ddc-source-lsp-setup\nrequire('ddc_source_lsp_setup').setup()\n\n-- https://github.com/neovim/nvim-lspconfig?tab=readme-ov-file#configuration\nlocal lspconfig = require('lspconfig')\n-- lspconfig.pylsp.setup{}\nlspconfig.denols.setup{}\nlspconfig.efm.setup{}\n\n-- :help lsp-defaults-disable\nvim.api.nvim_create_autocmd('LspAttach', {\n  callback = function(ev)\n    -- unset\n    vim.bo[ev.buf].formatexpr = nil\n    vim.bo[ev.buf].omnifunc = nil\n\n    -- unmap\n    -- vim.keymap.del('n', 'K', { buffer = ev.buf })\n\n    -- map\n    local opts = { buffer = bufnr, noremap = true, silent = true }\n    vim.keymap.set('n', '&lt;space&gt;lf', vim.diagnostic.open_float, opts)\n  end,\n})\n\nvim.api.nvim_create_autocmd('BufWritePost', {\n  callback = function()\n    if vim.v.cmdbang == 0 then\n      vim.lsp.buf.format()\n    end\n  end,\n})\n'''"
  },
  {
    "objectID": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#まとめ",
    "href": "blog/2025-06-04-use-cmdbang-to-disable-lsp-formatting-on-save.html#まとめ",
    "title": "Vim/Neovim の保存時の LSP フォーマットを :w! のときに無効化する方法",
    "section": "4. まとめ",
    "text": "4. まとめ\nこれまでは保存したいけどフォーマットしたくない場面を回避するためにフォーマット用のキーバインドを用意して format on save を無効化していました。\nたまにフォーマットし忘れて辛かったのでこの対応でとってもハッピーになりました！"
  }
]