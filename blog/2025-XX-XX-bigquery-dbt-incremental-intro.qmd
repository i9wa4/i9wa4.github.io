---
title: "BigQuery で dbt incremental モデルのパフォーマンス改善をしてみた"
author: uma-chan
date: last-modified
date-modified: last-modified
image: "/assets/common/icon_hhkb3_large.jpg"
description: |
  BigQuery 上で dbt incremental モデルの実行時間を40分短縮した手順を共有する
categories:
  - "tech"
  - "tech-data"
  - "tech-dbt"
---

## 1. 概要

ログ同士を突き合わせる dbt モデルの実行時間が1時間を超えていたため、BigQuery の特性を活かして25分56秒まで短縮した流れを紹介します。
対象はイミューターなログを扱うモデルで、過去データの更新を考慮しない前提を置ける構造でした。

## 2. 当初の課題

- incremental_strategy が merge で、ターゲットテーブル全体を走査
- unique_key が15列と多く、結合条件が複雑
- 参照元テーブルが期間条件なしで FULL OUTER JOIN され、中間結果が肥大化

## 3. BigQuery で実施した最適化

### 3.1. incremental_strategyの切り替え

- merge から insert_overwrite へ変更し、対象パーティションのみを差し替え
- メタデータ更新コストが下がり、実行計画もシンプル化

### 3.2. パーティションプルーニングの徹底

- vars で渡した日付範囲を JOIN 前のフィルタで適用し、読み取り対象を日次で限定
- パーティション指定を日単位で明示化し、BigQuery のスキャン範囲を事前に制限

### 3.3. 重複除去ロジックの簡素化

- unique_key での比較を ROW_NUMBER() による重複除去へ置き換え
- BigQuery のウィンドウ関数最適化でコンパイル時間とスキャン量が縮小

## 4. 効果と検証

- 実行時間は1時間10分前後から25分56秒へ短縮
- 同期間の surrogate key 単位で件数と代表値を比較し整合性を確認
- 既存の dbt test (not_null と unique) を再実行して差異なし

## 5. 今後の検討

- days_to_process を vars で調整しつつ既定値3日 上阁30日の運用を整備
- require_partition_filter の適用可否を再検討し、過去データ再処理時の安全策を整理
- INFORMATION_SCHEMA.PARTITIONS を用いた差分監視を自動化し、他テーブルにも展開
