---
title: "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ãƒ³ãƒ†ã‚£ã‚¹ãƒˆç”¨æœ€å¼· Dev Container for Databricks with Claude Code"
author: uma-chan
date: 2025-07-28 00:59:19 +0900
date-modified: last-modified
image: "/assets/common/icon_hhkb3_large.jpg"
description: |
  Claude Code å¯¾å¿œã® Dev Container ã§ Databricks ã§ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã® AI ã®æ©æµã‚’å—ã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™
categories:
  - "blog"
  - "tech"
  - "tech-ai"
  - "tech-python"
  - "tech-vscode"
---

## 1. ã¯ã˜ã‚ã«

DWH ã‚µãƒ¼ãƒ“ã‚¹ãŒæä¾›ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§æ©Ÿæ¢°å­¦ç¿’ã‚„åˆ†æã‚’è¡Œã£ã¦ã„ã‚‹æ–¹ã¯å¤šã„ã¨æ€ã„ã¾ã™ã€‚

ãã†ã„ã£ãŸæ–¹ã€…å…±é€šã®æ‚©ã¿ã¨ã—ã¦ VS Code ãªã©ã®ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒãŒåˆ©ç”¨ã§ããªã„ã€ãã—ã¦çµæœçš„ã«é–‹ç™ºæ™‚ã« AI ã®æ©æµãŒå—ã‘ã‚‰ã‚Œãªã„ã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã¨æ€ã„ã¾ã™ã€‚

ä»Šå›ç§ãŒä»Šãƒ¡ã‚¤ãƒ³ã§ä½¿ã£ã¦ã„ã‚‹ Databricks ã«ã¤ã„ã¦ã“ã®æ‚©ã¿ã‚’è§£æ±ºã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## 2. å¯¾è±¡èª­è€…

- Databricks ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰åˆ©ç”¨ã—ãŸã„æ–¹
- Databricks ä¸Šã§ã®é–‹ç™ºã« Claude Code ã‚’åˆ©ç”¨ã—ãŸã„æ–¹
- Databricks ä»¥å¤–ã® DWH ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã£ã¦ã„ã‚‹ãŒå‚è€ƒã«ã—ãŸã„æ–¹ (å®Ÿéš›èª­ã‚€ã¨è‡ªä½œã§ãã‚‹ã¨æ€ã„ã¾ã™)

## 3. å‰æçŸ¥è­˜

### 3.1. Dev Container ã¨ã¯

Dev Container ã¯ VS Code ã§ã‚³ãƒ³ãƒ†ãƒŠã‚’é–‹ç™ºç’°å¢ƒã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ä¾¿åˆ©æ©Ÿèƒ½ã§ã™ã€‚

ä»Šå› Dev Container è¨­å®šã§ç´¹ä»‹ã™ã‚‹ã®ã§æ•´å‚™ã™ã‚‹æ–¹ãŒã„ã‚Œã°ãƒãƒ¼ãƒ å…¨å“¡ã«åŒã˜é–‹ç™ºç’°å¢ƒã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

VS Code ã§ã¯ãªã„æ–¹ã‚‚ Dev Container CLI ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã¡ãªã¿ã«ç§ã¯ VS Code ã‚’ãƒ¡ã‚¤ãƒ³ã§ä½¿ç”¨ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã®ã§ VS Code å›ºæœ‰ã®æ©Ÿèƒ½ã¯ä»Šå›ã‚ã¾ã‚Šå¤šãç™»å ´ã—ã¾ã›ã‚“ã€‚

### 3.2. Claude Code in Dev Container

Claude Code ã‚’ Dev Container ã§åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦2é€šã‚Šç´¹ä»‹ã—ã¾ã™ã€‚

#### 3.2.1. devcontainer.json ã® features ã‚’åˆ©ç”¨ã™ã‚‹

ã“ã¡ã‚‰ãŒç°¡å˜ãªæ–¹æ³•ã§ã™ã€‚

ä»¥ä¸‹ã« Anthropic ãŒæä¾›ã—ã¦ã„ã‚‹ Dev Container feature ã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚

<https://github.com/anthropics/devcontainer-features/blob/main/src/claude-code/README.md>

æŠœç²‹ã™ã‚‹ã¨ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

```{.json filename=".devcontainer/devcontainer.json"}
"features": {
    "ghcr.io/devcontainers/features/node:1": {},
    "ghcr.io/anthropics/devcontainer-features/claude-code:1": {}
}
```

#### 3.2.2. Dockerfile ã‚’åˆ©ç”¨ã™ã‚‹

æœ¬å®¶ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£…ã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã§ã™ã€‚

ä»¥ä¸‹ãŒ Claude Code å‘ã‘ Dev Container ã«ã¤ã„ã¦è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚

<https://docs.anthropic.com/en/docs/claude-code/devcontainer>

ã“ã®ä¸­ã§ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£…ã¨ã—ã¦ Claude Code è‡ªèº«ã® Dev Container è¨­å®šãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

<https://github.com/anthropics/claude-code/tree/main/.devcontainer>

```{.sh}
.devcontainer
â”œâ”€â”€ devcontainer.json
â”œâ”€â”€ Dockerfile
â””â”€â”€ init-firewall.sh
```

ã“ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£…ã‚’å‚è€ƒã«ã—ã¤ã¤ç§ãŒä½¿ã„ã‚„ã™ã„ã‚ˆã†ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸã‚‚ã®ã‚’ä»¥ä¸‹ã§ç´¹ä»‹ã—ã¦ã„ãã¾ã™ã€‚

### 3.3. uv ã¨ã¯

ä»Šå›åˆ©ç”¨ã—ã¦ã„ã‚‹ Python ç’°å¢ƒç®¡ç†ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

<https://github.com/astral-sh/uv>

æœ€ä½é™ç†è§£ã—ã¦ãŠãã¹ãè¦ç‚¹ã¯ä»¥ä¸‹ã§ã™ã€‚

- uv è‡ªä½“ã¯ Python ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®å¤–ã«ã‚ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹
- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã„ Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ `pyproject.toml` ã§ç®¡ç†ã™ã‚‹
- `pyproject.toml` ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ä¾å­˜é–¢ä¿‚è§£æ±ºçµæœã‚’ `uv.lock` ã«ä¿å­˜ã—ç’°å¢ƒã®å†ç¾æ€§ã‚’æ‹…ä¿ã—ã¦ã„ã‚‹

## 4. Dev Container è¨­å®š

### 4.1. VS Code å´ã®æº–å‚™

Dev Container æ‹¡å¼µã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

<https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers>

### 4.2. Dockerfile

Anthropic ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£…ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ãª Dockerfile ã‚’ä½œæˆã—ã¾ã—ãŸã€‚

è¦‹ã¦åˆ†ã‹ã‚‹é€šã‚Š hadolint ã§çµæ§‹æŒ‡æ‘˜ãŒå‡ºã‚‹æ›¸ãå‘³ã§ã™ãŒç‰¹ã«æ„æ€ã‚‚ãªã„ã®ã§ãã®ã¾ã¾ã«ã—ã¦ã„ã¾ã™ã€‚

::: {.callout-note appearance="simple" collapse="true"}

#### 4.2.1. `.devcontainer/Dockerfile`

```{.Dockerfile filename=".devcontainer/Dockerfile"}
FROM node:20

ARG TZ
ENV TZ="$TZ"

# Install basic development tools and iptables/ipset
RUN apt update && apt install -y less \
  git \
  procps \
  sudo \
  fzf \
  zsh \
  man-db \
  unzip \
  gnupg2 \
  gh \
  iptables \
  ipset \
  iproute2 \
  dnsutils \
  aggregate \
  jq

# Ensure default node user has access to /usr/local/share
RUN mkdir -p /usr/local/share/npm-global && \
  chown -R node:node /usr/local/share

ARG USERNAME=node

# Persist bash history.
RUN SNIPPET="export PROMPT_COMMAND='history -a' && export HISTFILE=/commandhistory/.bash_history" \
  && mkdir /commandhistory \
  && touch /commandhistory/.bash_history \
  && chown -R $USERNAME /commandhistory

# Set `DEVCONTAINER` environment variable to help with orientation
ENV DEVCONTAINER=true

# Create workspace and config directories and set permissions
RUN mkdir -p /workspace /home/node/.claude && \
  chown -R node:node /workspace /home/node/.claude

WORKDIR /workspace

RUN ARCH=$(dpkg --print-architecture) && \
  wget "https://github.com/dandavison/delta/releases/download/0.18.2/git-delta_0.18.2_${ARCH}.deb" && \
  sudo dpkg -i "git-delta_0.18.2_${ARCH}.deb" && \
  rm "git-delta_0.18.2_${ARCH}.deb"

# Set up non-root user
USER node

# Install global packages
ENV NPM_CONFIG_PREFIX=/usr/local/share/npm-global
ENV PATH=$PATH:/usr/local/share/npm-global/bin

# Set the default shell to zsh rather than sh
ENV SHELL=/bin/zsh

# Default powerline10k theme
RUN sh -c "$(wget -O- https://github.com/deluan/zsh-in-docker/releases/download/v1.2.0/zsh-in-docker.sh)" -- \
  -p git \
  -p fzf \
  -a "source /usr/share/doc/fzf/examples/key-bindings.zsh" \
  -a "source /usr/share/doc/fzf/examples/completion.zsh" \
  -a "export PROMPT_COMMAND='history -a' && export HISTFILE=/commandhistory/.bash_history" \
  -x

# Install Claude
RUN npm install -g @anthropic-ai/claude-code

# Python environment setup (if needed)
# Copy uv binary from official image
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

USER node
```

Anthropic ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£… ([e394b39](https://github.com/anthropics/claude-code/blob/55219b8b4e612b5fc6a85f7dc4eb4382ec4134eb/.devcontainer/Dockerfile)) ã¨æ¯”è¼ƒã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªå¤‰æ›´ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚

- firewall ã‚¹ã‚¯ãƒªãƒ—ãƒˆå¯¾å¿œéƒ¨åˆ†ã‚’å‰Šé™¤
- uv ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«éƒ¨åˆ†ã‚’è¿½åŠ 

```{.diff}
$ diff -u ../../anthropics/claude-code/.devcontainer/Dockerfile .devcontainer/Dockerfile
--- ../../anthropics/claude-code/.devcontainer/Dockerfile       2025-07-26 16:16:50
+++ .devcontainer/Dockerfile    2025-07-26 23:24:59
@@ -69,10 +69,8 @@
 # Install Claude
 RUN npm install -g @anthropic-ai/claude-code

-# Copy and set up firewall script
-COPY init-firewall.sh /usr/local/bin/
-USER root
-RUN chmod +x /usr/local/bin/init-firewall.sh && \
-  echo "node ALL=(root) NOPASSWD: /usr/local/bin/init-firewall.sh" > /etc/sudoers.d/node-firewall && \
-  chmod 0440 /etc/sudoers.d/node-firewall
+# Python environment setup (if needed)
+# Copy uv binary from official image
+COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv
+
 USER node
```

:::

### 4.3. devcontainer.json

ä»¥ä¸‹ã®ã‚ˆã†ãª `devcontainer.json` ã‚’ä½œæˆã—ã¾ã—ãŸã€‚

ã“ã¡ã‚‰ã¯ Anthropic ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£…ã«æ¯”ã¹ã‚‹ã¨å‰²ã¨å¤‰æ›´ç‚¹ãŒå¤šã„ã§ã™ã€‚

::: {.callout-note appearance="simple" collapse="true"}

#### 4.3.1. `.devcontainer/devcontainer.json`

```{.json filename=".devcontainer/devcontainer.json"}
{
    "name": "Claude Code Sandbox",
    "build": {
        "dockerfile": "Dockerfile",
        "args": {
            "TZ": "${localEnv:TZ:Asia/Tokyo}"
        }
    },
    "runArgs": [
        "--cap-add=NET_ADMIN",
        "--cap-add=NET_RAW",
        "--network=host"
    ],
    "customizations": {
        "vscode": {
            "extensions": [
                "editorconfig.editorconfig",
                "elagil.pre-commit-helper",
                "ms-python.python",
                "ms-toolsai.jupyter"
            ],
            "settings": {
                "terminal.integrated.defaultProfile.linux": "zsh",
                "terminal.integrated.profiles.linux": {
                    "bash": {
                        "path": "bash",
                        "icon": "terminal-bash"
                    },
                    "zsh": {
                        "path": "zsh"
                    }
                }
            }
        }
    },
    "remoteUser": "node",
    "mounts": [
        "source=${localEnv:CLAUDE_CONFIG_DIR},target=/home/node/.claude,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.config/gh,target=/home/node/.config/gh,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.config/git,target=/home/node/.config/git,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.databrickscfg,target=/home/node/.databrickscfg,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.dbt,target=/home/node/.dbt,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.gitconfig,target=/home/node/.gitconfig,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,consistency=cached",
        "source=claude-code-bashhistory-${devcontainerId},target=/commandhistory,type=volume"
    ],
    "remoteEnv": {
        "CLAUDE_CONFIG_DIR": "/home/node/.claude",
        "NODE_OPTIONS": "--max-old-space-size=4096",
        "POWERLEVEL9K_DISABLE_GITSTATUS": "true",
        "UV_LINK_MODE": "copy"
    },
    "workspaceMount": "source=${localWorkspaceFolder},target=/workspace,type=bind,consistency=delegated",
    "workspaceFolder": "/workspace",
    "postStartCommand": "uv sync --frozen --group dev && uv run pre-commit install"
}
```

Anthropic ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹å®Ÿè£… ([33e37bd](https://github.com/anthropics/claude-code/blob/55219b8b4e612b5fc6a85f7dc4eb4382ec4134eb/.devcontainer/devcontainer.json)) ã¨æ¯”è¼ƒã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªå¤‰æ›´ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚

- `runArgs` ã« `--network=host` ã‚’è¿½åŠ 
    - Databricks å‘ã‘
- VS Code å‘ã‘æ‹¡å¼µæ©Ÿèƒ½ã‚’è¿½åŠ 
    - `editorconfig.editorconfig`
        - ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ‡ã‚£ã‚¿é–“ã§ã®è¨­å®šã‚’çµ±ä¸€ã™ã‚‹
    - `elagil.pre-commit-helper`
        - pre-commit ã‚’ä½¿ã„ã‚„ã™ãã™ã‚‹
    - `ms-python.python`
        - æµçŸ³ã«å¿…è¦
    - `ms-toolsai.jupyter`
        - ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ VS Code ã§é–‹ããŸã‚ã«å¿…è¦
- VS Code å‘ã‘ Formatter è¨­å®šã‚’å‰Šé™¤
- `mounts` ã«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‚’è¿½åŠ 
    - ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦åˆ©ç”¨ã—ã¾ã™
        - Claude Code
        - GitHub CLI
        - Git
        - Databricks (èªè¨¼æƒ…å ±)
        - dbt (èªè¨¼æƒ…å ±)
        - ssh
- `mounts` ã® Claude Code è¨­å®šåˆ†é›¢éƒ¨åˆ†ã‚’å‰Šé™¤
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦åˆ©ç”¨ã—ãŸã‹ã£ãŸã®ã§å‰Šé™¤ã—ã¾ã—ãŸ
- `remoteEnv` ã«ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã‚’è¿½åŠ 
    - `CLAUDE_CONFIG_DIR`
        - Claude Code ã®è¨­å®šå‚ç…§ç®‡æ‰€ã®å®‰å®šåŒ–ã‚’å›³ã‚‹
    - `UV_LINK_MODE`
        - ã‚³ãƒ³ãƒ†ãƒŠãªã®ã§ uv ã®ãƒªãƒ³ã‚¯ãƒ¢ãƒ¼ãƒ‰ã‚’ `copy` ã«è¨­å®š
- `postStartCommand` ã«ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’è¿½åŠ 
    - `uv sync --frozen --group dev`
        - Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
    - `uv run pre-commit install`
        - pre-commit ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹

:::

### 4.4. start-jupyter.sh

VS Code ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä¸è¦ã§ã™ãŒä¸€å¿œ JupyterLab ã‚’èµ·å‹•ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚ç”¨æ„ã—ã¾ã—ãŸã€‚

ãƒãƒ¼ãƒˆã¯è‡ªå‹•å‰²ã‚Šå½“ã¦ã«ã—ã¦ã„ã¾ã™ã€‚

::: {.callout-note appearance="simple" collapse="true"}

#### 4.4.1. `devcontainer/start-jupyter.sh`

```{.sh filename=".devcontainer/start-jupyter.sh"}
#!/usr/bin/env bash
set -o errexit

# JupyterLabèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# Databricks Connectç’°å¢ƒã§ã®å¿«é©ãªé–‹ç™ºç”¨

echo "ğŸ”¥ Databricks JupyterLab ç’°å¢ƒã‚’èµ·å‹•ä¸­..."

# ãƒãƒ¼ãƒˆè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è‡ªå‹•å‰²ã‚Šå½“ã¦ï¼‰
# JUPYTER_PORT=8888 # NOTE: ã“ã®è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã™ã‚‹ã¨è‡ªå‹•ãƒãƒ¼ãƒˆæ¤œç´¢ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã™
JUPYTER_PORT=${JUPYTER_PORT:-0}

if [ "$JUPYTER_PORT" = "0" ]; then
  echo "ğŸ“¡ åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆã‚’è‡ªå‹•æ¤œç´¢ä¸­..."
else
  echo "ğŸ“¡ æŒ‡å®šãƒãƒ¼ãƒˆ ${JUPYTER_PORT} ã§èµ·å‹•ã—ã¾ã™"
fi

# Pythonç’°å¢ƒã®ç¢ºèª
if [ -f "uv.lock" ]; then
  echo "ğŸ“¦ uvç’°å¢ƒã‚’ä½¿ç”¨ã—ã¦JupyterLabã‚’èµ·å‹•ã—ã¾ã™"
  uv sync --frozen
  nohup uv run jupyter lab --ip=0.0.0.0 --port=${JUPYTER_PORT} --no-browser --allow-root \
    --NotebookApp.token='' --NotebookApp.password='' \
    --ServerApp.allow_origin='*' --ServerApp.disable_check_xsrf=True >/dev/null 2>&1 &
elif [ -d ".venv" ]; then
  echo "ğŸ“¦ venvç’°å¢ƒã‚’ä½¿ç”¨ã—ã¦JupyterLabã‚’èµ·å‹•ã—ã¾ã™"
  source .venv/bin/activate
  nohup jupyter lab --ip=0.0.0.0 --port=${JUPYTER_PORT} --no-browser --allow-root \
    --NotebookApp.token='' --NotebookApp.password='' \
    --ServerApp.allow_origin='*' --ServerApp.disable_check_xsrf=True >/dev/null 2>&1 &
else
  echo "âŒ Pythonä»®æƒ³ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
  echo "uvã¾ãŸã¯venvã§ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„"
  exit 1
fi

# å®Ÿéš›ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸãƒãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
for i in {1..10}; do
  sleep 1
  ACTUAL_PORT=$(ss -tlnp 2>/dev/null | grep jupyter-lab | awk '{print $4}' | cut -d: -f2 | head -1)
  if [ -n "$ACTUAL_PORT" ]; then
    break
  fi
done

if [ "$JUPYTER_PORT" = "0" ] && [ -n "$ACTUAL_PORT" ]; then
  echo "ğŸŒ JupyterLabã¯ http://localhost:${ACTUAL_PORT}/lab ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™"
else
  echo "ğŸŒ JupyterLabã¯ http://localhost:${JUPYTER_PORT}/lab ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™"
fi
```

:::

## 5. Python ç’°å¢ƒè¨­å®š

Python ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å‘ã‘ç’°å¢ƒè¨­å®šã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

æœ€é‡è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ `databricks-connect` ã§ã™ã€‚

ä»–ã« pre-commit ã§ Black ã‚„ isortã€flake8 ã‚’åˆ©ç”¨ã—ã¦ã„ãã®ã§è¨­å®šã‚‚è¨˜è¿°ã—ã¦ã„ã¾ã™ã€‚

::: {.callout-note appearance="simple" collapse="true"}

### 5.1. `pyproject.toml`

```{.toml filename="pyproject.toml"}
[project]
name = "databricks-devcontainer"
version = "0.1.0"
description = "Add your description here"
requires-python = "~=3.13.0"
dependencies = [
    "databricks-connect~=16.4.0",
    "ipykernel",
    "jupyterlab",
    "matplotlib",
    "numpy",
    "pandas",
    "python-dotenv",
    "requests",
    "seaborn",
]

[dependency-groups]
dev = [
    "pre-commit~=4.2.0",
    "black==25.1.0",
    "isort==6.0.0",
    "flake8==7.3.0",
    "flake8-pyproject",
]

[tool.black]
line-length = 88
target-version = ['py313']

[tool.isort]
profile = "black"
line_length = 88

[tool.flake8]
max-line-length = 120
extend-exclude = [".venv"]
extend-ignore = [
    "E203",  # Whitespace before ':'
    "E701",  # Multiple statements on one line (colon)
    "F821"   # undefined name (Databricks-specific module)
]
```

:::

### 5.2. pre-commit è¨­å®š

Formatter è¨­å®šã‚’ VS Code ã‹ã‚‰åˆ‡ã‚Šé›¢ã™ã“ã¨ã§ VS Code ä»¥å¤–ã®ã‚¨ãƒ‡ã‚£ã‚¿ã‚„ GitHub Actions ã§ã‚‚åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦æœ€é«˜ã§ã™ã­ï¼

::: {.callout-note appearance="simple" collapse="true"}

#### 5.2.1. `.pre-commit-config.yaml`

```{.yaml filename=".pre-commit-config.yaml"}
default_stages: [pre-commit]
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: check-added-large-files
      - id: check-json
      - id: check-yaml
      - id: detect-private-key
      - id: end-of-file-fixer
      - id: mixed-line-ending
        args: [--fix=no]
      - id: trailing-whitespace
        args: [--markdown-linebreak-ext=md]

  - repo: local
    hooks:
      - id: black
        name: black
        entry: uv run black
        language: system
        types: [python]

  - repo: local
    hooks:
      - id: isort
        name: isort (python)
        entry: uv run isort
        language: system
        types: [python]

  - repo: local
    hooks:
      - id: flake8
        name: flake8
        entry: uv run flake8
        language: system
        types: [python]

  - repo: local
    hooks:
      - id: sqlfmt
        name: sqlfmt
        entry: uv run sqlfmt
        language: system
        types: [sql]

  - repo: https://github.com/gitleaks/gitleaks
    rev: v8.28.0
    hooks:
      - id: gitleaks
```

:::

### 5.3. pre-commit in GitHub Actions

ãŠã¾ã‘ã§ã™ãŒ GitHub Actions ã§ pre-commit ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®è¨­å®šã‚‚ç”¨æ„ã—ã¾ã—ãŸã€‚

::: {.callout-note appearance="simple" collapse="true"}

#### 5.3.1. `.github/workflows/pre-commit.yaml`

```{.yaml filename=".github/workflows/pre-commit.yaml"}
name: pre-commit
run-name: ${{ github.event_name }} on ${{ github.ref_name }} by @${{ github.actor }}

on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
    types:
      - opened
      - synchronize
      - reopened

permissions: {}

defaults:
  run:
    shell: bash

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  pre-commit:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã¯ã‚½ãƒ¼ã‚¹ãƒ–ãƒ©ãƒ³ãƒ(github.head_ref)ã‚’ã€
          # æ‰‹å‹•å®Ÿè¡Œæ™‚ã¯å®Ÿè¡Œå¯¾è±¡ãƒ–ãƒ©ãƒ³ãƒ(github.ref_name)ã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ
          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref_name }}
          persist-credentials: false

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "0.8.3"

      - name: Set up Python
        run: |
          uv sync --only-group dev

      - name: Install pre-commit
        run: |
          uv run pre-commit install

      - name: Run pre-commit
        run: |
          uv run pre-commit run --all-files
```

:::

### 5.4. Python ä»®æƒ³ç’°å¢ƒæ›´æ–°æ‰‹é †

1. å¿…è¦ã«å¿œã˜ã¦ `.python-version` ã‚„ `pyproject.toml` ã‚’æ›´æ–°ã—ã¾ã™ã€‚
1. `uv.lock` ã‚’æ›´æ–°ã—ã¾ã™ã€‚

    ```sh
    $ uv lock --upgrade
    ```

1. .venv ã‚’æ›´æ–°ã—ã¾ã™ã€‚

    ```sh
    $ uv sync --frozen --group dev
    ```


## 6. Databricks Connect è¨­å®š

Dev Container (ãƒ­ãƒ¼ã‚«ãƒ«) ã¨ Databricks ã®ä¸¡æ–¹ã§åŒã˜ã‚ˆã†ã«å‹•ä½œã™ã‚‹ Spark ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚

ä»¥ä¸‹ã®ã‚ˆã†ã«åˆ©ç”¨ã§ãã¾ã™ã€‚

```{.python}
from databricks_spark import create_spark_session

# æ–°ã—ã„Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
spark = create_spark_session()
df = spark.sql("SHOW CATALOGS")
df.show()
```

::: {.callout-note appearance="simple" collapse="true"}

### 6.1. `databricks_connect.py`

```{.python filename="databricks_connect.py"}
"""
Databricks Spark ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
Databricksã¨ãƒ­ãƒ¼ã‚«ãƒ«ä¸¡å¯¾å¿œã®1ãƒ•ã‚¡ã‚¤ãƒ«å®Œçµå‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

ä½¿ç”¨æ–¹æ³•:
    from databricks_spark import create_spark_session

    # æ–°ã—ã„Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    spark = create_spark_session()
    df = spark.sql("SHOW CATALOGS")
    df.show()
"""

import logging
import os
import sys

# ãƒ­ã‚¬ãƒ¼è¨­å®š
_logger = logging.getLogger(__name__)
if not _logger.handlers:
    _logger.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s %(name)s [%(levelname)s] %(message)s")
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(formatter)
    _logger.addHandler(handler)


def is_databricks_environment() -> bool:
    """Databricksç’°å¢ƒã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®š"""
    return os.environ.get("DATABRICKS_RUNTIME_VERSION") is not None


def get_environment_type() -> str:
    """å®Ÿè¡Œç’°å¢ƒã®ã‚¿ã‚¤ãƒ—ã‚’å–å¾—"""
    if is_databricks_environment():
        return "databricks"
    else:
        return "local"


def create_databricks_native_session():
    """Databricksä¸Šã§ã®ãƒã‚¤ãƒ†ã‚£ãƒ–Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
    try:
        from pyspark.sql import SparkSession

        spark = SparkSession.getActiveSession()
        if spark is None:
            spark = SparkSession.builder.appName("DatabricksNotebook").getOrCreate()

        _logger.info("âœ… Databricks native Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—å®Œäº†")
        _logger.info(f"ğŸ“Š Spark version: {spark.version}")
        return spark

    except ImportError:
        raise ImportError("Databricksç’°å¢ƒã§PySparkãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")


def create_local_connect_session():
    """ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®DatabricksConnect Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
    try:
        from databricks.connect import DatabricksSession

        # .envèª­ã¿è¾¼ã¿
        from dotenv import find_dotenv, load_dotenv

        env_file = find_dotenv()
        if env_file:
            load_dotenv(env_file)
            _logger.info(f"ğŸ“ .envèª­ã¿è¾¼ã¿: {env_file}")

        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®šãƒã‚§ãƒƒã‚¯
        profile_name = os.environ.get("DATABRICKS_CONFIG_PROFILE")

        if profile_name:
            _logger.info(f"ğŸ”§ .databrickscfgãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {profile_name}")
            os.environ.setdefault("DATABRICKS_CONNECT_DISABLE_VERSION_CHECK", "true")

            if os.environ.get("DATABRICKS_CLUSTER_ID"):
                cluster_id = os.environ.get("DATABRICKS_CLUSTER_ID")
                spark = (
                    DatabricksSession.builder.profile(profile_name)
                    .clusterId(cluster_id)
                    .getOrCreate()
                )
                _logger.info(f"ğŸ†” ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½¿ç”¨: {cluster_id}")
            else:
                os.environ.setdefault("DATABRICKS_SERVERLESS_COMPUTE_ID", "auto")
                spark = (
                    DatabricksSession.builder.profile(profile_name)
                    .serverless(True)
                    .getOrCreate()
                )
                _logger.info("ğŸš€ Serverless Computeä½¿ç”¨")
        else:
            _logger.info("ğŸ”§ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç›´æ¥æ¥ç¶š")

            required_vars = ["DATABRICKS_HOST", "DATABRICKS_TOKEN"]
            missing_vars = [var for var in required_vars if not os.environ.get(var)]

            if missing_vars:
                raise ValueError(f"ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®š: {missing_vars}")

            os.environ.setdefault("DATABRICKS_CONNECT_DISABLE_VERSION_CHECK", "true")

            if os.environ.get("DATABRICKS_CLUSTER_ID"):
                cluster_id = os.environ.get("DATABRICKS_CLUSTER_ID")
                spark = DatabricksSession.builder.clusterId(cluster_id).getOrCreate()
                _logger.info(f"ğŸ†” ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½¿ç”¨: {cluster_id}")
            else:
                os.environ.setdefault("DATABRICKS_SERVERLESS_COMPUTE_ID", "auto")
                spark = DatabricksSession.builder.serverless(True).getOrCreate()
                _logger.info("ğŸš€ Serverless Computeä½¿ç”¨")

        # DataFrameè¡¨ç¤ºæœ€é©åŒ–ï¼ˆServerlessç’°å¢ƒã§ã¯ä¸€éƒ¨è¨­å®šãŒåˆ¶é™ã•ã‚Œã‚‹ï¼‰
        try:
            spark.conf.set("spark.sql.repl.eagerEval.enabled", True)
        except Exception:
            # Serverless Computeã§ã¯è¨­å®šã§ããªã„å ´åˆãŒã‚ã‚‹ã®ã§ã‚¹ã‚­ãƒƒãƒ—
            pass

        _logger.info("âœ… Databricks Connect Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†")
        _logger.info(f"ğŸ“Š Spark version: {spark.version}")
        _logger.info(f"ğŸŒ æ¥ç¶šå…ˆ: {spark.client.host}")
        return spark

    except ImportError as e:
        raise ImportError(f"databricks-connectãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")


def create_spark_session():
    """å®Ÿè¡Œç’°å¢ƒã«å¿œã˜ã¦é©åˆ‡ãªSparkã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    env_type = get_environment_type()
    _logger.info(f"ğŸ” å®Ÿè¡Œç’°å¢ƒæ¤œå‡º: {env_type}")

    try:
        if env_type == "databricks":
            return create_databricks_native_session()
        else:  # localç’°å¢ƒï¼ˆVS Codeã€Cursorã€Dev Container CLIç­‰ï¼‰
            return create_local_connect_session()

    except Exception as e:
        error_msg = str(e)
        _logger.error(f"âŒ Sparkã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå¤±æ•—: {error_msg}")

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸æ•´åˆã®æ¤œå‡ºã¨å¯¾å¿œææ¡ˆ
        if "Unsupported combination" in error_msg and "Databricks Runtime" in error_msg:
            _logger.error("ğŸ”§ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸æ•´åˆãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            _logger.error("ğŸ’¡ ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®å¯¾å¿œã‚’è¡Œã£ã¦ãã ã•ã„:")
            _logger.error(
                "   1. DatabricksConnectã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã«åˆã‚ã›ã¦ãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰:"
            )
            _logger.error(
                "      uv add 'databricks-connect~=[ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒãƒ¼ã‚¸ãƒ§ãƒ³]'"
            )
            _logger.error("   2. Databricksã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰")

        _logger.error(f"ğŸ’¡ ç’°å¢ƒã‚¿ã‚¤ãƒ—: {env_type}")
        raise


# æ˜ç¤ºçš„ã«create_spark_session()ã‚’å‘¼ã³å‡ºã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„
# ä¾‹: spark = create_spark_session()
```

:::

::: {.callout-note appearance="simple" collapse="true"}

### 6.2. `.env.example`

```{.sh}
# Databricksè¨­å®š

# .databrickscfgã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ¨å¥¨ï¼‰
DATABRICKS_CONFIG_PROFILE=DEFAULT

# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½¿ç”¨ã®å ´åˆï¼ˆã©ã¡ã‚‰ã‹ä¸€æ–¹ã‚’è¨­å®šï¼‰
# DATABRICKS_CLUSTER_ID=

# Serverless Computeä½¿ç”¨ã®å ´åˆ
DATABRICKS_SERVERLESS_COMPUTE_ID=auto

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ç„¡åŠ¹åŒ–
DATABRICKS_CONNECT_DISABLE_VERSION_CHECK=true
```

:::

## 7. ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã® Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•

HACK ã£ã½ã„ã§ã™ãŒä»¥ä¸‹ã®ã‚ˆã†ã«è¨˜è¿°ã—ã¦ãŠãã¨ Databricks ã§ã®å®Ÿè¡Œæ™‚ã®ã¿ Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚

uv ã‚’ä½¿ã£ã¦ã„ãªã„å ´åˆã¯ `%pip install <package>` ã§å¤§ä¸ˆå¤«ã§ã™ã€‚

```{.py}
import os
if os.environ.get("DATABRICKS_RUNTIME_VERSION"):
    %pip install uv
    %pip install -r <(uv pip compile pyproject.toml --color never)
```

## 8. Dev Container åˆ©ç”¨æ‰‹é †

### 8.1. æ¥ç¶šå…ˆã‚¯ãƒ©ã‚¹ã‚¿è¨­å®š

Spark config ã§ä»¥ä¸‹ã‚’è¨­å®šã—ã¾ã™

```
spark.databricks.service.server.enabled true
```

### 8.2. Databricks æ¥ç¶šè¨­å®š

Databricks ã¸æ¥ç¶šã™ã‚‹å ´åˆã¯ `~/.databrickscfg` ã«ä»¥ä¸‹ã®å†…å®¹ã‚’è¨˜è¿°ã—ã¾ã™

```ini
[DEFAULT]
host = https://your-databricks-workspace.cloud.databricks.com
token = your-access-token
```

- `host`: Databricks ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã® URL
- `token`: Databricks ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³

### 8.3. `.env` ä½œæˆ

1. `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™

    ```sh
    cp .env.example .env
    ```

1. å¿…è¦ã§ã‚ã‚Œã° `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„

### 8.4. Dev Container VS Code

1. F1 -> "Dev Containers: Open Folder in Container..." ã‚’é¸æŠã—ã¾ã™
1. ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã® Python ã‚«ãƒ¼ãƒãƒ«ã¯ "Python Environments..." -> "å¯¾è±¡ç’°å¢ƒ" ã¨é¸æŠã—ã¾ã™
1. Claude Code ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãªã®ã§ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‹ã‚‰èµ·å‹•ã§ãã¾ã™

## 9. ãŠã‚ã‚Šã«

å¤šåˆ†ã“ã‚ŒãŒä¸€ç•ªå¼·ã„ã¨æ€ã„ã¾ã™ã€‚
