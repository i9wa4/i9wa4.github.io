---
title: "データサインティスト用最強 Dev Container for Databricks with Claude Code"
author: uma-chan
date: 2025-07-28 00:59:19 +0900
date-modified: last-modified
image: "/assets/common/icon_hhkb3_large.jpg"
description: |
  Claude Code 対応の Dev Container で Databricks でもローカル開発環境の AI の恩恵を受けられるようになります
categories:
  - "blog"
  - "tech"
  - "tech-ai"
  - "tech-python"
  - "tech-vscode"
---

## 1. はじめに

DWH サービスが提供するコンピューティングリソースを使用してノートブックで機械学習や分析を行っている方は多いと思います。

そういった方々共通の悩みとして VS Code などのローカル開発環境が利用できない、そして結果的に開発時に AI の恩恵が受けられないことが挙げられると思います。

今回私が今メインで使っている Databricks についてこの悩みを解決する方法を紹介します。

## 2. 対象読者

- Databricks のコンピュートをローカルから利用したい方
- Databricks 上での開発に Claude Code を利用したい方
- Databricks 以外の DWH サービスを使っているが参考にしたい方 (実際読むと自作できると思います)

## 3. 前提知識

### 3.1. Dev Container とは

Dev Container は VS Code でコンテナを開発環境として利用できる便利機能です。

今回 Dev Container 設定で紹介するので整備する方がいればチーム全員に同じ開発環境を提供することができます。

VS Code ではない方も Dev Container CLI を利用することで恩恵を受けることができます。

ちなみに私は VS Code をメインで使用しているわけではないので VS Code 固有の機能は今回あまり多く登場しません。

### 3.2. Claude Code in Dev Container

Claude Code を Dev Container で利用する方法について2通り紹介します。

#### 3.2.1. devcontainer.json の features を利用する

こちらが簡単な方法です。

以下に Anthropic が提供している Dev Container feature を利用する方法が記載されています。

<https://github.com/anthropics/devcontainer-features/blob/main/src/claude-code/README.md>

抜粋すると以下の通りです。

```{.json filename=".devcontainer/devcontainer.json"}
"features": {
    "ghcr.io/devcontainers/features/node:1": {},
    "ghcr.io/anthropics/devcontainer-features/claude-code:1": {}
}
```

#### 3.2.2. Dockerfile を利用する

本家のリファレンス実装を利用する方法です。

以下が Claude Code 向け Dev Container について記載されている公式ドキュメントです。

<https://docs.anthropic.com/en/docs/claude-code/devcontainer>

この中でリファレンス実装として Claude Code 自身の Dev Container 設定が紹介されています。

<https://github.com/anthropics/claude-code/tree/main/.devcontainer>

```{.sh}
.devcontainer
├── devcontainer.json
├── Dockerfile
└── init-firewall.sh
```

このリファレンス実装を参考にしつつ私が使いやすいようにカスタマイズしたものを以下で紹介していきます。

### 3.3. uv とは

今回利用している Python 環境管理ツールです。

<https://github.com/astral-sh/uv>

最低限理解しておくべき要点は以下です。

- uv 自体は Python エコシステムの外にあるツールである
- インストールしたい Python パッケージを `pyproject.toml` で管理する
- `pyproject.toml` のパッケージの依存関係解決結果を `uv.lock` に保存し環境の再現性を担保している

## 4. Dev Container 設定

### 4.1. VS Code 側の準備

Dev Container 拡張をインストールしておく必要があります。

<https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers>

### 4.2. Dockerfile

Anthropic のリファレンス実装をベースにして以下のような Dockerfile を作成しました。

見て分かる通り hadolint で結構指摘が出る書き味ですが特に意思もないのでそのままにしています。

::: {.callout-note appearance="simple" collapse="true"}

#### 4.2.1. `.devcontainer/Dockerfile`

```{.Dockerfile filename=".devcontainer/Dockerfile"}
FROM node:20

ARG TZ
ENV TZ="$TZ"

# Install basic development tools and iptables/ipset
RUN apt update && apt install -y less \
  git \
  procps \
  sudo \
  fzf \
  zsh \
  man-db \
  unzip \
  gnupg2 \
  gh \
  iptables \
  ipset \
  iproute2 \
  dnsutils \
  aggregate \
  jq

# Ensure default node user has access to /usr/local/share
RUN mkdir -p /usr/local/share/npm-global && \
  chown -R node:node /usr/local/share

ARG USERNAME=node

# Persist bash history.
RUN SNIPPET="export PROMPT_COMMAND='history -a' && export HISTFILE=/commandhistory/.bash_history" \
  && mkdir /commandhistory \
  && touch /commandhistory/.bash_history \
  && chown -R $USERNAME /commandhistory

# Set `DEVCONTAINER` environment variable to help with orientation
ENV DEVCONTAINER=true

# Create workspace and config directories and set permissions
RUN mkdir -p /workspace /home/node/.claude && \
  chown -R node:node /workspace /home/node/.claude

WORKDIR /workspace

RUN ARCH=$(dpkg --print-architecture) && \
  wget "https://github.com/dandavison/delta/releases/download/0.18.2/git-delta_0.18.2_${ARCH}.deb" && \
  sudo dpkg -i "git-delta_0.18.2_${ARCH}.deb" && \
  rm "git-delta_0.18.2_${ARCH}.deb"

# Set up non-root user
USER node

# Install global packages
ENV NPM_CONFIG_PREFIX=/usr/local/share/npm-global
ENV PATH=$PATH:/usr/local/share/npm-global/bin

# Set the default shell to zsh rather than sh
ENV SHELL=/bin/zsh

# Default powerline10k theme
RUN sh -c "$(wget -O- https://github.com/deluan/zsh-in-docker/releases/download/v1.2.0/zsh-in-docker.sh)" -- \
  -p git \
  -p fzf \
  -a "source /usr/share/doc/fzf/examples/key-bindings.zsh" \
  -a "source /usr/share/doc/fzf/examples/completion.zsh" \
  -a "export PROMPT_COMMAND='history -a' && export HISTFILE=/commandhistory/.bash_history" \
  -x

# Install Claude
RUN npm install -g @anthropic-ai/claude-code

# Python environment setup (if needed)
# Copy uv binary from official image
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

USER node
```

Anthropic のリファレンス実装 ([e394b39](https://github.com/anthropics/claude-code/blob/55219b8b4e612b5fc6a85f7dc4eb4382ec4134eb/.devcontainer/Dockerfile)) と比較すると以下のような変更を行っています。

- firewall スクリプト対応部分を削除
- uv インストール部分を追加

```{.diff}
$ diff -u ../../anthropics/claude-code/.devcontainer/Dockerfile .devcontainer/Dockerfile
--- ../../anthropics/claude-code/.devcontainer/Dockerfile       2025-07-26 16:16:50
+++ .devcontainer/Dockerfile    2025-07-26 23:24:59
@@ -69,10 +69,8 @@
 # Install Claude
 RUN npm install -g @anthropic-ai/claude-code

-# Copy and set up firewall script
-COPY init-firewall.sh /usr/local/bin/
-USER root
-RUN chmod +x /usr/local/bin/init-firewall.sh && \
-  echo "node ALL=(root) NOPASSWD: /usr/local/bin/init-firewall.sh" > /etc/sudoers.d/node-firewall && \
-  chmod 0440 /etc/sudoers.d/node-firewall
+# Python environment setup (if needed)
+# Copy uv binary from official image
+COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv
+
 USER node
```

:::

### 4.3. devcontainer.json

以下のような `devcontainer.json` を作成しました。

こちらは Anthropic のリファレンス実装に比べると割と変更点が多いです。

::: {.callout-note appearance="simple" collapse="true"}

#### 4.3.1. `.devcontainer/devcontainer.json`

```{.json filename=".devcontainer/devcontainer.json"}
{
    "name": "Claude Code Sandbox",
    "build": {
        "dockerfile": "Dockerfile",
        "args": {
            "TZ": "${localEnv:TZ:Asia/Tokyo}"
        }
    },
    "runArgs": [
        "--cap-add=NET_ADMIN",
        "--cap-add=NET_RAW",
        "--network=host"
    ],
    "customizations": {
        "vscode": {
            "extensions": [
                "editorconfig.editorconfig",
                "elagil.pre-commit-helper",
                "ms-python.python",
                "ms-toolsai.jupyter"
            ],
            "settings": {
                "terminal.integrated.defaultProfile.linux": "zsh",
                "terminal.integrated.profiles.linux": {
                    "bash": {
                        "path": "bash",
                        "icon": "terminal-bash"
                    },
                    "zsh": {
                        "path": "zsh"
                    }
                }
            }
        }
    },
    "remoteUser": "node",
    "mounts": [
        "source=${localEnv:CLAUDE_CONFIG_DIR},target=/home/node/.claude,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.config/gh,target=/home/node/.config/gh,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.config/git,target=/home/node/.config/git,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.databrickscfg,target=/home/node/.databrickscfg,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.dbt,target=/home/node/.dbt,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.gitconfig,target=/home/node/.gitconfig,type=bind,consistency=cached",
        "source=${localEnv:HOME}/.ssh,target=/home/node/.ssh,type=bind,consistency=cached",
        "source=claude-code-bashhistory-${devcontainerId},target=/commandhistory,type=volume"
    ],
    "remoteEnv": {
        "CLAUDE_CONFIG_DIR": "/home/node/.claude",
        "NODE_OPTIONS": "--max-old-space-size=4096",
        "POWERLEVEL9K_DISABLE_GITSTATUS": "true",
        "UV_LINK_MODE": "copy"
    },
    "workspaceMount": "source=${localWorkspaceFolder},target=/workspace,type=bind,consistency=delegated",
    "workspaceFolder": "/workspace",
    "postStartCommand": "uv sync --frozen --group dev && uv run pre-commit install"
}
```

Anthropic のリファレンス実装 ([33e37bd](https://github.com/anthropics/claude-code/blob/55219b8b4e612b5fc6a85f7dc4eb4382ec4134eb/.devcontainer/devcontainer.json)) と比較すると以下のような変更を行っています。

- `runArgs` に `--network=host` を追加
    - Databricks 向け
- VS Code 向け拡張機能を追加
    - `editorconfig.editorconfig`
        - テキストエディタ間での設定を統一する
    - `elagil.pre-commit-helper`
        - pre-commit を使いやすくする
    - `ms-python.python`
        - 流石に必要
    - `ms-toolsai.jupyter`
        - ノートブックを VS Code で開くために必要
- VS Code 向け Formatter 設定を削除
- `mounts` に設定ファイル群を追加
    - 以下のツールの設定ファイルをマウントして利用します
        - Claude Code
        - GitHub CLI
        - Git
        - Databricks (認証情報)
        - dbt (認証情報)
        - ssh
- `mounts` の Claude Code 設定分離部分を削除
    - ユーザー設定をマウントして利用したかったので削除しました
- `remoteEnv` に以下の環境変数を追加
    - `CLAUDE_CONFIG_DIR`
        - Claude Code の設定参照箇所の安定化を図る
    - `UV_LINK_MODE`
        - コンテナなので uv のリンクモードを `copy` に設定
- `postStartCommand` に以下のコマンドを追加
    - `uv sync --frozen --group dev`
        - Python モジュールをインストールする
    - `uv run pre-commit install`
        - pre-commit をインストールする

:::

### 4.4. start-jupyter.sh

VS Code ユーザーは不要ですが一応 JupyterLab を起動するスクリプトも用意しました。

ポートは自動割り当てにしています。

::: {.callout-note appearance="simple" collapse="true"}

#### 4.4.1. `devcontainer/start-jupyter.sh`

```{.sh filename=".devcontainer/start-jupyter.sh"}
#!/usr/bin/env bash
set -o errexit

# JupyterLab起動スクリプト
# Databricks Connect環境での快適な開発用

echo "🔥 Databricks JupyterLab 環境を起動中..."

# ポート設定（環境変数または自動割り当て）
# JUPYTER_PORT=8888 # NOTE: この行をコメントアウトすると自動ポート検索が有効になります
JUPYTER_PORT=${JUPYTER_PORT:-0}

if [ "$JUPYTER_PORT" = "0" ]; then
  echo "📡 利用可能なポートを自動検索中..."
else
  echo "📡 指定ポート ${JUPYTER_PORT} で起動します"
fi

# Python環境の確認
if [ -f "uv.lock" ]; then
  echo "📦 uv環境を使用してJupyterLabを起動します"
  uv sync --frozen
  nohup uv run jupyter lab --ip=0.0.0.0 --port=${JUPYTER_PORT} --no-browser --allow-root \
    --NotebookApp.token='' --NotebookApp.password='' \
    --ServerApp.allow_origin='*' --ServerApp.disable_check_xsrf=True >/dev/null 2>&1 &
elif [ -d ".venv" ]; then
  echo "📦 venv環境を使用してJupyterLabを起動します"
  source .venv/bin/activate
  nohup jupyter lab --ip=0.0.0.0 --port=${JUPYTER_PORT} --no-browser --allow-root \
    --NotebookApp.token='' --NotebookApp.password='' \
    --ServerApp.allow_origin='*' --ServerApp.disable_check_xsrf=True >/dev/null 2>&1 &
else
  echo "❌ Python仮想環境が見つかりません"
  echo "uvまたはvenvで環境をセットアップしてください"
  exit 1
fi

# 実際に割り当てられたポートを取得（リトライ機能付き）
for i in {1..10}; do
  sleep 1
  ACTUAL_PORT=$(ss -tlnp 2>/dev/null | grep jupyter-lab | awk '{print $4}' | cut -d: -f2 | head -1)
  if [ -n "$ACTUAL_PORT" ]; then
    break
  fi
done

if [ "$JUPYTER_PORT" = "0" ] && [ -n "$ACTUAL_PORT" ]; then
  echo "🌐 JupyterLabは http://localhost:${ACTUAL_PORT}/lab でアクセス可能です"
else
  echo "🌐 JupyterLabは http://localhost:${JUPYTER_PORT}/lab でアクセス可能です"
fi
```

:::

## 5. Python 環境設定

Python コーディング向け環境設定について説明していきます。

最重要なモジュールは `databricks-connect` です。

他に pre-commit で Black や isort、flake8 を利用していくので設定も記述しています。

::: {.callout-note appearance="simple" collapse="true"}

### 5.1. `pyproject.toml`

```{.toml filename="pyproject.toml"}
[project]
name = "databricks-devcontainer"
version = "0.1.0"
description = "Add your description here"
requires-python = "~=3.13.0"
dependencies = [
    "databricks-connect~=16.4.0",
    "ipykernel",
    "jupyterlab",
    "matplotlib",
    "numpy",
    "pandas",
    "python-dotenv",
    "requests",
    "seaborn",
]

[dependency-groups]
dev = [
    "pre-commit~=4.2.0",
    "black==25.1.0",
    "isort==6.0.0",
    "flake8==7.3.0",
    "flake8-pyproject",
]

[tool.black]
line-length = 88
target-version = ['py313']

[tool.isort]
profile = "black"
line_length = 88

[tool.flake8]
max-line-length = 120
extend-exclude = [".venv"]
extend-ignore = [
    "E203",  # Whitespace before ':'
    "E701",  # Multiple statements on one line (colon)
    "F821"   # undefined name (Databricks-specific module)
]
```

:::

### 5.2. pre-commit 設定

Formatter 設定を VS Code から切り離すことで VS Code 以外のエディタや GitHub Actions でも利用できるようになって最高ですね！

::: {.callout-note appearance="simple" collapse="true"}

#### 5.2.1. `.pre-commit-config.yaml`

```{.yaml filename=".pre-commit-config.yaml"}
default_stages: [pre-commit]
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: check-added-large-files
      - id: check-json
      - id: check-yaml
      - id: detect-private-key
      - id: end-of-file-fixer
      - id: mixed-line-ending
        args: [--fix=no]
      - id: trailing-whitespace
        args: [--markdown-linebreak-ext=md]

  - repo: local
    hooks:
      - id: black
        name: black
        entry: uv run black
        language: system
        types: [python]

  - repo: local
    hooks:
      - id: isort
        name: isort (python)
        entry: uv run isort
        language: system
        types: [python]

  - repo: local
    hooks:
      - id: flake8
        name: flake8
        entry: uv run flake8
        language: system
        types: [python]

  - repo: local
    hooks:
      - id: sqlfmt
        name: sqlfmt
        entry: uv run sqlfmt
        language: system
        types: [sql]

  - repo: https://github.com/gitleaks/gitleaks
    rev: v8.28.0
    hooks:
      - id: gitleaks
```

:::

### 5.3. pre-commit in GitHub Actions

おまけですが GitHub Actions で pre-commit を実行するための設定も用意しました。

::: {.callout-note appearance="simple" collapse="true"}

#### 5.3.1. `.github/workflows/pre-commit.yaml`

```{.yaml filename=".github/workflows/pre-commit.yaml"}
name: pre-commit
run-name: ${{ github.event_name }} on ${{ github.ref_name }} by @${{ github.actor }}

on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
    types:
      - opened
      - synchronize
      - reopened

permissions: {}

defaults:
  run:
    shell: bash

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  pre-commit:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          # プルリクエスト時はソースブランチ(github.head_ref)を、
          # 手動実行時は実行対象ブランチ(github.ref_name)をチェックアウト
          ref: ${{ github.event_name == 'pull_request' && github.head_ref || github.ref_name }}
          persist-credentials: false

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "0.8.3"

      - name: Set up Python
        run: |
          uv sync --only-group dev

      - name: Install pre-commit
        run: |
          uv run pre-commit install

      - name: Run pre-commit
        run: |
          uv run pre-commit run --all-files
```

:::

### 5.4. Python 仮想環境更新手順

1. 必要に応じて `.python-version` や `pyproject.toml` を更新します。
1. `uv.lock` を更新します。

    ```sh
    $ uv lock --upgrade
    ```

1. .venv を更新します。

    ```sh
    $ uv sync --frozen --group dev
    ```


## 6. Databricks Connect 設定

Dev Container (ローカル) と Databricks の両方で同じように動作する Spark セッションを作成するためのライブラリを用意しました。

以下のように利用できます。

```{.python}
from databricks_spark import create_spark_session

# 新しいSparkセッションを作成
spark = create_spark_session()
df = spark.sql("SHOW CATALOGS")
df.show()
```

::: {.callout-note appearance="simple" collapse="true"}

### 6.1. `databricks_connect.py`

```{.python filename="databricks_connect.py"}
"""
Databricks Spark セッション管理
Databricksとローカル両対応の1ファイル完結型ライブラリ

使用方法:
    from databricks_spark import create_spark_session

    # 新しいSparkセッションを作成
    spark = create_spark_session()
    df = spark.sql("SHOW CATALOGS")
    df.show()
"""

import logging
import os
import sys

# ロガー設定
_logger = logging.getLogger(__name__)
if not _logger.handlers:
    _logger.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s %(name)s [%(levelname)s] %(message)s")
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(formatter)
    _logger.addHandler(handler)


def is_databricks_environment() -> bool:
    """Databricks環境で実行されているかを判定"""
    return os.environ.get("DATABRICKS_RUNTIME_VERSION") is not None


def get_environment_type() -> str:
    """実行環境のタイプを取得"""
    if is_databricks_environment():
        return "databricks"
    else:
        return "local"


def create_databricks_native_session():
    """Databricks上でのネイティブSparkセッション作成"""
    try:
        from pyspark.sql import SparkSession

        spark = SparkSession.getActiveSession()
        if spark is None:
            spark = SparkSession.builder.appName("DatabricksNotebook").getOrCreate()

        _logger.info("✅ Databricks native Sparkセッション取得完了")
        _logger.info(f"📊 Spark version: {spark.version}")
        return spark

    except ImportError:
        raise ImportError("Databricks環境でPySparkが利用できません")


def create_local_connect_session():
    """ローカルでのDatabricksConnect Sparkセッション作成"""
    try:
        from databricks.connect import DatabricksSession

        # .env読み込み
        from dotenv import find_dotenv, load_dotenv

        env_file = find_dotenv()
        if env_file:
            load_dotenv(env_file)
            _logger.info(f"📁 .env読み込み: {env_file}")

        # プロファイル指定チェック
        profile_name = os.environ.get("DATABRICKS_CONFIG_PROFILE")

        if profile_name:
            _logger.info(f"🔧 .databrickscfgプロファイル使用: {profile_name}")
            os.environ.setdefault("DATABRICKS_CONNECT_DISABLE_VERSION_CHECK", "true")

            if os.environ.get("DATABRICKS_CLUSTER_ID"):
                cluster_id = os.environ.get("DATABRICKS_CLUSTER_ID")
                spark = (
                    DatabricksSession.builder.profile(profile_name)
                    .clusterId(cluster_id)
                    .getOrCreate()
                )
                _logger.info(f"🆔 クラスター使用: {cluster_id}")
            else:
                os.environ.setdefault("DATABRICKS_SERVERLESS_COMPUTE_ID", "auto")
                spark = (
                    DatabricksSession.builder.profile(profile_name)
                    .serverless(True)
                    .getOrCreate()
                )
                _logger.info("🚀 Serverless Compute使用")
        else:
            _logger.info("🔧 環境変数から直接接続")

            required_vars = ["DATABRICKS_HOST", "DATABRICKS_TOKEN"]
            missing_vars = [var for var in required_vars if not os.environ.get(var)]

            if missing_vars:
                raise ValueError(f"環境変数が未設定: {missing_vars}")

            os.environ.setdefault("DATABRICKS_CONNECT_DISABLE_VERSION_CHECK", "true")

            if os.environ.get("DATABRICKS_CLUSTER_ID"):
                cluster_id = os.environ.get("DATABRICKS_CLUSTER_ID")
                spark = DatabricksSession.builder.clusterId(cluster_id).getOrCreate()
                _logger.info(f"🆔 クラスター使用: {cluster_id}")
            else:
                os.environ.setdefault("DATABRICKS_SERVERLESS_COMPUTE_ID", "auto")
                spark = DatabricksSession.builder.serverless(True).getOrCreate()
                _logger.info("🚀 Serverless Compute使用")

        # DataFrame表示最適化（Serverless環境では一部設定が制限される）
        try:
            spark.conf.set("spark.sql.repl.eagerEval.enabled", True)
        except Exception:
            # Serverless Computeでは設定できない場合があるのでスキップ
            pass

        _logger.info("✅ Databricks Connect Sparkセッション作成完了")
        _logger.info(f"📊 Spark version: {spark.version}")
        _logger.info(f"🌐 接続先: {spark.client.host}")
        return spark

    except ImportError as e:
        raise ImportError(f"databricks-connectが利用できません: {e}")


def create_spark_session():
    """実行環境に応じて適切なSparkセッションを作成"""
    env_type = get_environment_type()
    _logger.info(f"🔍 実行環境検出: {env_type}")

    try:
        if env_type == "databricks":
            return create_databricks_native_session()
        else:  # local環境（VS Code、Cursor、Dev Container CLI等）
            return create_local_connect_session()

    except Exception as e:
        error_msg = str(e)
        _logger.error(f"❌ Sparkセッション作成失敗: {error_msg}")

        # バージョン不整合の検出と対応提案
        if "Unsupported combination" in error_msg and "Databricks Runtime" in error_msg:
            _logger.error("🔧 バージョン不整合が検出されました")
            _logger.error("💡 以下のいずれかの対応を行ってください:")
            _logger.error(
                "   1. DatabricksConnectをクラスターのランタイムに合わせてダウングレード:"
            )
            _logger.error(
                "      uv add 'databricks-connect~=[クラスターのランタイムバージョン]'"
            )
            _logger.error("   2. Databricksクラスターのランタイムをアップグレード")

        _logger.error(f"💡 環境タイプ: {env_type}")
        raise


# 明示的にcreate_spark_session()を呼び出してセッションを作成してください
# 例: spark = create_spark_session()
```

:::

::: {.callout-note appearance="simple" collapse="true"}

### 6.2. `.env.example`

```{.sh}
# Databricks設定

# .databrickscfgのプロファイル名（推奨）
DATABRICKS_CONFIG_PROFILE=DEFAULT

# クラスター使用の場合（どちらか一方を設定）
# DATABRICKS_CLUSTER_ID=

# Serverless Compute使用の場合
DATABRICKS_SERVERLESS_COMPUTE_ID=auto

# バージョンチェック無効化
DATABRICKS_CONNECT_DISABLE_VERSION_CHECK=true
```

:::

## 7. ノートブックでの Python モジュールインストール方法

HACK っぽいですが以下のように記述しておくと Databricks での実行時のみ Python パッケージをインストールできます。

uv を使っていない場合は `%pip install <package>` で大丈夫です。

```{.py}
import os
if os.environ.get("DATABRICKS_RUNTIME_VERSION"):
    %pip install uv
    %pip install -r <(uv pip compile pyproject.toml --color never)
```

## 8. Dev Container 利用手順

### 8.1. 接続先クラスタ設定

Spark config で以下を設定します

```
spark.databricks.service.server.enabled true
```

### 8.2. Databricks 接続設定

Databricks へ接続する場合は `~/.databrickscfg` に以下の内容を記述します

```ini
[DEFAULT]
host = https://your-databricks-workspace.cloud.databricks.com
token = your-access-token
```

- `host`: Databricks ワークスペースの URL
- `token`: Databricks アクセストークン

### 8.3. `.env` 作成

1. `.env` ファイルを作成します

    ```sh
    cp .env.example .env
    ```

1. 必要であれば `.env` ファイルの内容を変更してください

### 8.4. Dev Container VS Code

1. F1 -> "Dev Containers: Open Folder in Container..." を選択します
1. ノートブックの Python カーネルは "Python Environments..." -> "対象環境" と選択します
1. Claude Code はインストール済みなのでターミナルから起動できます

## 9. おわりに

多分これが一番強いと思います。
